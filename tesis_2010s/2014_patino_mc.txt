CENTRO DE ESTUDIOS INTERNACIONALES
MAESTRÍA EN CIENCIA POLÍTICA PROMOCIÓN 2011-2013
LA UTILIZACIÓN EFECTIVA DE LAS EVALUACIONES EN LAS DECISIONES SOBRE
POLÍTICA PÚBLICA:
EL CASO DE LOS PROGRAMAS FEDERALES DE ATENCIÓN A
GRUPOS VULNERABLES.
TESIS PARA OBTENER EL GRADO DE MAESTRÍA QUE PRESENTA:
MIREYA CAROLINA PATIÑO PEÑA

DIRECTOR: MTRO. JAVIER GONZÁLEZ GÓMEZ

MÉXICO, D.F.

MAYO, 2014

Para Carlos, que siempre has estado ahí.
2 de 212

AGRADECIMIENTOS
Aunque pareciera que la elaboración de una tesis es fruto de un proceso individual, este trabajo hubiera sido imposible culminarlo sin el apoyo de distintas personas que contribuyeron de muchas formas a su desarrollo. Trataré de mencionarlas a todas, anticipando mis disculpas por cualquier involuntaria omisión.
Quiero expresar mi estima y gratitud a Isidro Soloaga y Gloria Rubio por creer en mí y apoyarme para iniciar hace cuatro años esta maestría en El Colegio de México. La experiencia de “vivir” esta maestría me permitió enriquecer no solo mi formación académica, también me brindó la oportunidad de vivir muchas otras cosas que nutrieron mi desarrollo personal.
De manera particular mi gran agradecimiento a Javier González Gómez, por acompañarme en este proceso como asesor de tesis y quien leyó cuidadosamente los diversos borradores de este trabajo. Sus observaciones críticas modificaron el orden de exposición y precisaron desarrollos conceptuales. Este proceso de ajustes y desajustes fue un tiempo rico en aprendizaje.
Mi agradecimiento se extiende también a mis lectores Guillermo Cejudo y José Luis Méndez que en las primeras etapas de esta investigación aportaron sus valiosas y oportunas consideraciones, sin olvidar las palabras de aliento que me expresaron en la etapa final de este proceso.
Merece asimismo mi agradecimiento a cada una de las personas que me dedicaron su tiempo para entrevistas en el contexto complicado que siempre representa el cierre de una administración. Quiero mencionar en particular el espacio que me concedieron Ernesto Cordero Arroyo, Ana María León Miravalles, Benjamín Hill Mayoral, Thania de la Garza Navarrete, Agustín Caso Raphael y la paciencia de Claudia Mir Cervantes. Asimismo, mi gratitud por la buena disposición para ayudarme de Gerardo Franco Parrillat Marroquín, Rogelio Omar Grados Zamudio, Carmen Echeverría, Mónica Orozco Corona, Carlos Augusto Morales López, Cecilia Reyes Montes y aquellas personas que prefirieron no ser mencionadas pero que me arrojaron mucha luz conforme avancé en el camino, les estoy profundamente agradecida.
Quiero agradecer también a Fernando López y Roberto Moreno que a lo largo de este trabajo contribuyeron de formas muy distintas en este proceso. Especial mención a Horacio Chavira quien además de un buen compañero de retos durante la maestría, se convirtió en un gran amigo con quien compartí largas y estimulantes pláticas conforme avanzamos en el camino de nuestras investigaciones.
A esta larga lista debo añadir a mi familia por sus atinados apoyos en distintos momentos de la maestría, y en especial a Carlos Guerrero por su apoyo incondicional desde que inicié el sendero para estudiar esta maestría, por su emoción por mis logros pero también, por resistir los ires y venires con paciencia y con la mayor comprensión como ha sido desde hace años.
3 de 212

TABLA DE CONTENIDO

Introducción

5

Capítulo 1. ¿Por qué y para qué evaluar en el sector público?

20

1.1. Los propósitos de la evaluación para el sector público

21

1.2. La utilización de los resultados derivados de las evaluaciones

30

1.3. La decisión pública: modelos teóricos que la explican

55

Capítulo 2. El sistema de evaluación en México y descripción del conjunto de

63

Programas federales dirigidos a Grupos Vulnerables

2.1. El sistema de evaluación en el ámbito del Poder Ejecutivo

64

2.2. El sistema de evaluación y su vínculo con el presupuesto público

84

2.3. Descripción de los casos de estudio

93

Capítulo 3. El comportamiento de los programas dirigidos a Grupos Vulnerables a 118 partir de los resultados de las evaluaciones

3.1. Acciones que se tradujeron en compromisos de mejora de los programas

119

dirigidos a Grupos Vulnerables

3.2. Factores que explican las decisiones de mejora de los programas públicos 127

3.3. Factores que explican las decisiones presupuestales

141

Capítulo 4. ¿Qué factores explican el sistema de evaluación en la experiencia

163

mexicana?

Conclusiones

179

Anexo 1. Avance porcentual de las acciones para la atención de los ASM de los 190 Programa de Atención a Grupos Vulnerables

Anexo 2. Actores entrevistados para la elaboración de esta investigación

198

Anexo 3. Modelo de cuestionario aplicado en las entrevistas

199

Acrónimos

201

Contenido de Tablas, Figuras y Gráficos

203

Referencias bibliográficas

205

4 de 212

La utilización efectiva de las evaluaciones en las decisiones sobre política pública federal: el caso de los programas federales de Atención a Grupos Vulnerables.
Introducción. Recientemente, la evaluación de políticas y programas públicos en México se colocó como un eje principal en el quehacer del gobierno. El interés por implementar un sistema de evaluación en el ámbito federal responde a la necesidad de aplicar criterios racionalinstrumentales en las decisiones en torno al desempeño de la gestión pública y los recursos que para ello se emplean. En este sentido, los ejercicios de evaluación representan una forma de insumo, de evidencia empírica sobre los resultados de la intervención gubernamental y en consecuencia, sirven para monitorear la calidad del gasto público. Las evaluaciones proveen de información técnica para la toma de decisiones en la administración pública, así como permiten conocer si los gobiernos so capaces de resolver los problemas públicos, generar consensos en torno a la legitimidad de la capacidad para gobernar, y son un componente muy importante para fortalecer la rendición de cuentas. En concreto, con las evaluaciones se genera información precisa sobre el avance en el cumplimiento de los objetivos y metas de las políticas públicas.
Aunque en nuestro país los ejercicios en materia de evaluación se tienen registrados desde al menos cuatro décadas atrás, los esfuerzos se concentraron en el control legal-administrativo de los insumos y recursos, dejando de lado los impactos y
5 de 212

resultados orientados a crear valor público1 entre la ciudadanía como se busca hoy en
día.
A partir de finales de la década de 1990, cuando se registró un importante cambio
en el contexto político mexicano traducido en pluralidad en el Congreso, y años más
tarde en alternancia del Poder Ejecutivo, se comenzó a transformar gradualmente el
diseño institucional y el marco legal que reconoció la relevancia de la evaluación de las intervenciones públicas, con énfasis en los programas sociales2 como una herramienta
para producir evidencia sobre la eficacia de las decisiones de gobierno. Sin embargo, fue
hasta 2007 cuando se aprobó el marco legal que buscaría vincular los resultados de
desempeño de los programas públicos con las decisiones de gasto. Esta forma de hacer
presupuesto, conocida como Presupuesto Basado en Resultados, es una forma de
mejorar la efectividad del proceso presupuestario a partir de decisiones más informadas
que se derivan de evaluaciones sistemáticas de los programas gubernamentales.
Esta ola de transformación de la administración pública en México en el terreno
federal, también respondió a las iniciativas impulsadas en el ámbito internacional por
organismos de corte económico, como la OCDE y del Banco Mundial, que promovieron
reformas de gestión pública sustentadas en resultados. En los últimos años, estos
organismos internacionales han otorgado financiamiento y asesoría técnica a los países
1 “El valor público se crea cuando se generan las condiciones orientadas a que todos los miembros de la sociedad disfruten de oportunidades para una vida digna, de empleo y bienestar, y garantizar el acceso a dichas oportunidades; es decir, cuando se aportan respuestas efectivas y útiles a las necesidades o demandas presentes y futuras de la población.” Secretaría de Hacienda y Crédito Público, Sistema de Evaluación del Desempeño, México, 2008. 2 De acuerdo con CONEVAL un programa social es aquel que cumple con las siguientes definiciones: pertenece a los programas presupuestarios de modalidad S (Reglas de Operación) o U (Otros Programas de Subsidios); son responsabilidad de una dependencia o entidad de la Administración Pública Federal y, están alineados con alguno de los Derechos Sociales o con la Dimensión de Bienestar Económico. CONEVAL, Inventario CONEVAL de Programas y Acciones Federales de Desarrollo Social. Presentación y Análisis del Inventario 2011-2012. p.8.
6 de 212

en desarrollo que han expresado interés en implementar sistemas de monitoreo y
evaluación de políticas basadas en evidencia. Estos esfuerzos globales buscan contribuir
a objetivos más amplios como las estrategias internacionales de reducción de la pobreza,
los Objetivos del Milenio de las Naciones Unidas y mayor eficacia del desarrollo, entre
otros.
En este sentido, las reformas administrativas implementadas en pocos años en
nuestro país se orientaron a generar, ordenar y sistematizar información sobre los programas federales, particularmente de tipo social3; crear indicadores relevantes, reglas de operación4 y sobre todo se promovió que los programas planearan con base en metas
de desempeño y generaran información útil para poder ser monitoreada y evaluada. El
esfuerzo empezó por aplicarse a la política social porque este fue el ramo en el que se
comenzaron a practicar evaluaciones desde hace décadas, sin embargo poco a poco se
han considerado más sectores, aunque los avances han sido incipientes. Hasta el año
2012, según datos de la Auditoría Superior de la Federación, el gobierno federal tenía
registrados 975 programas públicos (con un presupuesto neto de 3,706,922.2 millones de pesos)5, de esta cantidad 272 programas estuvieron dirigidos al logro de resultados y 110 programas contaron con Matrices de Indicadores para Resultados (MIR)6, es decir tuvieron información técnica para analizar sus resultados7.
3 Hasta hace unos años el gobierno federal, coordinado por el Consejo Nacional de Evaluación de la Política Social (CONEVAL), se dio a la tarea de construir un inventario de los programas sociales en el ámbito federal y diseñar información técnica (matrices de indicadores, indicadores estratégicos y de gestión, reglas de operación) que permitiera mayor claridad y sistematización de la información sobre política social. 4 Las Reglas de Operación establecen las disposiciones específicas a las cuales se sujetan determinados programas y fondos federales, con el objeto de otorgar transparencia y asegurar la aplicación eficiente, eficaz, no discrecional, oportuna y equitativa de los recursos públicos asignados a los mismos (SHCP, 2008). 5 Del total de programas públicos, 951 programas corresponden al gasto público y 24 programas al gasto no programable. 6 A diferencia de las cifras reportadas por la Auditoría Superior de la Federación, la Secretaría de Hacienda y Crédito Público señala que para el mismo año, de un total de 1,022 programas presupuestarios, 614 contaron con Matriz de Indicadores para Resultados. Información obtenida del Modelo Sintético de Desempeño publicado por la Secretaría de Hacienda y Crédito Público. Ver vínculo
7 de 212

Si lo vemos desde el punto de vista de lo que representa en términos de recursos
públicos, se tiene que del total del gasto programable8 para el año 2012 (2, 869, 583,
millones de pesos), 68.7 por ciento (1, 971, 729.71 millones pesos) estuvo orientado a
resultados9, pero si hacemos este mismo análisis considerando el gasto neto total (3,
706, 922, 200, 000 de pesos), podemos concluir que el gasto sujeto a Presupuesto por
Resultados representó el 53.19 por ciento10, y una gran parte de este porcentaje lo
tuvieron los programas sociales.11
http://www.transparenciapresupuestaria.gob.mx/ptp/contenidos/?id=7&page=Avances, fecha de consulta 10 de diciembre de 2012. 7 Los programas presupuestarios obligados a contar con Matriz de Indicadores para Resultados (MIR) se encuentran en las modalidades de gasto: (S) Sujetos a reglas de operación; (U); Otros subsidios; (E) Prestación de servicios públicos; (B) Provisión de bienes públicos; (F) Promoción y fomento; (G) Regulación y supervisión, y (P) Planeación, seguimiento y evaluación de políticas públicas. 8 El gasto público programable se refiere a “las erogaciones que la Federación realiza en cumplimiento de sus atribuciones conforme a los programas para proveer bienes y servicios públicos a la población” (Ley Federal de Presupuesto y Responsabilidad Hacendaria, 2006). Incluye el gasto corriente y el gasto de inversión. 9 Para este cálculo se consideraron los siguientes montos: 456,026,900,000 de pesos relacionados con las modalidades S y U; 64,733, 000,000 de pesos relacionados con la modalidad B; 617,131,300,000 de pesos relacionados con la modalidad E; 34,072,500, 000 de pesos relacionados con la modalidad P; 6,251,200, 000 de pesos relacionados con la modalidad F; 23,556,300, 000 de pesos de la modalidad G; 428,265,000, 000 de pesos de la modalidad K; 263,625,161,573 de pesos correspondientes al fondo FAEB; 61,951,394,932 de pesos correspondientes al fondo FASSA y 16,116,959,056 de pesos correspondientes del fondo FAM. Cabe señalar que como no se tiene información acerca de qué proyectos de inversión se consideraron dentro de la modalidad K esta autora tomó el monto total. Presupuesto de Egresos de la Federación 2012. 10 Para 2012, también se incluyó la modalidad K que se refiere a proyectos de inversión y que incluye a los 20 proyectos más grandes relacionados con la inversión pública de Petróleos Mexicanos y de la Secretaría de Comunicaciones y Transportes. Asimismo, durante los últimos meses de este año se incluyeron tres fondos del gasto federalizado, Ramo 33, relacionados con las Aportaciones Múltiples (FAM), las Aportaciones para la Educación Básica y Normal (FAEB) y las Aportaciones para los Servicios de Salud (FASSA. Información obtenida de una entrevista telefónica con un funcionario de alto nivel de la Secretaría de Hacienda y Crédito Público, 28 de noviembre de 2012. 11 De acuerdo a un artículo del Lic. Benjamín Hill Mayoral, Extitular de la Unidad de Evaluación del Desempeño, SHCP (2010-2012), en ese mismo año “cerca de 600 programas [contaban con información] para medir la ejecución, administración, seguimiento, evaluación, rendición de cuentas y transparencia de alrededor de dos quintas partes del total del gasto público del gobierno federal” en Maldonado C. y Galíndez, C, 2013, Monitoreo, Evaluación y Gestión por Resultados. Aprendizaje y Cooperación Sur-Sur para la Innovación: El Papel de los Actores Subnacionales, CIDE-Centro CLEAR para América Latina, México.
8 de 212

Además, vale resaltar que para los ejercicios fiscales 2009, 2010 y 2011, según datos de la Secretaría de Hacienda y Crédito Público12 (en adelante Secretaría de Hacienda), se ejercieron alrededor de 360 millones de pesos (mdp) que se destinaron a cubrir contrataciones de consultoría, asesoría, servicios de capacitación y viáticos para servidores públicos que buscaban instrumentar mecanismos operativos y normativos del sistema de evaluación mexicano. A esta cantidad también debería sumarse el costo total de 870 evaluaciones realizadas en el periodo 2007-2012. Tan sólo para dimensionar este tema, en el año 2012 se gastaron alrededor de 50 millones de pesos en 162 evaluaciones13 entre las que destacan las de diseño, procesos, Específicas de Desempeño y de impacto.14
La relevancia de estos datos permite voltear la atención a la política de evaluación que se viene implementando en nuestro país en los últimos años y cuestionarse sobre el impacto real que ha tenido en las políticas públicas sujetas a este tipo de medición. El impulso que el gobierno federal ha dado a la generación de evidencia empírica se señala como útil para alimentar las decisiones públicas. Sin embargo, no se tiene un balance claro sobre el retorno de inversión que han representado las evaluaciones en nuestro país, ni tampoco se conoce el grado de utilización15 de esta información en la efectividad de las políticas públicas. Aunque han transcurrido pocos años a partir de la decisión de garantizar el uso de criterios técnicos en las políticas públicas, la información acumulada
12 SHCP, Evaluación del sistema de presupuesto por resultados 2012, México. Disponible en http://www.transparenciapresupuestaria.gob.mx/ptp/ServletImagen?tipo=pdf&idDoc=39. 13 Para dimensionar esta cantidad de recursos vale la pena compararlo con el presupuesto que ejerció el programa Infraestructura en Distrito de Riego de la Comisión Nacional del Agua o el programa Investigación Científica y Tecnológica del Instituto de Seguridad y Servicios Sociales de los Trabajadores del Estado. 14 Datos obtenidos a partir del Inventario CONEVAL de Programas y Acciones Federales de Desarrollo Social 2012 disponible en http://www.coneval.gob.mx/evaluacion/ipfe/Paginas/default.aspx 15 Por “utilización de las evaluaciones” se entenderá la utilización efectiva de los resultados y las recomendaciones derivadas de las evaluaciones para la toma de decisiones (Weiss, 1998).
9 de 212

en el último sexenio ya puede darnos una pista sobre los efectos reales en los programas medidos, los impactos en la población y sobre todo, ofrecer datos técnicos sobre cómo han incidido en las decisiones del gasto público. Con la oferta de información generada hasta el momento, las decisiones en el proceso presupuestal tienen más criterios técnicos para reducir la lógica inercial y la discrecionalidad con que han sido asignados los recursos públicos por décadas. Sería bastante grave que todo el gasto invertido en esta política de reformas administrativas orientadas a la medición y sobre todo en las evaluaciones, se limitara a cumplir con una rutina burocrática como parte del control organizacional, en lugar de servir como insumo para mejora del ciclo de políticas y la toma de decisiones sobre el gasto público.
Debido a que la evaluación de la política social es un ámbito con mayor experiencia en ejercicios de evaluación, esta tesis se concentrará en algunos programas sociales del ámbito federal. Las preguntas centrales que guían esta investigación son ¿qué tipo de decisiones se adoptan a partir de los resultados de las evaluaciones en el ámbito federal? ¿Qué factores influyen para que las recomendaciones se utilicen efectivamente en acciones concretas? ¿Cómo afecta la falta de incentivos en el sistema de evaluación?
La hipótesis sugiere que en México, en particular en los programas de tipo social, los resultados de las evaluaciones se utilizan con fines instrumentales para las decisiones de mejora continua de desempeño. Sin embargo, la influencia de esta herramienta en las decisiones relativas al presupuesto se ha limitado al uso simbólico16 debido a la falta de
16 Aunque el “uso simbólico” de las evaluaciones se describe detalladamente más adelante, éste se refiere a la información de desempeño que se utiliza únicamente para el apoyo político y la legitimidad de la acción gubernamental.
10 de 212

criterios técnicos durante el proceso de negociación y a la carencia de incentivos en el diseño del sistema de evaluación.
Para cumplir este objetivo, se han planteado dos preguntas adicionales: ¿cómo es el proceso de toma de decisiones una vez que se tienen las recomendaciones de las evaluaciones? y ¿qué efectos han generado las evaluaciones en la operación de los programas públicos y en las decisiones presupuestales?
Estas preguntas están orientadas a ofrecer una pista sobre la influencia que tienen las evaluaciones en los diferentes actores involucrados en el proceso de decisión sobre los programas sociales del gobierno federal mexicano. De nada servirían los esfuerzos y recursos invertidos en este ámbito si la información de las evaluaciones tuviera un impacto limitado para mejorar los programas y el proceso presupuestario. Sin embargo, es importante no sobredimensionar la capacidad de influencia de las evaluaciones, éstas son una herramienta de gestión que provee evidencia empírica para decisiones más informadas, no obstante no es el único factor que influye en las decisiones de política pública, su utilización no puede ni se debe limitar a un ejercicio mecánico e irreflexivo que se aplique directamente a la toma de decisiones.
En este sentido, esta tesis identificó que hay tres formas principales de utilizar los resultados de las evaluaciones. La primera responde a fines instrumentales, es decir, es un proceso orientado a afectar directamente las decisiones sobre los programas públicos. En particular, es cuando la evaluación se entiende como un instrumento de cambio para la mejora continua de los programas públicos o para influir en las decisiones presupuestales. Dentro de la decisión de mejorar la gestión del programa, se puede optar por modificaciones orientadas a corregir procesos y actividades; cambiar el tipo de apoyos que se entregan, rediseñar sustancialmente el propósito, reubicar o fusionar
11 de 212

programas e incluso, suspenderlo17. En el contexto de las decisiones presupuestales, los
tomadores de decisión pueden optar por modificar el monto de los recursos públicos,
dejarlo sin cambios o crear un nuevo programa. Por otra parte, la segunda forma de
utilizar una evaluación responde a un fin conceptual, es decir, cuando la información
generada no alcanza a vincular la evidencia empírica con decisiones inmediatas; favorece
sobre todo al aprendizaje organizacional y a la comprensión integral del programa
público. Finalmente, el tercer uso es de tipo simbólico, completamente vinculado a los
intereses y preferencias políticas o burocráticas. Sirve para movilizar apoyo, sobre todo
cuando se justifican decisiones previamente tomadas. Generalmente se asocia al uso que
lo políticos hacen de las evaluaciones y estudios técnicos para legitimar sus decisiones
ante la ciudadanía.
Para aterrizar este proceso en el contexto mexicano, la investigación propone un
modelo de toma de decisiones para describir la utilización de los resultados de las
evaluaciones a partir de un estudio de caso integrado por un conjunto de cinco
programas federales que la administración del presidente Felipe Calderón dirigió a los llamados grupos prioritarios18. El modelo intenta demostrar que el vínculo entre los
resultados de las evaluaciones y su traducción en acciones concretas no es directo, como
la literatura sobre toma de decisiones señala, en el proceso entre decisiones y acciones
17 Esta clasificación está basada en las acciones que el CONEVAL clasifica como cambios a los programas sociales a partir de la información que se compromete como Aspecto Susceptible de Mejora. Más adelante se detalla esta información. 18 Según la Evaluación Integral del Desempeño 2010-2011 del CONEVAL, la selección de los programas federales de atención a grupos prioritarios y fortalecimiento de capacidades parte del concepto definido en la Ley General de Desarrollo Social, que señala como grupos sociales en situación de vulnerabilidad a “aquellos núcleos de población y personas que por diferentes factores o la combinación de ellos, enfrentan situaciones de riesgo o discriminación que les impiden alcanzar mejores niveles de vida y, por lo tanto requieren de la atención e inversión del Gobierno para lograr su bienestar” (art. 5°). La población que atiende estos programas se integra de adultos mayores de 69 años, mujeres, jornaleros agrícolas y actores sociales que atienden diversos grupos vulnerables. Este trabajo utilizará de forma equivalente los conceptos de grupos prioritarios y grupos vulnerables.
12 de 212

existen diversos factores que intervienen. Lo que intenta este trabajo es analizar, como propone Méndez (1993), a la política pública de la evaluación en México como la variable dependiente para conocer el alcance que ésta ha tenido como efecto de otras variables. El modelo es el resultado de la evidencia empírica recogida en el tercer capítulo, y representa las dos decisiones para las que más se utilizan los resultados de las evaluaciones en México (mejora de los programas públicos y Presupuesto basado en Resultados). Asimismo, este modelo representa los factores que más afectaron a cada una de estas decisiones: los factores de tipo organizacional y los relacionados a las características de las propias de las evaluaciones afectan más cuando las decisiones se orientan por mejorar el ciclo de políticas públicas; y los factores políticos y características del diseño institucional del sistema de evaluación influyen de forma directa cuando la decisión es definir el presupuesto público. (Ver Figura 1)
Figura 1. Modelo de toma de decisiones del sistema de evaluación en México
Fuente: Elaboración propia.
13 de 212

Los grupos prioritarios, entendidos como aquellos grupos que enfrentan situaciones de riesgo o discriminación que les impide alcanzar mejores niveles de vida, reciben los siguientes cinco programas: Atención de jornaleros agrícolas (PAJA); Coinversión social (PCS); 70 y más; Apoyo a las Instancias de Mujeres en las Entidades Federativas, para implementar y ejecutar programas de prevención de la violencia contra las mujeres (PAIMEF) y el programa de Fortalecimiento a la transversalidad de la perspectiva de género (Ver Tabla 1). Del total de recursos destinados a programas sociales (456,026.9 millones de pesos), los recursos dirigidos a programas prioritarios para el año 2012 representaron el 4.38% del total, es decir, 19,987.1 millones de pesos19. La selección de los programas se basó en la clasificación que realizó CONEVAL en el año 2011 como parte de un análisis global para conocer la pertinencia de estos programas en conjunto. Dicho estudio se realizó a partir de una evaluación integral de desempeño aplicada exclusivamente a estos cinco programas y lo que buscó fue identificar de forma general complementariedades entre los programas y buenas prácticas internacionales que abonaran a la mejora de los programas en su conjunto.

Tabla 1. Composición de los programas federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades

Programa Programa de Atención a Jornaleros Agrícolas (PAJA) Programa 70 y más Programa de Coinversión Social Programa de Apoyo a las instancias de mujeres en las entidades federativas para implementar y ejecutar programas de prevención de la violencia contra las mujeres (PAIMEF) Programa de Fortalecimiento a la Transversalidad de la Perspectiva de Género
Fuente: CONEVAL, 2011.

Dependencia SEDESOL SEDESOL INDESOL INDESOL
INMUJERES

La metodología utilizada está basada en un análisis cualitativo tanto de fuentes primarias (documentos presupuestales y entrevistas semiestructuradas con evaluadores
19 Presupuesto de Egresos de la Federación 2012. 14 de 212

externos y servidores públicos de nivel operativo, directivo y un ex secretario de Estado del gobierno federal en el sexenio del Presidente Felipe Calderón Hinojosa, así como miembros del cuerpo legislativo), como de información secundaria (se centró en analizar las recomendaciones derivadas de evaluaciones, se clasificaron los cambios adoptados por los operadores de los programas20, y se realizó un monitoreo de los resultados de desempeño y su vínculo con los montos de presupuesto asignados). La principal aportación de las entrevistas radicó en que enriquecieron esta investigación con información cualitativa sobre los criterios o motivaciones para adoptar las decisiones de mejora continua de un programa público y sobre todo, las relacionadas con la asignación del gasto.
A fin de delimitar el alcance de este trabajo, es necesario precisar que el foco de análisis que se desarrolla son los procesos de toma de decisiones en el sector público en un entorno de restricciones normativas, operativas, presupuestales y burocráticas. No se trata de un análisis de la política social y distributiva del país, ni una revisión de los planteamientos y definiciones gubernamentales para entender y afrontar los problemas de pobreza y desigualdad en el territorio nacional. Tampoco se buscó evaluar el impacto neto de los programas en la política pública del gobierno federal. La investigación y revisión bibliográfica se apoya entonces en literatura especializada sobre reforma administrativa, principalmente en políticas públicas, evaluación y toma de decisiones, más que en una revisión exhaustiva o concluyente de la efectividad de las políticas sociales. En este sentido, uno de los objetivos secundarios de la investigación será discutir hasta qué punto los hallazgos de la misma son extrapolables a otros sectores o
20 En este trabajo se usará como concepto intercambiable el término operador o responsable de un programa público. Para fines prácticos, son aquellos funcionarios públicos encargados de implementar día a día el programa federal.
15 de 212

arenas de política pública. Por esa razón, se tomará como base la definición “oficial” de grupos prioritarios como criterio de demarcación útil para la selección de los casos de estudio. Lo que se pretende es conocer los efectos generados por las evaluaciones en las decisiones de los funcionarios públicos encargados de las políticas y los factores que incidieron en la toma de decisiones para realizar ajustes que permitieran la mejora del desempeño de los programas públicos y los que definieron el presupuesto de los mismos.
En este sentido, los límites de esta investigación se desarrollan en el marco de la toma de decisiones, no obstante en futuras líneas de investigación es pertinente indagar el impacto efectivo (análisis cuantitativo) que tienen las decisiones de mejora en las reglas de operación de los programas, en sus matrices de indicadores, definición de poblaciones o en sus procesos administrativos, de diseño e impacto de presupuestos. Otro tema pendiente es identificar la forma en que las evaluaciones inciden en el reacomodo de la estructura programática presupuestal (fusión entre programas, eliminación o creación de nuevos), en la conformación de los planes anuales de evaluación y en un alcance mayor, en la definición de prioridades de mediano y largo plazo de los planes nacionales de desarrollo.
La presente investigación tiene el interés por analizar los programas dirigidos a grupos prioritarios porque busca conocer los cambios que presentan los programas sociales seleccionados a partir de los resultados de las evaluaciones, y presentar el impacto de esta herramienta de gestión pública sobre la reorientación de la política social. El periodo analizado comienza en 2008, debido a que a partir de ese año se implementó un mecanismo de seguimiento a las recomendaciones adoptadas por las dependencias, y se extiende hasta finales de 2012 cuando termina el periodo de
16 de 212

gobierno del presidente Felipe Calderón. Antes de ese año, las dependencias no estaban obligadas a implementar acciones concretas para corregir la operación de un programa social, si un funcionario público así lo decidía, los hallazgos y recomendaciones sugeridas por la evaluación podían permanecer aisladas y sin influencias en las decisiones de política pública. Dado que los cambios sustantivos del marco normativo para garantizar el uso de la información se hicieron en 2008, esta investigación esperaba que los programas que conformaron el estudio tuvieran cambios que mejoraran sus procesos, focalizaran de una forma más clara su población objetivo y los bienes o servicios que ofrecían; incluso, en caso de que hubiera sido necesario también rediseñaran el propósito de su intervención. Asimismo, a partir de dichos cambios, se esperaba un vínculo en el presupuesto que reflejara el desempeño del programa.
La evidencia documentada permitió demostrar que la información sobre desempeño derivada de las evaluaciones tuvo más influencia en las decisiones de mejora de los programas seleccionados que en el objetivo de implementar el Presupuesto basado en Resultados. En otras palabras, la política de evaluación del gobierno federal ha provocado que los resultados de las evaluaciones se utilicen con fines instrumentales para las decisiones de mejora continua en los programas de tipo social pero para las decisiones de presupuesto su uso aún se limita a ser de tipo simbólico.
La razón que explica este comportamiento es porque no todos los factores señalados en la literatura afectan en el contexto mexicano. Los programas utilizaron las recomendaciones y hallazgos de las evaluaciones porque el marco normativo así los obliga, sin embargo la utilización intensiva de la evaluaciones se logra por la presencia del liderazgo y compromiso por parte del operador del programa; la capacidad organizacional, sobre todo técnica, de los operadores para asumir los cambios sugeridos
17 de 212

y traducirlos en acciones concretas; y, debido a la factibilidad de las recomendaciones, producto de ejercicios constantes de comunicación directa entre el evaluado y el evaluador que garanticen que las evaluaciones se enfoquen en elementos de interés para los responsables de los programas.
Sin embargo, para la designación del presupuesto el criterio que explicó las motivaciones que guiaron la decisión final fue de tipo político. La influencia de las prioridades del Ejecutivo y de los intereses partidistas en la Cámara de Diputados provocó que la información de desempeño pasara a un segundo plano en la negociación presupuestal. Esta situación seguirá siendo dominante mientras el diseño institucional en el que se sustentan los mecanismos que prevén la utilización de las evaluaciones en la etapa de la negociación presupuestaria no cree mayores incentivos para que esta información se utilice de forma sistemática. De hecho, el diseño institucional es un factor que afecta más a las decisiones sobre presupuesto que a las decisiones de mejorar a los programas públicos. Al final de este trabajo se sugieren algunas recomendaciones para corregir estas deficiencias.
La investigación se divide en cuatro capítulos. El capítulo uno presenta el marco teórico que describe los distintos propósitos que cumple la evaluación en el sector público; asimismo, se presentan los factores que señala la literatura influyen para utilizar los resultados de las evaluaciones en la toma de decisiones futuras y, finalmente, se analizan modelos teóricos que permiten describir la toma de decisiones en la administración pública. En el capítulo dos, se presenta el sistema de evaluación del gobierno federal mexicano, así como la forma en la participa el poder Ejecutivo en el diseño del presupuesto y la influencia del Legislativo en las políticas públicas a través de la aprobación final del gasto público. Además, se detallan las características particulares
18 de 212

de los programas que componen el caso de estudio. En un tercer capítulo, se sistematiza la información documentada y se presenta la evidencia empírica recogida principalmente a través de las entrevistas y del análisis de la información pública sobre los programas. Finalmente, en el capítulo cuatro se ofrecen respuestas a las preguntas iniciales de esta investigación a fin de proporcionar evidencia que refuerce la hipótesis sugerida. En este capítulo se ajustó el modelo de toma de decisiones presentado al inicio de este apartado a partir de la evidencia presentada en el tercer capítulo. Este modelo ajustado se presenta como una propuesta evolucionada que recoge la utilización que hacen los programas de las evaluaciones para tomar decisiones de política pública en el contexto de gestión de resultados del gobierno federal. A partir de los resultados, la sección final presenta las conclusiones y recomendaciones de políticas relevantes.
19 de 212

Capítulo 1. ¿Por qué y para qué evaluar en el sector público? Dentro de la esfera de la administración pública, la evaluación de políticas públicas es un tema de especial interés para los gobiernos. La atención que esta última ha recibido se explica porque en un entorno de restricciones presupuestarias, la evaluación, como una técnica que hace uso de métodos cualitativos y cuantitativos, permite entender los efectos positivos o negativos de un programa sobre la población beneficiada, facilita la medición del desempeño de la intervención del gobierno, contribuye al aprendizaje dentro de las organizaciones y promueve la mejora continua de los programas públicos; además, es un componente principal de la cadena de rendición de cuentas y de la legitimidad de los gobiernos, y, sobre todo, genera evidencia empírica que permite tomar decisiones de manera más informada.
El presente capítulo tiene por objeto presentar el marco teórico que explica los diferentes propósitos de la evaluación en el sector público, detallar los diversos objetivos para los que se utiliza la información generada por esta herramienta para incrementar la racionalidad de las decisiones y exponer los principales obstáculos que influyen en el uso de las evaluaciones. Para cumplir este objetivo el capítulo se organiza en tres secciones. En la primera, se presentan los usos más frecuentes que justifican la realización de ejercicios de evaluación en el sector público. En un segundo apartado, se presentará la utilidad de los resultados provistos por las evaluaciones y los factores que influyen para alcanzar el propósito de utilizar de forma instrumental esos resultados en las decisiones de gobierno. Finalmente, la última sección se concentrará en presentar distintos modelos teóricos de toma de decisión que permiten explicar el comportamiento racional del gobernante o del administrador público al momento de elegir entre las distintas opciones de políticas o programas públicos que mejor se adapten a los objetivos perseguidos. Este
20 de 212

último apartado busca aportar información que contribuya a la dimensión teórica del análisis de políticas públicas, pero también, aspira a dejar más claro para el lector el vínculo entre los propósitos de la evaluación y las decisiones en materia de políticas.
1.1. Los propósitos de la evaluación para el sector público
Puede entenderse como evaluación la “valoración sistemática de la operación o impactos de un programa o política, comparada con un conjunto de estándares explícitos o implícitos” (Weiss, 1998: 4), es decir, la evaluación incorpora un juicio valorativo basado en la evidencia que sirve como una herramienta para tomar decisiones en torno a la intervención pública. En un sentido más amplio, la evaluación sirve para determinar si los resultados que se esperaban se han cumplido y permite emitir recomendaciones para rediseñar las intervenciones gubernamentales. La evaluación no es un fin en sí mismo,
contribuye a la cadena de decisiones más informadas. El tipo de decisiones que se consideran a partir de los resultados de las
evaluaciones depende del propósito para el que se realiza la evaluación, y algunos de ellos son incompatibles con otros (Weiss, 1998)21. En el contexto del sector público, la evaluación responde a la necesidad de conocer los resultados de las acciones que implementó el Estado; en las últimas décadas, se ha convertido en una herramienta de gestión que permite medir el desempeño de la intervención del gobierno y contribuye a
la legitimidad de sus acciones. La evaluación se asume como “una práctica administrativa
21 Algunos usos de la evaluación persiguen propósitos diferentes y cuando se busca cumplir con más de dos objetivos distintos se generan lógicas incompatibles. Este supuesto lo podemos ver más claramente reflejado cuando la evaluación busca generar control que cuando se orienta por el desempeño. En el primer caso, la evaluación se enfoca en el control de insumos y el cumplimiento de la normatividad y en el segundo, lo que se busca es la orientación por resultados e impactos y requiere de mayor flexibilidad administrativa. En países con fuerte tradición legalista, como México, frecuentemente se enfrentan este tipo de incompatibilidades porque la cultura organizacional de las dependencias de gobierno, por mucho tiempo, estaba orientada al cumplimiento de la normatividad, y cualquier evaluación que se practicaba respondía frecuentemente a criterios de auditoría.
21 de 212

deseable en la gestión pública contemporánea” (Ospina, 2010) porque además, promueve procesos de aprendizaje en el entorno institucional.
Dentro de la literatura en políticas públicas, la evaluación es una de las etapas principales del ciclo de políticas, mediante la información sistemática retroalimenta continuamente cada una de las siguientes etapas. Además, permite ubicar errores de la política y en los programas públicos y facilita la comprensión de relaciones de causalidad entre el problema y la forma de solventarlo.
En el contexto de la ciencia política, además de incidir en la credibilidad de los gobernantes, “un sistema de evaluación contribuye a democratizar la gestión y a ejercer un control más racional del gasto público, fortaleciendo así la capacidad del Estado para gobernar. En este sentido, la evaluación de la gestión pública contribuye a la democratización de la sociedad y del Estado, a la consolidación de procesos de desarrollo institucional, y por tanto, al fortalecimiento de las instituciones democráticas” (Ospina, 2001: 7). Además, permite una mayor interacción entre gobernante y gobernado porque facilita una mayor participación de la sociedad para que continuamente dé seguimiento a las acciones de gobierno.
La práctica de ejercicios de evaluación depende de los objetivos que se persigan y de la decisión pendiente que deba ser resuelta. La literatura identifica al menos cinco propósitos: control y auditoría; mejora continua del desempeño de las políticas y programas públicos; transparencia y rendición de cuentas; Presupuesto basado en Resultados; y, mejora de la gestión organizacional (Weiss, 1998; González, 2010; Cejudo y Maldonado, 2011; OCDE 2009, Banco Mundial, 2005). Esta multiplicidad de propósitos provoca que una misma evaluación responda a lógicas distintas entre sus usuarios, por lo “que deben reconocerse con claridad las motivaciones técnicas y políticas que justifican
22 de 212

cierto tipo de evaluación” (González, 2010: 149). En México, todas estas motivaciones han estado presentes, dependiendo del contexto político y económico a veces unas están más presentes que otras. Sin embargo, como se explicará más adelante, las distintas lógicas detrás de estos propósitos convierten a la evaluación en una política desarticulada con estrategias en competencia y que superan los esfuerzos comunes. Veamos en qué consiste cada una:
a) La evaluación vinculada al control y auditoría22, como señala González (2010), se asocia a los supuestos del modelo tradicional de administración pública orientado por el análisis de los insumos y el cumplimiento de la norma. Sin embargo, en el marco de la Gestión para Resultados, el control se orienta por el análisis de cumplimiento de metas y no a partir del cumplimiento de reglas (García et. al., 2010). En el sector público, ante la restricción presupuestal, hay una necesidad por conocer si los recursos públicos han tenido un buen uso (OCDE, 2005) a través de mecanismos internos y externos a la organización. En un sistema presidencial como en México, los mecanismos externos se aplican frecuentemente por la entidad fiscalizadora superior del Poder Legislativo y, los mecanismos internos son aquellos implementados por las dependencias públicas que pertenecen al Poder Ejecutivo, tal es el caso de las Secretaría de la Función Pública.
b) Una segunda justificación está relacionada a la evaluación para fines de mejora continua de las políticas, “se busca determinar la relevancia y satisfacción de los objetivos, la eficiencia del desarrollo, su efectividad, impacto y sostenibilidad” (Zall y Rist, 2005: 12). La información derivada de las evaluaciones sirve para entender la teoría del
22 Entendemos como auditoría la “comprobación de la legalidad y regularidad de la utilización de los recursos, llevada a cabo por auditores independientes para determinar si las actividades y procedimientos organizativos se ajustan a las normas y criterios previamente establecidos y en qué medida” (Fondo Internacional de Desarrollo Agrícola, 2002).
23 de 212

cambio de una intervención pública23, para resolver problemas de causalidad, mejorar
los procesos de producción, identificar fallas en la gestión, problemas en los indicadores,
en la planeación estratégica o en la delimitación de la población objetivo.
La mejora del desempeño de los programas requiere que la evaluación considere cada una de las etapas del ciclo que compone al programa público24 a fin de obtener
aprendizaje continuo de éstas (Urbanos, 2012). Cuando se busca mejorar un programa
público, la evaluación orientada a resultados permite analizar el diseño del programa, las
actividades que se implementan durante el proceso, los bienes y servicios que se
entregan a la población objetivo y los impactos que éstos tienen en la población
beneficiada. El propósito es que las evaluaciones aporten la evidencia necesaria para
informar las decisiones sobre políticas. Para Rossi et. al. (2004), los actores que deberían
hacer un uso intensivo de esta información son los planeadores de los programas, los
administradores y los funcionarios públicos de mayor jerarquía, aunque en los últimos
años el usuario final también incluye a los ciudadanos.
c) La tercera motivación se relaciona con el ámbito de la transparencia y rendición de cuentas25. La evaluación, como parte de una política de rendición de cuentas,
contribuye a dos principales objetivos: al sistema de pesos y contrapesos entre el Poder
Ejecutivo y el Legislativo y, provee información pública a los ciudadanos sobre los
resultados de la acción gubernamental (González, 2010). En sistemas presidenciales, es
23 Según Gertler, et. al. (2011), la teoría del cambio permite describir las relaciones causales de una política. A partir de una lógica secuencial de la intervención pública, la teoría del cambio permite analizar las condiciones y los supuestos necesarios para conseguir los resultados deseados. 24 Para lograr este fin, existen distintos tipos de evaluaciones: diseño, procesos, resultados, impacto y de indicadores, entre las principales. 25 La rendición de cuentas, según Merino et. al. (2010), debe ser entendida como una relación de responsabilidad entre los actores que ejercen el gasto público y los actores encargados de verificar que ese gasto se ha ejercido de conformidad con las reglas. Para estos autores, la rendición de cuentas no se limita al control del presupuesto ni tampoco a la evaluación, sino contribuye a una mayor transparencia e información pública sobre la forma en que los gobiernos han utilizado los recursos que tiene disponibles.
24 de 212

posible identificar con mayor claridad la función de contrapesos que juega el poder legislativo sobre las decisiones de formulación de políticas públicas y presupuesto (Banco Mundial y Secretaría de Hacienda y Crédito Público, 2010). Además, la evaluación se convierte en una herramienta que, mediante evidencia empírica, permite convencer a los ciudadanos sobre la legitimidad democrática tanto de las instituciones, como del gobierno en turno (Urbanos, 2012).
d) Una cuarta justificación para realizar evaluaciones se vincula con el proceso presupuestario: el Presupuesto basado en Resultados (PBR). En palabras de González (2013:97) el PBR “es un subproducto de dos fenómenos o influencias. Primeramente, se deriva de las políticas de ajuste de las finanzas públicas de las décadas de 1980 y 1990 y, en segundo lugar, de las reformas administrativas gerenciales que propugnaba la Nueva Gerencia Pública (NGP) por los mismos años, y que destacaban la importancia de orientar la gestión de los gobiernos hacia resultados de valor social y no sólo hacia el cumplimiento o conformance de procesos o productos intermedios”. Este supuesto parte de las restricciones presupuestales que los gobiernos experimentan y por lo tanto, están obligados a elegir los programas que aseguren un mejor aprovechamiento de los recursos limitados. Se trata de hacer más con menos y de asignar recursos según el desempeño. La información derivada de las evaluaciones es un insumo que los gobiernos deberían usar para convencer a sus ciudadanos sobre el rendimiento productivo del gasto público. Como señalan Sterck y Scheers (2006:48) “el presupuesto puede ser considerado como un sistema heterogéneo con funciones múltiples, usuarios múltiples y formatos múltiples (Van Reeth, 2002). El reto consiste en armonizar y alinear las funciones, los procedimientos, y los formatos para crear un sistema presupuestal sostenible”.
25 de 212

Aunque los países miembros de la Organización para la Cooperación y Desarrollo Económico (OCDE) han implementado reformas administrativas encaminadas a aplicar el Presupuesto basado en Resultados26, no todos han tenido los mismos efectos, los alcances dependen de las distintas fases, los objetivos, los actores que participan, y la integración que busque cada país (Curristine, 2005). Recordemos que aunque México es miembro de la OCDE, este modelo también se ha extendido recientemente en otros países de América Latina27.
Según la OCDE (2007), existen tres tipos de funciones que cumple el Presupuesto basado en Resultados: el primero, el modelo presentacional, tiene como objetivo informar sobre el desempeño con el propósito de rendir cuentas y establecer un diálogo con el poder legislativo y la ciudadanía; el segundo modelo, presupuestación informada, busca apoyar las decisiones de asignación de recursos públicos en la información sobre el desempeño y otras variables; y, el tercero, fórmula directa para presupuestación por resultados, consiste en asignar fondos públicos basándose, exclusivamente, en la información sobre el desempeño y mediante fórmulas preestablecidas. (Tabla 2).
Para 2007, casi dos terceras partes de los países miembros de la OCDE incluían información no financiera sobre desempeño en sus documentos de presupuesto; no obstante, vincular el desempeño con el presupuesto no es una tarea fácil. Además de ser un proceso técnico, el presupuesto también es un proceso político que requiere de una negociación entre los actores involucrados. En el caso de los países con sistemas presidenciales, el poder legislativo es un aactor muy poderoso para definir la agenda y
26 Por Presupuesto basado en Resultados la OCDE entiende como una forma de presupuestación que se vincula con la asignación de recursos a resultados medibles (OCDE, 2007). 27 Aunque los ejercicios de evaluación en Chile tienen antecedentes desde la década de 1980, diversos estudios han colocado a México como el modelo a seguir en los últimos años debido a la relativa celeridad con que se ha implementado el sistema de evaluación y los mecanismos institucionales y normativos creados para asegurar un uso más intensivo y estratégico de la información de desempeño.
26 de 212

para tomar decisiones sobre las políticas y su presupuesto (Figura 2). De hecho, en sistemas democráticos, el presupuesto es un mecanismo para limitar los poderes del gobierno e involucra la negociación de preferencias de distintos actores políticos.

Tabla 2. Objetivos planteados en las reformas recientes de los países miembros de la OCDE

Año de última

País

reforma

Propósito

Australia

2006

Dotar de mayores facultades al Ministerio de Finanzas en la

administración y manejo de las revisiones

del gasto

Canadá

2005

Establecer objetivos para todas las entidades y ligar recursos, mediciones

de desempeño y resultados de todos

Dinamarca

2004-2007

los programas Fortalecer rendición de cuentas

Corea

2006

en el sector central Desarrollar planes estratégicos

Holanda

2001

actualizados cada tres años Dotar al Parlamento de mejor

Suecia Reino Unido

2001 2001, 2002, 2007

información de desempeño Ligar al gasto los objetivos de política Asignación de recursos a gastos prioritarios

Estados Unidos

2002

y facilitar planeación de los departamentos Evaluar desempeño de los programas

Fuente: González, 2013.
Además de las complejidades mencionadas, vincular decisiones sobre políticas y

presupuesto resulta difícil porque no es sencillo determinar el problema de la atribución

de una intervención pública. A veces, los programas presentan un desempeño deficiente

que no puede ser atribuible al presupuesto que reciben; el Presupuesto Basado en

Resultados tiene limitaciones para explicar la relación causal entre el programa y su

asignación presupuestaria. Al respecto, Cejudo y Maldonado (2011) señalan que

difícilmente las evaluaciones arrojan resultados contundentes sobre la orientación de los

recursos asignados a los programas, pero sí pueden identificar áreas susceptibles de

mejora de forma más específica. Además, el efecto más importante que se consigue al
27 de 212

implementar el PBR es que reduce la discrecionalidad en las decisiones y reorienta el comportamiento inercial de la distribución de recursos.

Figura 2. Posibles usos por el Congreso de la información sobre el desempeño en el ciclo presupuestal

Durante la preparación del presupuesto
Para ayudar a establecer el marco fiscal e informar sobre las negociaciones presupuestarias

Durante la aprobación del presupuesto
Para revisar y modificar las partidas en el momento de la aprobación del presupuesto

Auditorías y evaluaciones Para asegurar la
responsabilidad mediante auditorías y evaluaciones
del desempeño
Fuente: Banco Mundial, 2010.

Durante la ejecución del presupuesto
Para verificar el desempeño en los informes de ejecución
del presupuesto

En consecuencia, el Presupuesto basado en Resultados requiere de una coordinación más estrecha entre los actores involucrados; es decir, entre los funcionarios responsables de planear el presupuesto en el poder ejecutivo y los miembros del poder legislativo, como los responsables de la aprobación final del mismo.
e) Finalmente, la quinta motivación para realizar evaluaciones se relaciona con el propósito de mejorar los procesos de gestión organizacional. Este objetivo se orienta hacia la mejora de procesos de operación al interior de las organizaciones. Si los resultados de una evaluación se socializan, las probabilidades de generar aprendizaje organizacional aumentan. Como señala Ospina (2001: 8) “la evaluación del desempeño organizacional es una actividad que compete al ámbito de la función gerencial de la planeación estratégica”, en consecuencia, las metodologías y el tipo de insumos que se

28 de 212

requieren demanda un conocimiento profundo de la dinámica organizacional (González, 2010). Aunque en México se han hecho esfuerzos encaminados a evaluar a las organizaciones y a los servidores públicos éstas no han tenido la misma continuidad que la evaluación de programas públicos.
Como se explicará en el siguiente capítulo, aunque estos objetivos no son excluyentes, los ejercicios de evaluación en México de años recientes se han concentrado más en unos que en otros, principalmente hacia la mejora continua del desempeño de los programas públicos y para vincular la información técnica derivada de las evaluaciones con las decisiones de un control más racional del gasto público. El fin último del sistema de evaluación en nuestro país es alcanzar un uso intensivo y estratégico de los resultados de desempeño, sin embargo, como se podrá observar en el desarrollo de la tesis, no todo el tiempo se logra; en las decisiones de presupuesto todavía influyen más los criterios discrecionales para distribuir los recursos.
Antes de concluir este apartado, es importante señalar que el alcance de un sistema de evaluación depende de la integración y coherencia que se le otorgue a la información de desempeño en distintos niveles de análisis. A través de las evaluaciones se puede obtener información global que involucre a la política pública en su conjunto, o información desagregada que explique el valor un programa público o el desempeño de los responsables que ejecutan estos programas.
Ospina, Cunill y Zaltsman (2004) señalan que en el sector público, la evaluación del desempeño ocurre en varios niveles que involucran la integración vertical y la horizontal. La primera se refiere a la coherencia del diseño institucional, es decir a la integración de tres niveles de análisis: las políticas públicas del gobierno (nivel macro), de los programas y actividades de las dependencias (nivel meso) y, de los funcionarios
29 de 212

públicos en el sector público (nivel micro). La integración horizontal considera la coherencia del trabajo independiente de cada dependencia y el desempeño de cada una para alcanzar los objetivos de una política pública.
En teoría, el análisis por niveles macro, meso y micro permitiría planear, ejecutar y evaluar con mayor coherencia; en la práctica, los gobiernos tendrían mayor capacidad de analizar si los objetivos planteados al inicio de la gestión están alcanzando las metas propuestas; en otras palabras, permitiría contar con un panorama global de la intervención pública, y aunque los tres niveles son interdependientes, cada uno de ellos puede ser sujeto de distintos tipos de medición y ciclos de evaluación para aportar información sobre la coherencia de las acciones gubernamentales. Este trabajo se enfocará en el nivel meso, es decir, la unidad de análisis son los programas públicos del gobierno federal.
1.2. La utilización de los resultados derivados de las evaluaciones La evaluación como práctica administrativa no es una tarea fácil, involucra aspectos técnicos como las metas elegidas y el tipo de indicadores, pero también involucra los distintos intereses de los actores involucrados y el rumbo de las decisiones que éstos pretendan adoptar. Como señala Maldonado: “[h]istóricamente, la utilización de las evaluaciones para la gestión pública basada en evidencia y orientada a resultados ha sido el talón de Aquiles de los sistemas nacionales de evaluación” (en Cejudo y Maldonado, 2011:227) porque garantizar su utilización efectiva requiere de la participación y el compromiso de los distintos actores involucrados.
Las evaluaciones tienen como propósito principal ser un instrumento para el análisis de las actividades gubernamentales y servir como insumo para la toma de
30 de 212

decisiones (González, 2010). La sola existencia de los resultados de una evaluación no garantiza que sean asimilados y sobre todo, convertidos en acciones concretas que garanticen un mejor desempeño o criterios para la asignación de recursos públicos. Ninguno de los propósitos que explican los ejercicios de evaluación arriba mencionados, garantiza necesariamente que los resultados se utilicen efectivamente para la toma de decisiones. “La dificultad de emplear los resultados de las evaluaciones en la toma de decisiones se debe, principalmente, a ciertos dilemas que en general se resuelven en la arena de la negociación política u organizacional (…)” (González, 2010: 153). Por lo tanto, el reto principal de los sistemas de evaluación es asegurar una estrecha vinculación con el proceso de toma de decisiones de la política pública.
Como señalan Cejudo y Maldonado (2011), para que los hallazgos de una evaluación incidan en la mejora de una política, tienen que ser convertidos en recomendaciones factibles, y una vez incorporadas en la toma de decisiones derivarán en acciones concretas; si las acciones son pertinentes y coherentes, tendrán consecuencias positivas en la mejora de los programas. (Figura 3).
Figura 3. Ciclo de acciones de mejora

Resultados
Acciones Decisiones Producción de información y cumplimiento administrativo Recomendaciones Hallazgos

Uso instrumental

Uso conceptual

Uso simbólico

Fuente: Elaboración propia con base en Cejudo y Maldonado, 2011 y Bailey, 2008.

31 de 212

Además de los propósitos prácticos que motiva la evaluación, podemos ubicar los alcances reales de la utilización y apropiación de sus resultados. Weiss (1998) detecta cuatro distintos tipos de utilización. El primero, cumple una función instrumental que al menos debe considerar tres condiciones: 1) que los hallazgos no sean controversiales al grado de provocar riesgos y conflictos de intereses dentro de las organizaciones; 2) que los cambios recomendados sean pertinentes y relativamente de pequeña escala, y 3) que el entorno del programa sea relativamente estable sin grandes cambios de liderazgo, presupuesto, beneficiarios o tipos de apoyo públicos. A veces, señala la autora, cuando un programa está en crisis y nadie sabe cómo resolverla, entonces se acude a la información disponible en las evaluaciones.
El segundo tipo, según Weiss, es cuando su fin es conceptual. La evaluación, generalmente, tiene influencia sobre los miembros operativos del programa, y aunque los hallazgos no se utilicen de forma inmediata, pueden cambiar la comprensión de lo que representa el tipo de intervención pública, sus fortalezas y debilidades, y posibles escenarios de acción.
Un tercer uso involucra la movilización de apoyo, es decir, permite que los responsables de los programas puedan legitimar su posición respecto a los cambios necesarios. Y finalmente, el cuarto tipo de uso permite que las evaluaciones se utilicen para influenciar a otras instituciones que tienen programas similares, incluso, a comunidades de conocimiento como las redes de académicos y evaluadores, las coaliciones de apoyo, la agenda de política y, afectar las creencias comunes dentro de las instituciones. Es decir, aunque los cambios en los programas sean la última consecuencia del uso de las evaluaciones, éstas contribuyen al cúmulo de conocimiento en la formulación de políticas y programas.
32 de 212

Por su parte, Ospina (2001) señala que la utilización efectiva de la información derivada de las evaluaciones en ocasiones cumple una función más técnica, y en otras, una función de tipo político. La primera influye “para mejorar la gestión y volverla más estratégica” y la segunda, tiene efectos más participativos debido a que involucra mayor concertación entre las dependencias y actores específicos de la sociedad, como ONG´s y fundaciones, y en consecuencia, genera mayor legitimidad de la intervención pública.
En el mismo sentido que Weiss, Bailey (2008) ubica cuatro formas similares de utilizar las evaluaciones aunque con algunos matices distintos. La primera, que clasifica de tipo instrumental, se relaciona con el uso racional de las evaluaciones, es decir, cuando se usan para afectar el proceso de decisiones y para llevar a cabo cambios en los programas. Un segundo uso es el llamado conceptual, el cual se limita a los procesos de aprendizaje cognitivo y social, útiles para el conocimiento global de una política y no siempre implica decisiones inmediatas sobre el programa, ni mucho menos se logra el vínculo entre esta información y la toma de decisiones. El tercer uso, de tipo político o simbólico, está relacionado con el uso de las evaluaciones como insumos para justificar decisiones previamente tomadas y que sirven para defender intereses y preferencias políticas. Finalmente, el cuarto uso involucra la afectación de procesos, es decir, cuando los resultados de las evaluaciones sirven para cambiar formas de pensar y comportamientos tanto individuales como en la cultura organizacional.
Por su parte, Dahler-Larsen (2000) mediante un estudio empírico en municipios en Dinamarca, reveló que los ejercicios de evaluación se convierten en una herramienta de apoyo para la gestión, es decir, la utilización que los funcionarios públicos hacen de las evaluaciones se orienta a hacer ajustes a los programas existentes, y no son determinantes para explicar un conocimiento más extenso de la lógica causal del
33 de 212

programa, ni tampoco para orientar decisiones sobre la terminación de éste. Su estudio arrojó que menos del 1% de las evaluaciones influyeron para la terminación de programas, mientras que 78% contribuyeron a realizar ajustes en algunas actividades. En consecuencia, señala el autor, las evaluaciones se convirtieron en procedimientos administrativos que se rutinizan como parte del control organizacional. Bajo estas circunstancias, es entendible que los programas frecuentemente tengan ajustes en lugar de que desaparezcan.
En resumen, se puede señalar que los resultados de las evaluaciones (debilidades, hallazgos y recomendaciones) son útiles dependiendo del objetivo que se quiere alcanzar con la información que aportan. Para efectos de este trabajo sólo se considerarán: el fin instrumental, que involucra decisiones orientadas a reformular los programas públicos o informar las asignaciones presupuestarias; el conceptual, que permite el aprendizaje organizacional y no representa un uso intensivo para la toma de decisiones futuras, y el fin simbólico, que permite el apoyo político y la legitimidad para la acción gubernamental.
Sin embargo, para suponer que los hallazgos y las recomendaciones son utilizados, se necesitan condiciones favorables para que los ejercicios de evaluación no se conviertan en un simple trámite burocrático. Lo que se busca, sobre todo cuando se invierten tantos recursos en la política de evaluación, es que cumplan su papel como insumo técnico para la toma de decisiones en distintos ámbitos del sector público.
Se esperaría que los resultados de las evaluaciones fueran evidencia suficiente para la toma de decisiones en política pública. Este propósito ha sido estudiado en algunas investigaciones que buscan explicar la forma en que la evidencia empírica se utiliza por los tomadores de decisión (Weiss, 1982; Julnes, et.al. 2001). Recordemos que
34 de 212

este trabajo se enfocará en conocer el alcance real que tienen las evaluaciones cuando se utilizan sus resultados para informar las decisiones de los distintos actores involucrados. Si la teoría señala que la evaluación es una herramienta para incrementar la racionalidad de las decisiones entonces, desde el punto de vista instrumental, es posible identificar y diferenciar aquellos programas que funcionan de aquéllos cuyo desempeño requiere cambios o en el último de los casos, su desaparición. Es decir, a partir de la evidencia empírica se pueden sustentar decisiones más informadas de políticas. El uso inteligente de los resultados de estudios científicos y de la evaluación misma es la base de lo que se conoce como políticas basadas en evidencia.
Desde el punto de vista de la toma de decisiones, las políticas basadas en evidencia contribuyen a sustentar las acciones y decisiones públicas en un marco racional y con respaldo en evidencia científica. Para Chelimsky (1983), la elaboración de las políticas debería estar en función de la calidad de la evidencia acumulada que apoye el cambio y el conocimiento general sobre la experiencia y resultado de esfuerzos similares que se llevaron a cabo en el pasado. Las políticas basadas en evidencia se entienden como “un tipo de política pública basada en investigación, que aplica procedimientos rigurosos y sistemáticos para la recolección de datos y se preocupa por la transformación de éstos en conocimiento formal de carácter utilizable para la toma de decisiones” (Bracho, 2010: 307). Esta retroalimentación entre la investigación científica y las políticas públicas requiere de una demanda constante de información; sin embargo, cuando no se dispone de ésta, entonces la evaluación de las políticas públicas se convierte en una herramienta esencial para generar la evidencia empírica (Bracho, 2010).
No obstante, en política pública el vínculo entre información y decisiones no es lineal, en otras palabras, no hay una apropiación automática e irreflexiva de los
35 de 212

resultados de evaluación por parte del tomador de decisiones. Éste es un debate que por muchos años ha ocupado un lugar central entre la comunidad científica y los políticos: la primera, señala que sus estudios no se aprovechan de forma intensiva para mejorar la política pública y el conocimiento científico, y los segundos expresan que en el ámbito académico permea falta de entendimiento sobre la “realidad” que afecta al sector público.
En la esfera del sector público, la toma de decisiones está influida por distintos factores, “lo procedente sería encontrar políticas estrictamente racionales, pero susceptibles de factibilidad administrativa y viabilidad política […] Son precisamente las restricciones que pesan en la elección de las políticas públicas las que ocasionan que se valore en el análisis de políticas la factibilidad más que la optimalidad” (Aguilar, 1996:39).
Primero, debe existir una decisión pendiente que requiera de investigación e información que arroje hallazgos aplicables de forma directa al problema (Weiss, 1979). Las decisiones pueden ser respecto a correcciones de los programas en proceso; para continuar, expandir, disminuir recursos o abandonar la intervención pública; para probar un nuevo programa; escoger la mejor de las alternativas de programas similares o decidir si un programa debe seguir recibiendo presupuesto. De todas estas alternativas, la decisión que menos ocurre es la relacionada con la desaparición de un programa público. Aun cuando las recomendaciones de una evaluación demuestren el desempeño limitado de un programa, el uso de la información generalmente se orientará por “parchar” o intentarlo nuevamente. Los actores esperan que la evaluación arroje recomendaciones para el cambio constructivo (Weiss, 1998). Cualquiera que sea el hallazgo, se espera que los resultados clarifiquen el problema y reduzcan la incertidumbre al momento de tomar una decisión.
36 de 212

Cuando la investigación ha sido solicitada por el gobierno, señala Weiss, las recomendaciones derivadas de la investigación tienen mayor probabilidad de reorientar los planes, programas y políticas. Sin embargo, como reconoce la autora, la expectativa de utilizar los hallazgos directamente en la definición de decisiones es muy optimista. Los actores que utilizan la evaluación para propósitos específicos no basan sus decisiones solamente en los resultados que ésta provee. Los hallazgos de las evaluaciones por sí solos raramente determinan una decisión inmediata, los diseñadores de políticas y los administradores de programas tienen que tomar en cuenta otras consideraciones (Weiss, 1998). Factores relacionados con los intereses de los actores, posiciones ideológicas, experiencias acumuladas, fuentes de información distintas a la evaluación y un subconjunto de temas involucrados relacionados con la reacción del electorado, el presupuesto y los efectos del programa sobre una población determinada, influyen en la decisión final del tomador de decisiones. Estos factores pueden ser identificados en lo que Weiss clasifica como las “cuatro i”: ideología, intereses, información y la institución. Sobre esta última variable, la autora señala que debido a que la organización cuenta con historia, cultura y un conjunto de procedimientos de operación, las decisiones se ven limitadas por el contexto institucional. “Los hallazgos de una evaluación están entremezclados con la experiencia práctica, la experiencia política y el compromiso ideológico, y la mezcla de éstas cristaliza en una acción cuando las oportunidades políticas se abren” (Weiss, 1998).
En un estudio empírico sobre los factores que influyen para la toma de decisiones estratégicas en las empresas, Papadakis et. al. (1998), encontraron que las características específicas de la decisión, entendidas como magnitud del impacto percibido, la frecuencia de la decisión, la incertidumbre y el componente de crisis, tienen la influencia
37 de 212

más importante en el proceso de elaboración de la decisión estratégica; “los tomadores de decisión actúan más racionalmente cuando las decisiones implican consecuencias importantes […] por ejemplo, existe evidencia de que si una decisión es percibida como una crisis se tomarán acciones distintas que si fuera percibida como una oportunidad”.
Por otra parte, Weiss y Bucuvalas (1980) realizaron un estudio empírico aplicado a tomadores de decisiones en el ámbito de la salud mental. El estudio reveló que los tomadores de decisión consideran tres marcos de referencia para considerar los resultados de una investigación en ciencias sociales: la primera, involucra la relevancia del estudio para la esfera de responsabilidad del que la analiza; la segunda, es la confianza que genera el estudio, y la tercera, el tipo de prospectiva que provee. En los dos últimos marcos de referencia, los tomadores de decisión realizan dos pruebas para evaluar una investigación en ciencias sociales. Una implica una prueba de confianza que involucra la validez de los resultados y el grado en que los hallazgos de la investigación coinciden con su conocimiento y experiencia previa. La otra, prueba de utilidad, se refiere a las recomendaciones prácticas que se puedan aplicar y a las propuestas que aportan nuevas perspectivas y orientaciones sobre el problema. Sin embargo, los resultados del estudio revelaron que cuando los resultados de una investigación coinciden con el conocimiento previo del tomador de decisiones, la calidad de la investigación es menos relevante que cuando los resultados revelan hallazgos inesperados o contra intuitivos. Además, las recomendaciones de una investigación serán más utilizadas cuando señalan poca crítica y reorientación de las políticas implementadas que cuando la presión por grandes cambios es mucho mayor.
En las decisiones del gasto, la demanda de los resultados de las evaluaciones debería aumentar porque es un proceso que requiere de mayor información y
38 de 212

racionalidad; sin embargo, como señala Wiesner (2000), en este rubro existen problemas para integrar la información de desempeño a las decisiones de presupuesto. Para este autor, el primer problema se relaciona con las características institucionales y presupuestarias que involucran el gasto público, es decir, debido a que las transferencias se realizan con un destino específico desde el gobierno central, no se toman en cuenta los resultados de las evaluaciones debido a la inflexibilidad del gasto. En otras palabras, son recursos que desde el principio consideran metas de gasto independientemente de los resultados logrados, por lo tanto, “si los resultados de las evaluaciones no logran afectar los procesos de asignación presupuestaria, será muy difícil desarrollar la demanda real de evaluación”.
El segundo conjunto de problemas involucra las limitaciones de economía política. Por una parte, señala el autor, el gasto social es mucho más complejo en términos técnicos e institucionales, que aquél que se destina a construir infraestructura; por otra, en el sector social se presenta el fenómeno de “determinación endógena de las políticas”, es decir, que los grupos organizados influyen en el diseño de las políticas y logran beneficios y privilegios especiales no relacionados con los resultados efectivamente logrados. Además, señala, en los sectores de salud y educación hay “problemas de monopolio de oferta y competencia” que obstaculizan la aplicación real de las evaluaciones.
El tercer problema, señala Wiesner, se refiere a los obstáculos que provienen de la rápida expansión del gasto agregado en el sector público, lo cual provoca que los agentes económicos y políticos no consideren necesario que “las evaluaciones tengan resultado positivo para obtener parte de ese creciente gasto público” ya que de lo contrario, si primero se hubieran aplicado evaluaciones no “se habría dado un
39 de 212

crecimiento rápido del gasto y […] el gasto habría sido de mejor calidad y más sostenible”.
Además, otros factores también se relacionan con la disponibilidad y la calidad de la información (Urbanos, 2012; Moynihan et. al., 2010; Aguilar, 1996; Weiss, 1982; Bailey, 2008; Cejudo y Maldonado, 2011; Arellano, et. al., 2012a; González, 2010; Wiesner, 2000; Langley, et. al., 1995). En particular, Bailey (2008) menciona que las características de las evaluaciones (relevancia de sus resultados, credibilidad, oportunidad temporal, calidad de las recomendaciones y capacidad del evaluador para comunicar los resultados) son un factor determinante. Respecto al tema de las disponibilidad de la información, González (2010) señala que hay ocasiones en las que los indicadores que seleccionaron los programas no son los más pertinentes para medir resultados, ya sea porque no existe información confiable para afinar las mediciones o porque, como se mencionó anteriormente, es difícil aislar los factores contextuales que están alrededor del programa para atribuir la incidencia real de éste en el problema identificado. Dicho de otra manera, “cuando es necesario elegir entre las cosas que pueden medirse y aquellas que son importantes” (González, 2010:154) se crean problemas metodológicos y de confiabilidad en la información.
Factores que influyen en la utilización de las evaluaciones A partir de la revisión de la literatura se puede observar que hay muchos factores
que intervienen en la utilización efectiva de las evaluaciones, sin embargo, a fin de tener más claro aquellos que más influyen se clasificaron en dos grandes grupos: los que están relacionados con la demanda y aquéllos que afectan al ámbito de la oferta. Dentro de la demanda se encuentran los factores relacionados con la organización, en particular, el
40 de 212

compromiso y el liderazgo de los actores para apropiarse de los hallazgos y la capacidad real para internalizar los cambios sugeridos. En esta misma dimensión de la demanda se ubican los factores políticos: los funcionarios públicos, sobre todo los políticos más que los operadores de programas, recurren al uso de los resultados de la evaluación para apoyar sus intereses particulares y de grupo.
Por el lado de la oferta, podemos colocar a las características propias de la evaluación, en particular la factibilidad de las recomendaciones y la oportunidad con que se tienen los resultados para las decisiones futuras. En este ámbito también se encuentra la accesibilidad a los resultados de las evaluaciones. Si una determinada evaluación se queda solamente en manos de ciertos actores y no se sociabilizan sus resultados, la capacidad de influir en las decisiones es limitada, sobre todo si lo que se busca es hacer un uso intensivo y estratégico del insumo.
Por último, y de manera central, el diseño institucional de un sistema de evaluación también afecta a las esferas de la oferta y demanda, sobre todo porque éste puede generar incentivos erróneos y distraer los esfuerzos comunes.
Antes de pasar a describir cada factor, o variable independiente, es importante mencionar que la relación entre oferta y demanda se retroalimenta mutuamente. Los problemas que presenta la utilización de los resultados de la evaluación deben analizarse de forma integral.
Factores organizacionales No debemos entender a las organizaciones como entes monolíticos que sólo buscan cumplir objetivos formales y preestablecidos; que siguen una cadena lineal de formulación del problema, implementación de acciones gubernamentales y evaluación
41 de 212

de políticas públicas. El espacio organizacional es dinámico, involucra objetivos diversos que son interpretados por actores con intereses políticos diferentes, con limitadas capacidades y recursos y, que ejecutan políticas sujetas a reglas formales e informales (Arellano, 2010). Si partimos de este reconocimiento será más fácil entender los factores organizacionales que inciden en la utilización de las evaluaciones.
La finalidad de contar con información derivada de las evaluaciones es mejorar el desempeño de un programa o determinar el monto de los recursos que recibirá anualmente. Sin embargo, el punto principal de hacer evaluaciones no solamente se limita a generar información sistemática y continua, su éxito depende de la manera en que esta información se utiliza por los actores que toman decisiones. Cualquier intento por analizar el papel de la organización en un proceso evaluativo siempre será parcial si no se considera el comportamiento, las motivaciones y los valores de sus agentes. En este sentido, una característica principal para garantizar el uso de las evaluaciones es el compromiso y liderazgo de los actores responsables de la operación de programas públicos para alinear la cultura organizacional con los objetivos de las administraciones orientadas a resultados y buen desempeño28.
El liderazgo puede estar presente en tres dimensiones. Primero, en la forma que el líder del equipo estimula intelectualmente a su equipo para innovar en sus actividades cotidianas; segundo, la imagen del líder como un modelo de autorreferencia para el equipo y, tercero, la influencia del líder para que los agentes asuman empatía entre sus propios valores y los de la organización (Moynihan, et. al., 2011).
28 En el campo de lo empírico, Moynihan et. al. (2010) encontraron, a través de una encuesta dirigida a autoridades locales de poblaciones mayores a 50,000 habitantes en Estados Unidos, que la motivación del servicio público, el papel del liderazgo, la disponibilidad de la información, la cultura organizacional y la flexibilidad administrativa son factores que afectan la utilización efectiva de las evaluaciones en el sector público.
42 de 212

Cuando la cultura organizacional está orientada por los resultados, el liderazgo y el compromiso tienen mayor potencial para desplegarse. Depende de los incentivos positivos o negativos que se empleen para promover la utilización de la información en la toma de decisiones. Para ejemplificar esta explicación, Moynihan et.al. (2010) señalan que cuando “los administradores están en un ambiente que premia la innovación y les permite cuestionar las rutinas existentes, entonces tendrán mayor propensión a utilizar la información de desempeño. Sin embargo, si se encuentran en un ambiente que prioriza la continuidad procedimental y es adverso al riesgo, los administradores probablemente no la utilicen”. De ahí que los sistemas de información de desempeño pueden responder a dos tipos de incentivos: un uso pasivo de la información, donde los actores hacen el uso mínimo requerido para cumplir con requerimientos administrativos y creación de mediciones de desempeño, o un uso propositivo, que se refiere a la utilización efectiva para mejorar las decisiones de gestión o de asignación de recursos (Moynihan et. al., 2011).
En consecuencia, en un ambiente donde las rutinas de la organización limitan las posibilidades de transformación y establecen barreras a la innovación, la intensidad con que se utilice la información sobre el desempeño será muy limitada. Esta situación plantea que la demanda de información dentro de las organizaciones debe responder a un “proceso internalizado en la gestión de las oficinas públicas” (Cejudo y Maldonado, 2011) que identifique el uso de la medición de desempeño como una herramienta útil para el aprendizaje organizacional y no como un procedimiento administrativo rutinario que se lleva a cabo para cumplir con el control organizacional. Dicho de otro modo, para alcanzar una conexión plena entre evaluaciones y decisiones, un uso instrumental de los hallazgos y resultados, los responsables de los programas públicos deben manifestar
43 de 212

públicamente la demanda de información o “una visualización previa de las mejoras a emprender por parte de los evaluados” (González, 2013:100).
Cuando el evaluado identifica las ventajas que resultan de la evaluación se generan círculos virtuosos de aprendizaje organizacional29. El flujo continuo de información al interior de las organizaciones como producto de los sistemas de información de desempeño y en particular de los hallazgos de las evaluaciones, influye para generar rutinas de aprendizaje que contribuyen al proceso decisorio en los diferentes niveles de las organización y mitigan la pérdida de memoria institucional (Moynihan, et. al., 2009; Kusek, et.al., 2005). Cuando en la cultura organizacional las evaluaciones son ejercicios constantes, tienden a convertirse en un proceso de pruebaerror. Cuando esta rutina está asociada con el éxito, la probabilidad de que los responsables se apropien y movilicen los resultados de las evaluaciones aumenta, pero disminuye cuando se asocia con el fracaso. (Levitt et.al., 1988). Si las organizaciones descubren que la información les ayuda a resolver problemas, generarán la percepción de que es útil y tratarán de persuadir al conjunto de la organización sobre los beneficios de su uso (Feldman, et.al., 1981). El compromiso también se refleja en la capacidad y motivación para traducir las recomendaciones en acciones concretas de acuerdo a las características particulares de cada programa.
En este sentido, la capacidad institucional, el segundo factor que influye en la demanda de evaluación, se refiere a la habilidad y los recursos disponibles para instrumentar los resultados de la evaluación en los procesos internos de la mejora continua del desempeño de los programas. Aunque esta investigación no busca medir la
29 Entendamos aprendizaje organizacional como “un conjunto de acciones (adquisición de conocimiento, distribución de la información, interpretación de la información y memoria organizacional) dentro de la organización que intencionalmente o no influyen positivamente en el cambio organizacional” (Templeton, et.al., 2002: 189).
44 de 212

capacidad institucional de los actores involucrados en la toma de decisiones, si explorará cómo influye para que las evaluaciones se utilicen en la mejora de programas públicos y para asignar el gasto.
La capacidad institucional es un concepto multidimensional que está compuesto por diversos elementos que permiten la coordinación de los actores involucrados dentro de una organización (Arellano, et. al., 2012a). Sin embargo, aunque no existe un consenso en la literatura sobre los elementos básicos que integran este concepto (para mayor detalle véase White, et. al., 2005), se entiende que la capacidad institucional está definida por una variedad de habilidades y recursos (humanos, tecnológicos y financieros) para el logro de objetivos y el mejoramiento del desempeño. La capacidad institucional puede entenderse como “la habilidad de una agencia para orientar sus recursos y alcanzar los objetivos organizacionales” (Rowe, Jacobs y Grant, 1999 citado en White, et. al., 2005: 7).
La capacidad institucional está delineada por el marco institucional que delimita las facultades y competencias de las organizaciones y determina en gran medida el tipo de relaciones horizontales y verticales con otros organismos. También, involucra elementos técnicos y financieros que permiten la operación administrativa al interior de la organización y en sus relaciones interinstitucionales. Dicho de otro modo, la capacidad institucional no sólo depende de la buena voluntad de los actores para realizar los cambios sugeridos por los hallazgos, sino involucra su capacidad de decisión y la posición jerárquica que cada actor ocupa; implica también los recursos (humanos, técnicos y financieros) necesarios para implementar los cambios propuestos en las evaluaciones (Cejudo y Maldonado, 2011) pero, de manera central, requiere una mayor capacidad técnica para asimilar e interpretar flujos constantes de información que alimentan los
45 de 212

sistemas de información de desempeño. En materia de evaluación, esta capacidad técnica también se refleja en la comprensión de ciertos conceptos, claridad para identificar las prioridades del programa o la selección pertinente de unidades de medición para la determinación de metas, entre otros. La construcción de capacidades implica el aprendizaje de un nuevo lenguaje administrativo y sobre todo, claridad de los propósitos para los que se practica la evaluación. La dimensión técnica de la capacidad institucional involucra un papel muy activo del funcionario público debido a que prácticamente lo obliga a un monitoreo individualizado y constante de la información derivada de las evaluaciones (Arellano, et. al., 2012a).
De esta forma, el compromiso y la capacidad son atributos estrechamente vinculados: la receptividad de los responsables para traducir hallazgos también implica un reconocimiento de las restricciones organizacionales, sin embargo el valor distintivo está en el proceso constructivo para identificar propuestas de mejora.
Factores políticos Aunque la instrumentación racional es la manera ideal de vincular los resultados de las evaluaciones con el proceso presupuestal, existe muy poco interés en los políticos, particularmente entre los legisladores, para considerar sistemáticamente la información desempeño en el presupuesto. En muchos países el poder ejecutivo tiene la facultad de controlar la planeación del gasto público y cuando la propuesta llega al poder legislativo se le pueden hacer muy pocas modificaciones. Esta situación termina provocando que sólo las comisiones legislativas responsables de la rendición de cuentas y auditoría parezcan tener un interés explícito en la información de desempeño (Sterck y Scheers,
46 de 212

2006). En contraste, el resto de las comisiones tienen fuertes incentivos para utilizar la evaluación sólo con fines simbólicos para la movilización de apoyo.
No obstante Feldman et. al. (1981) señalan que la información se produce y comunica en un contexto de conflicto de intereses sabiendo que ésta tiene consecuencias potenciales para persuadir una decisión, no es lo mismo el peso del factor político dentro de la organización que fuera de ésta, sobre todo, cuando el propósito de la evaluación es generar información para alimentar el proceso del PBR.
Para el analista de políticas, la información de desempeño de un programa resulta valiosa en términos de eficiencia económica; su interés es medir los resultados de la intervención y el grado en que se cumplen los objetivos. En contraste, los políticos están interesados en la distribución de los productos que reciben las comunidades organizadas de ciudadanos donde tienen influencia política (Behn, 1986). Los diferentes actores pueden tener la misma información de desempeño entre sus manos pero argumentar sus decisiones de forma distinta, de ahí que las decisiones en política pública no respondan a criterios de racionalismo puro.
Los datos producidos por las evaluaciones son información que no dice nada sobre el tipo de decisiones que se deban considerar, depende de la interpretación que los actores con capacidad de tomar decisiones hagan de estos datos para construir su evidencia. Los argumentos, como señala Majone (1997), no son pruebas formales, dependen de cómo se utilizan los datos e información seleccionada. La evidencia sobre desempeño presentada por cada actor es una representación de la información seleccionada que responde a creencias, preferencias y procesos cognitivos distintos y que reflejan las interacciones políticas y de poder dentro de las organizaciones (Moynihan, et.al., 2005).
47 de 212

La interpretación de la información de desempeño derivada de las evaluaciones permite hacer explícitos los supuestos de un grupo de actores que señalen como prioridad una determinada política pública sobre otras, no obstante, es probable que un grupo distinto al que está en el poder considere como prioridades otros problemas que merezcan ser resueltos. Si los hallazgos básicos coinciden con las visiones existentes de los diseñadores de políticas y los legisladores, éstos incluirán la información entre sus consideraciones para apoyar su argumento (Lipton, 1992).
Aunque la evaluación del desempeño esté disponible entre los tomadores de decisión, en la arena de la política las interpretaciones sobre evaluación del desempeño entrarán en mayor competencia. Lo más importante es que una vez generada la información exista demanda por parte de estos actores. Los políticos usarán la información sobre las evaluaciones para apoyar u oponerse a determinadas propuestas políticas, este comportamiento se explica porque “los problemas de políticas son definidos y comunicados en términos simbólicos y la característica más importante de los símbolos es su ambigüedad. [Entonces], más que representar la información comprensivamente, dando un balance igual a todo, los actores destacarán piezas específicas de información, ofrecerán explicaciones plausibles de por qué el desempeño ocurre de esa forma y cómo puede ser mejorado” (Moynihan, et. al., 2005: 12-13).
De esta forma, los políticos tienen más incentivos para utilizar la información del desempeño para cumplir con su agenda política y beneficiar a grupos organizados. “Este uso político de la información sobre desempeño parece prevalecer en los sistemas presidencialistas con gobiernos divididos más que en los sistemas parlamentarios” (Robinson, 2007, citado en OCDE, 2009: 127). Una posible explicación a este fenómeno es que en sistemas presidenciales “la posibilidad de que en la Comisión del Congreso se
48 de 212

den discusiones detalladas, con base en la información de M&E [Monitoreo y Evaluación], dependería de su composición política, en particular de que la oposición tenga mayoría” (Ríos Hess, 2007:47). Sin embargo, Sterck y Scheers (2006) demostraron que en siete países miembros de la OCDE30, algunos con sistemas presidenciales y otros de tipo parlamentario, no existe diferencia significativa en el tipo de sistema político que explique la tendencia del desinterés general entre los legisladores para analizar la información de desempeño. Esta tendencia se observa porque el diseño y negociación del presupuesto es el reflejo de las prioridades de un gobierno, de ahí la naturaleza esencialmente política de este proceso.
Ahora bien, una vez analizados los factores que influyen por el lado de la demanda, se deben ubicar los factores que tienen más peso en la dimensión de la oferta. Se requiere, en primera instancia, que exista información factible y oportuna – características de la evaluación- y que se diseñen los mecanismos adecuados para hacer accesible los resultados y hallazgos entre los actores responsables de tomar decisiones. A continuación se explicará cada uno.
Características de las evaluaciones Como ya se mencionó anteriormente, para que un programa pueda ser objeto de evaluación primero debe existir información básica del programa (indicadores precisos, confiabilidad de las fuentes de información, disponibilidad del evaluado para entregar dicha información). Cuando este requerimiento queda solventado es necesario que el evaluador articule propuestas factibles (Cejudo y Maldonado, 2011; Majone, 1975; May, 1981; Meltsner, 1972; Aguilar, 1996).
30 Australia, Canadá, Suecia, Países Bajos, Nueva Zelanda, Reino Unido y Estados Unidos. 49 de 212

Evaluar los resultados de un programa permite generar información para determinar qué se necesita cambiar, cómo se pueden hacer dichos cambios y cómo se pueden alcanzar los resultados. Sin embargo, uno de los problemas frecuentes de las evaluaciones es que contienen recomendaciones poco viables que se limitan a ser ideas con buenas intenciones pero sin efectos en la toma de decisiones en el contexto del sector público. La literatura sobre factibilidad de una política pública señala que una solución factible “es aquélla que puede enfrentar con éxito las restricciones” del contexto (Majone, 1975: 396). De ahí que la decisión de adoptar una recomendación depende de la factibilidad de la propuesta en un marco delimitado por restricciones que van desde las motivaciones, creencias y recursos de los actores (individuos o agregados organizacionales), hasta las restricciones sociales, administrativas, institucionales, técnicas y presupuestales de la política pública.
Cualquier recomendación derivada de una evaluación deberá considerar aquellas soluciones susceptibles de implementación en el marco del contexto donde opera la organización, pues es el contexto el que determina los factores que pueden ser manipulados y modificados para implementar la recomendación propuesta (May, 1981).
Una preocupación recurrente en la literatura sobre factibilidad es la que advierte sobre la viabilidad política de una política pública (May, 1981; Meltsner, 1972; Aguilar, 1996). Al respecto, Meltsner (1972) explica que uno de los errores frecuentes del diseño de políticas, aplica por igual a las recomendaciones de una evaluación, es no considerar los aspectos políticos de la toma de decisiones, en otras palabras, los analistas y los evaluadores de políticas frecuentemente emiten recomendaciones sin tomar en cuenta las consecuencias políticas futuras de una opción de política. “Las restricciones de una decisión van más allá de la escasez de los recursos públicos, cosa que afortunadamente
50 de 212

obliga a emprender cálculos finos de asignación racional y a estimar los beneficios y retornos en determinados periodos de tiempo. Incluyen también limitaciones constitucionales y reglamentarias, condicionamientos políticos provenientes de adversas correlaciones de fuerzas o de reticencias e inercias administrativas” (Aguilar, 1996, 62). De ahí que si se pretende que una recomendación tenga utilidad, las evaluaciones deben derivar en recomendaciones factibles y no en soluciones óptimas (Majone, 1975) que dejen de lado la viabilidad administrativa y política de una intervención pública. Esto incluye que los resultados ofrezcan “una respuesta clara a los principales retos del programa […] Resaltar las insuficiencias es con frecuencia menos interesante que ofrecer diagnósticos sobre las causas y posibles soluciones” (González, 2013:100).
Ante tal problema, Bracho (2010: 310) señala que los evaluadores deberán hacer un proceso de mapeo de los stakeholders, con el objeto de “prever diferentes medidas de resultados que reflejen la diversidad de estos intereses, para hacer que la evidencia generada sea relevante y útil para los interesados”.
Por otro lado, el segundo factor que influye en la utilización de las evaluaciones en la dimensión de la oferta, es la oportunidad de las recomendaciones, es decir, que la información sobre los resultados y los hallazgos encontrados en las evaluaciones estén disponibles en las etapas de toma de decisiones, especialmente las decisiones que involucren algunos cambios para el programa o en la etapa de preparación, discusión y aprobación del presupuesto. Si las recomendaciones sobre la evaluación se reciben después del momento de la decisión, la información se vuelve un simple dato histórico, sobre todo en el proceso presupuestario (Cejudo y Maldonado, 2011; Bracho, 2010; Weiss, 1998; Kusek, et.al., 2005; Grifel, 1994).
51 de 212

La oportunidad de la información es un problema frecuente de la evidencia científica. La razón de este desfase se relaciona con que la investigación científica generalmente requiere de periodos largos que no coinciden con el tiempo de los temas relevantes para los políticos (Bracho, 2010). No obstante, como señala Weiss (1998), a veces cuando el tiempo de entrega es muy corto, se debe optar por la entrega de un reporte intermedio con los resultados que más le interesen al evaluado y sobre todo, con aquellos resultados que hasta ese momento se puedan justificar. Estos reportes incrementan la posibilidad de que los administradores preparen una respuesta en caso de que los resultados no sean los esperados.
Kusek, et.al., (2005), señalan que la oportunidad de una evaluación involucra tres elementos: frecuencia, actualidad y accesibilidad de la información para respaldar las decisiones; “el flujo continuo de datos puede, asimismo, ofrecer un cúmulo de información sobre tendencias y direcciones en el tiempo”. Sin embargo, es importante señalar que para que un reporte de monitoreo y evaluación tenga la utilidad esperada por los tomadores de decisión de alto nivel, se deberán reportar solamente los indicadores más importantes. Reportar todas las medidas de desempeño que resultan de una evaluación puede volver impráctico cualquier informe (Grifel, 1994).
Accesibilidad a los resultados de las evaluaciones Finalmente, el tercer conjunto de desafíos para la oferta se compone de los relacionados con la accesibilidad a los resultados de la evaluación. Uno de los errores frecuentes de los sistemas de evaluación es asumir que el sólo hecho de contar con evaluaciones disponibles garantiza que sus resultados se socialicen, sobre todo, que lleguen a los funcionarios que jerárquicamente ocupan los puestos más altos en la administración
52 de 212

pública e incluso, que se reciban en el poder legislativo por los congresistas encargados del presupuesto. Si las evaluaciones no llegan a los principales tomadores de decisiones, la probabilidad de utilizar criterios discrecionales para hacer cambios de políticas aumenta.
Además, no todas las recomendaciones de las evaluaciones están dirigidas a mejoras de la gestión del programa, en ocasiones se refieren a los montos presupuestales o a los mecanismos de control y vigilancia, y los responsables de reaccionar a estos hallazgos son los funcionarios en puestos directivos externos a la organización o los legisladores (Cejudo y Maldonado, 2011). Este problema está más presente en actores externos a la organización, sobre todo cuando el propósito de evaluar es generar información para nutrir el proceso presupuestario. Es más fácil monitorear la intensidad del uso estratégico de la información de desempeño que hacen los operadores de programas, que el que puedan hacer los responsables de planear y aprobar el presupuesto. Sin la presencia de mecanismos operativos que aseguren la continuidad de la cadena de información entre los distintos usuarios involucrados en la producción de políticas públicas, el desafío para la utilización efectiva de las evaluaciones es sumamente complejo.
Diseño institucional Por último, y no por eso menos importante, describiré el factor relacionado con el diseño institucional de un sistema de evaluación. El diseño institucional entendido como “la estructura y atribuciones de cada poder y orden de gobierno”, determina los actores, los tiempos y las formas de su participación. En particular, y como se explicará en los próximos capítulos, la distribución de facultades entre las dependencias encargadas del
53 de 212

sistema de evaluación y la normatividad, determinan el alcance de la política de evaluación en nuestro país.
Si el diseño institucional de un sistema de evaluación no cuenta con los incentivos correctos para promover el equilibro entre la oferta y demanda de evaluación, presentará importantes desafíos en el esfuerzo de consolidar un sistema de evaluación. Sobre todo, el diseño institucional en el ámbito de la evaluación debe aspirar a la integración de los niveles macro, meso y micro de la acción gubernamental. Esto requiere articular la multiplicidad de señales y demandas de atención dentro de la administración pública y, principalmente, conectar el sistema de evaluación con otras lógicas institucionales: rendición de cuentas, auditoría y fiscalización, control presupuestal, contabilidad gubernamental, etc. (Cejudo y Maldonado, 2011).
En este sentido, es importante considerar que el arreglo institucional que da forma al sistema de evaluación en México a nivel federal, incluye la participación de dos poderes públicos que funcionan como contrapesos: el Ejecutivo como el encargado de planear, implementar y evaluar los programas públicos de cada periodo sexenal y, el Poder Legislativo, en particular la Cámara de Diputados, encargado de hacer los contrapesos a las decisiones del Ejecutivo y en una lógica de gestión por resultados, la Cámara de Diputados es un actor fundamental para la implementación del Presupuesto basado en Resultados.
En resumen, lo que este apartado busca es presentar al lector el conjunto de factores que frecuente se mencionan en la literatura como elementos que influyen en el proceso de toma de decisiones una vez que el actor cuenta con información sobre el desempeño de las políticas y los programas públicos. El uso efectivo de las evaluaciones en el campo de las organizaciones públicas obedece a factores que se pueden clasificar
54 de 212

en dos grandes dimensiones: los que están relacionados con la demanda de la evaluación (compromiso y liderazgo del operador del programa, capacidad organizacional y factores políticos), y los que influyen en la oferta (factibilidad y oportunidad de los resultados y recomendaciones derivadas de las evaluaciones y accesibilidad a éstas). El diseño institucional es un factor que afecta ambas dimensiones, es una variable que influye dependiendo de los incentivos con los que cuente el sistema.
Ahora bien, además de los factores que influyen en la decisión, en el siguiente apartado se presentan distintos modelos que por su grado de racionalidad permiten explicar teóricamente el proceso de toma de decisiones en el sector público. Estos enfoques, desarrollados en el campo de la administración pública, buscan captar la lógica racional y el proceso interno de las organizaciones para decidir en torno a las políticas. Son un referente para analizar la toma de decisiones real que se lleva a cabo al interior de las organizaciones en el ámbito de lo público y sirven como guía para la construcción del modelo que se presenta como propuesta en esta tesis.
1.3. La decisión pública: modelos teóricos que la explican. La toma de decisiones puede ser entendida como el “proceso por el cual se evalúan las alternativas o cursos de acción para decidir sobre ellas” (Graizbord, 2011), es un intento por introducir racionalidad en la selección de una alternativa. En particular, los estudios realizados dentro del campo de la administración pública y del análisis de las políticas se orientan a conocer el comportamiento del gobernante o del administrador a la hora de tomar decisiones entre las distintas políticas o programas públicos que mejor se adapten a los objetivos perseguidos.
55 de 212

Para explorar esta dimensión existen dos formas de analizar un proceso de toma de decisiones: la teórica y la empírica. “La primera busca explicar cómo se toman las decisiones o cómo deberían tomarse pero también cuáles son los factores que deben considerarse al tomarlas. La segunda intenta aprender de las decisiones tomadas y de sus efectos, conocer cuáles han sido los resultados y qué factores empujaron al que las tomó” (Graizbord, 2011, 735).
Desde el análisis teórico, se han generado distintos modelos que intentan captar, a través de supuestos, el proceso y los factores que participan en la de toma de decisiones. El primero que describiré, el modelo de racionalidad exhaustiva, parte de los supuestos de la economía neoclásica sobre las preferencias individuales. Entiende el proceso de toma de decisiones como un resultado racional ordenado y secuencial en el que los individuos, con preferencias estables en el tiempo, eligen la opción que maximiza sus beneficios. Según este modelo, los individuos primero definen el problema, después, son capaces de establecer orden en sus preferencias y valores, cuentan con suficiente tiempo e información para analizar todas las posibilidades de solución y posibles consecuencias y, finalmente, seleccionan la opción que maximice valores y minimice costos.
Sin embargo, este modelo difícilmente lo encontramos en la realidad. Variables como el límite de tiempo, el costo de obtener información y las capacidades cognoscitivas limitadas del individuo para considerar todas las opciones posibles, limitan el poder explicativo de este modelo a escenarios reales. “Varios procesos históricos han mostrado que esta orientación, aunque genera observaciones interesantes y soluciones técnicamente sólidas, ha fallado con frecuencia al no entender la naturaleza del proceso social. Aparentemente, el enfoque de política pública no sólo debe enfrentarse a los
56 de 212

problemas de implementación: también tiene que aceptar una marcada incapacidad para dirigir los comportamientos sociales exclusivamente por vías racionales y técnicas” (Arellano, 1996: 320). El entramado político y organizacional donde se desarrolla la política pública no permite que las decisiones sean enteramente racionales. Este modelo está construido sobre la noción individual de la toma de decisiones y no considera la participación de los diferentes actores dentro de la organización. La racionalidad técnica y económica sobre la que basa sus supuestos, tiene más aplicación en el mercado privado porque las posibilidades factibles son finitas y se puede predecir el comportamiento futuro de los actores. En contraste, en el sector público, la sola presencia de distintos intereses y preferencias sobre las políticas, hace difícil predecir tendencias puramente racionales en el comportamiento de los actores. Al respecto, Bozeman (2003) señala que en un modelo racional, la eficiencia y eficacia son criterios que dominan en una decisión técnica donde hay mayor consenso sobre los fines; mientras que en un espacio político, existe gran controversia sobre los fines o al menos, sobre el orden de los fines. Sin embargo, señala, no es fácil reconocer la diferencia entre una decisión técnica y una política, “a veces las decisiones técnicas son altamente politizadas”.
El Presupuesto basado en Resultados aspira a promover decisiones instrumentales más racionales. En otras palabras, asume que los hallazgos y recomendaciones derivadas de las evaluaciones sirven como insumo para los tomadores de decisiones que, bajo criterios económicos, determinarán el gasto público del siguiente periodo. Esta forma de presupuestar busca reducir el tipo de decisiones que consideren solamente criterios discrecionales e inerciales. Sin embargo, el contexto donde se toman las decisiones presupuestales es un espacio altamente politizado y son muchos los
57 de 212

actores involucrados con diferentes intereses que buscan incrementar los recursos públicos para sus propias políticas.
Como respuesta a los límites del modelo racional exhaustivo, se desarrollaron diversos estudios que apoyaban al modelo de racionalidad limitada (Simon, 1947; Wildavsky, 1964). Este modelo asume que las preferencias y la elección de alternativas se seleccionan bajo condiciones de racionalidad limitada y restringida por factores cognitivos y emocionales de los actores que interfieren con el proceso directo de racionalidad en la toma de decisiones. De esta forma, en lugar de buscar la solución que maximice los objetivos, los individuos eligen entre las alternativas disponibles, aquella solución más “satisfactoria” que responda a criterios mínimos de desempeño.
Uno de los primeros estudiosos en demostrar este comportamiento fue Herbert Simon quien en 1947 con un estudio del proceso presupuestario en Estados Unidos, demostró que los cambios presupuestales se ajustan incrementalmente, es decir, para determinar el monto de asignación del año fiscal corriente se considera primordialmente el presupuesto aprobado del año anterior. Como señala Aguilar (1996, 49) “cualquier política a decidir en un momento dado tiene precedentes cognoscitivos, memorias y experiencias. Cuenta con un conocimiento que le permite saber cuáles acciones produjeron cuáles consecuencias en cuáles circunstancias”.
Este modelo se fue haciendo más complejo cuando se consideraron otras variables. Al respecto, Allison (1969) señala que las decisiones de los gobiernos son generalmente resultados políticos, consecuencia de presiones, compromisos, coaliciones y negociaciones entre una pluralidad de miembros que persiguen objetivos diferentes según la posición desde donde se les considera.
58 de 212

Desde esta perspectiva, Lindblom (1979) incluye la variable política para señalar que las decisiones resultan del ajuste mutuo entre un gran número de participantes y de intereses, “lo mejor que podemos hacer es considerar las decisiones como formas de resolver o de ajustar intereses”. Para este autor, los ajustes de políticas son resultado de lo que llama incrementalismo, un modelo que permite el cambio a partir de pequeños ajustes.
Si bien el individuo tiene poco control del entorno y pocas capacidades para analizar toda la información, el incrementalismo busca reducir tanto el número de alternativas, como el costo de buscar información. Al reducirse el universo de posibles opciones, el actor sólo analizará las consecuencias de un limitado número de posibilidades y considerará la información disponible sobre experiencias del pasado. La lógica detrás de este modelo es que sólo a partir de pequeños cambios, es como se puede acumular conocimiento sobre los logros o fracasos de una política y sobre todo, tener más control a fin de evitar grandes catástrofes. La política no se hace de una vez por todas, señala Lindblom, se hace y se rehace continuamente. “La elaboración de políticas es un proceso de aproximaciones sucesivas a algunos objetivos deseados que van también cambiando bajo cierta reconsideración” (Lindblom, 1959: 86).
Sin embargo, como mencionan Moynihan et.al. (2005) la falla del incrementalismo es que es un modelo que niega la utilidad de la información de desempeño y por lo tanto, su debilidad es no explorar cómo debería usarse. El incrementalismo caracteriza al presupuesto como un proceso donde participan distintos actores con diferentes puntos de vista que negocian para alcanzar un consenso. Esto explica, señala el autor, las razones por las cuales “el valor del incrementalismo sean los procesos y los consensos, no la asignación eficiente o el desempeño”.
59 de 212

Como se ha podido observar, los modelos presentados hasta este momento se enfocan en la maximización, satisfacción y el compromiso entre los actores, sin embargo, una aproximación distinta explica que las decisiones no son el resultado de aproximaciones racionales o incrementales, sino de una combinación de múltiples factores contingentes. Este modelo conocido como bote de basura, propuesto por Cohen, March y Olsen (1972), reconoce que las organizaciones se caracterizan por una variedad de preferencias y objetivos difusos; sin tecnologías claras, que limitan a las organizaciones a operar con procedimientos de prueba y error; y la participación de los actores en los temas de la organización es inconstante. De esta forma, la decisión es el resultado de una combinación de problemas, soluciones, participantes y oportunidades de elección que coinciden en un determinado periodo y no necesariamente responde a un proceso bien definido para la solución del problema. En este modelo, los actores no están buscando resolver problemas, sólo es un momento en el tiempo donde se manifiesta un problema y existen soluciones disponibles para solventarlo. Solamente cuando los problemas, las soluciones y los participantes coinciden en un momento específico se puede tomar una decisión. Para estos autores, este modelo permite resolver problemas aun cuando “las organizaciones estén plagadas de objetivos ambiguos y conflicto, con problemas pobremente entendidos que no se apegan al sistema, con un contexto variable y con tomadores de decisión que tienen otras cosas en mente” (March y Olsen, 1972, 16).
Para este modelo, las decisiones sobre el presupuesto se explican como resultado de la coincidencia casual más que de decisiones racionales, el presupuesto presente no tiene relación alguna con el de años anteriores ni tampoco, con los presupuestos de los siguientes años. Todas las decisiones son resultado de la probabilidad. (Reddick, 2002).
60 de 212

Si ordenamos los modelos por su grado de racionalidad en una línea continua, el modelo racional exhaustivo estaría ubicado en un extremo y el modelo del bote de basura en el otro, mientras que el incrementalismo se ubicaría en medio de estos dos (Reddick, 2002). La toma de decisiones responde a distintas racionalidades dependiendo del tipo de decisión, no es lo mismo el grado de influencia que tienen los resultados de la evaluación sobre un actor técnico que sobre uno político.
La decisión pública está permeada de distintos factores que la vuelven compleja. Las decisiones en política pública no sólo responden a criterios enteramente racionales, económicos y técnicos; están definidas por objetivos difusos, información incompleta, tiempo y recursos escasos. Sobre todo, la decisión pública es resultado de una combinación de variables como los límites legales, organizacionales y administrativos del sector público que la vuelven más compleja si a ésta se suman los intereses, precedentes cognoscitivos y experiencias previas de los actores involucrados31.
Además, la decisión pública siempre considera elementos técnicos y políticos. Esta combinación de factores provoca que el cambio en política pública coincida más con la lógica del modelo incrementalista. La lógica incremental reduce el riesgo de errores potenciales, permite el cambio paulatino y ofrece mayor certidumbre a los actores participantes. Es verdad que el ajuste incremental de la política pública puede verse como un obstáculo para reformas administrativas profundas sin embargo, como se señaló en páginas anteriores, en decisiones de políticas existe una tendencia de aversión al riesgo que opta por el ajuste pausado en los cambios.
31 “(…) no resulta difícil admitir que los políticos expresan básicamente una racionalidad que tiende a maximizar su consenso electoral y por ende a prolongar e incrementar su poder. Los burócratas tenderían a maximizar los recursos financieros y humanos a su disposición” (Subirats, 1992: 83).
61 de 212

Aunque el propósito de la evaluación es convertirse en un insumo que aspire a fortalecer la racionalidad económica, no debemos ser ingenuos para considerar que en política pública, sobre todo en el proceso presupuestario, no intervienen ponderaciones políticas. Como se ha intentado enfatizar en el desarrollo de la tesis, la gestión por resultados y los elementos que la acompañan (información de desempeño, evaluación, mejora continua, presupuestos por resultados) intentan, como propósito central, disminuir los criterios discrecionales que explican las motivaciones que tiene un gobierno para distribuir de cierta manera los recursos públicos.
62 de 212

Capítulo 2. El sistema de evaluación en México y descripción del conjunto de programas federales dirigidos a Grupos Vulnerables.
Una vez que se han repasado las aportaciones teóricas relevantes, el objetivo de este capítulo es describir la forma en que se articuló el sistema de evaluación en México y una presentación breve del conjunto de programas que servirán para el caso de estudio. Este capítulo se dividirá en dos secciones. La primera, describirá el entramado institucional y normativo del sistema de evaluación en México. Se explicará, por una parte, el diseño institucional del sistema de evaluación en el marco del Ejecutivo Federal. Por otra parte, se desarrollará el diseño institucional del proceso presupuestario, que involucra tanto al Poder Ejecutivo como al Legislativo, para explicar la implementación del Presupuesto basado en Resultados. La segunda sección, se centrará en explicar los cinco programas federales que conforman el caso de estudio y se detallarán las características de la población objetivo que integran a los grupos prioritarios, los apoyos que se otorgan y, un breve resumen sobre las evaluaciones que se les han practicado.
La evaluación de políticas públicas en México es un tema que ha tomado reciente impulso debido a que los gobiernos de los últimos años han vinculado la evaluación de los programas con el cumplimiento de metas del gasto público. La relación entre la evaluación del desempeño y el tema de presupuesto resulta relevante si consideramos que en un entorno de recursos escasos, la información sobre desempeño permite legitimar los esfuerzos gubernamentales a partir de sus resultados en política pública. Como otros países, en México se busca que los resultados de las evaluaciones tengan influencia en las decisiones sobre la asignación de los recursos y la gestión de los programas públicos.
63 de 212

Aunque la evaluación de programas públicos en nuestro país se ha venido realizando desde hace más de cuarenta años, ésta se caracterizó por ejercicios dispersos que carecían de una lógica sistemática de medición del desempeño. Sólo después de los cambios importantes en el sistema político mexicano en la segunda mitad de la década de 1990, el gobierno federal adoptó nuevas leyes y creó instituciones destinadas a responder a la creciente demanda de transparencia y rendición de cuentas mediante evaluaciones externas, acceso público a la información y la creación de una auditoría superior que dependiera del Poder Legislativo (Rubio, 2011).
Debido a que la información que se deriva de la evaluación permite mejorar tanto la operación de programas como las decisiones que se toman alrededor de una intervención pública, la evaluación se ha convertido en una herramienta de información no sólo para investigadores sociales, también ha sido objeto de análisis para diseñadores de políticas públicas, funcionarios de los poderes públicos, operadores de los programas y recientemente, para los ciudadanos.
2.1. El sistema de evaluación en el ámbito del Poder Ejecutivo El desarrollo de este apartado se dividirá en dos secciones. La primera, el diseño
de la medición del desempeño, se entenderá como la construcción de todo el entramado técnico y normativo desarrollado por la Administración Pública Federal para generar los insumos de información sobre los programas públicos y posterior medición del desempeño. La segunda etapa relacionada con la implementación, involucra los mecanismos instrumentales que facilitan la utilización de las evaluaciones por parte de los tomadores de decisiones que se encuentran en el Poder Ejecutivo y Legislativo.
64 de 212

Aunque la evaluación no es una práctica nueva en México, en la actualidad ésta se orienta por un enfoque distinto del que se tenía en los primeros ejercicios32. Como ya se mencionó en párrafos anteriores, los ejercicios de evaluación que se practican actualmente buscan proveer información sobre el cumplimiento de metas de los programas públicos dentro del ciclo presupuestario33. Sin embargo, como se explicará más adelante, en la actualidad existe un problema de lógicas contrapuestas que ha provocado que cada esfuerzo de evaluación presente tensiones para su implementación.
Los primeros ejercicios de evaluación, llevados a cabo en las décadas de 1960 y 1970, se concentraban en las empresas paraestatales y algunos otros programas dispersos. Lo que se buscaba sobre todo, era el control legal y administrativo de las dependencias del gobierno federal (González, 2010). En la década de 1980, como consecuencia de las crisis fiscales que se vivieron en diversos países, incluyendo la crisis financiera en México, la evaluación se implementó como un instrumento que respondió a la racionalidad del gasto. En particular, durante el gobierno del presidente Miguel de la Madrid, la evaluación formó parte de la política orientada a la “renovación moral” de la administración pública como una respuesta del gobierno a los diversos actos de corrupción que se cometieron durante los sexenios anteriores en el sector público y que afectaron la imagen del gobierno federal. Posteriormente en los sexenios de Carlos Salinas de Gortari y Ernesto Zedillo, las reformas administrativas aceleraron el desarrollo incipiente de indicadores medibles en las dependencias gubernamentales y se inició con el cambio paulatino de la estructura programática del presupuesto. En esta década es
32 Para una mayor profundización sobre los antecedentes de la evaluación en México, ver González Gómez, Javier, “La evaluación de la actividad gubernamental: premisas básicas y algunas anotaciones sobre la experiencia mexicana” en José Luis Méndez (coord.), Los grandes problemas de México, Tomo XIII Políticas Públicas, México, El Colegio de México, 2010, pp. 143-145. 33 El ciclo presupuestario involucra las etapas de planeación, programación, presupuestación, ejercicio, control, seguimiento, evaluación y rendición de cuentas del gasto público.
65 de 212

posible identificar ejercicios aislados de evaluación34, aunque las justificaciones seguían siendo el control y la fiscalización también se hicieron esfuerzos para la modernización administrativa. Como señala Rubio (2011), “El SyE [seguimiento y evaluación], durante la primera etapa, careció de incentivos y mecanismos institucionales para asegurar el uso de las conclusiones. Se realizaron más de 500 evaluaciones externas en este período, pero, en la práctica, se utilizó muy poca de esa información”.
El tema comenzó a tomar mayor relevancia una vez que en 1997 el Partido Revolucionario Institucional (PRI), el partido en el gobierno, perdió la mayoría en la Cámara de Diputados. A partir de la LVII Legislatura en 1997, se despertó el interés de los partidos opositores por hacer del Poder Legislativo un verdadero actor de contrapeso a las decisiones del Ejecutivo. En este sentido, un primer esfuerzo de los legisladores se orientó por incluir en el Presupuesto de Egresos de la Federación para el ejercicio fiscal del año 2000, un mandato para que los programas federales que contaran con Reglas de Operación se evaluaran35. Cabe aclarar que la mayoría de los programas que cumplían con este requisito eran aquellos de tipo social.
A partir del periodo del presidente Vicente Fox, la evaluación se preocupó por alcanzar los supuestos de la Nueva Gestión Pública. Ya no sólo se buscaba el control y la auditoría, se intentó promover la lógica del buen gobierno: mejora del desempeño de los programas públicos y de la gestión, aunque de forma limitada. Para tal objetivo, se creó el Sistema de Metas Presidenciales en el cual los titulares de cada dependencia y entidad se comprometían con el presidente a cumplir las metas que ellos mismos establecían;
34 Durante el gobierno del ex presidente Carlos Salinas de Gortari se realizaron evaluaciones al Programa Nacional de Solidaridad (PRONASOL) y posteriormente, en el gobierno de Ernesto Zedillo, al Programa de Educación Salud y Alimentación (PROGRESA), hoy Oportunidades. 35 Los programas que debían sujetarse a Reglas de Operación estaban en las Secretarías de Hacienda y Crédito Público; Agricultura, Ganadería y Desarrollo Social; Comercio y Fomento Industrial; Educación Pública; Salud; Trabajo y Previsión Social; Medio Ambiente, Recursos Naturales y Pesca; Desarrollo Social y programas especiales como el Programa de Educación, Salud y Alimentación (Progresa).
66 de 212

además, se cambió el nombre de la entonces Secretaría de la Contraloría y Desarrollo Administrativo (SECODAM) por el de Secretaría de la Función Pública en el año 200336. Dentro de esta última, se creó la Subsecretaría de la Función Pública, entre cuyas principales responsabilidades fueron desarrollar el Servicio Profesional de Carrera para la Administración Pública Federal cuyo objetivo fue evitar la discrecionalidad en el nombramiento de funcionarios públicos. Este programa formó parte de la estrategia de mejorar la gestión de las dependencias públicas37 (para mayor información sobre la negociación de esta reforma en el caso mexicano ver Méndez, 2010).
Uno de los avances más importantes en materia de evaluación fue la publicación, en el año 2004, de la Ley General de Desarrollo Social (LGDS). Esta ley provocó modificaciones tanto normativas como institucionales que aceleraron el desarrollo de un sistema de evaluación orientado al uso de los resultados. Fue la primera piedra que hizo obligatoria y sistemática la evaluación a los programas públicos a fin de “corregirlos, modificarlos, adicionarlos, reorientarlos o suspenderlos total o parcialmente”. Además, por mandato de esta legislación, se creó en el año 2005 el Consejo Nacional de Evaluación de la Política de Desarrollo Social (CONEVAL), institución a la que se le asignó en el área de la política social, la tarea de “normar y coordinar la evaluación de las Políticas y Programas de Desarrollo Social, que ejecuten las dependencias públicas, y establecer los lineamientos y criterios para la definición, identificación y medición de la
36 Aunque el 2 de enero de 2013 se emitió en el Diario Oficial de la Federación una reforma para desaparecer de la Administración Pública a la Secretaría de la Función Pública, ésta continuará con sus funciones hasta que la Comisión Nacional Anticorrupción se constituya formalmente. 37 Aunque no es tema de esta investigación, es pertinente señalar que en cuanto a la evaluación de las organizaciones públicas, el gobierno federal hizo esfuerzos durante la administración del Presidente Felipe Calderón para desarrollar capacidades gerenciales dentro de las dependencias mediante el Programa de Mejora de la Gestión de la Secretaría de la Función Pública. Sin embargo, debido a que el programa no considera incentivos negativos que “castiguen” el mal desempeño no ha alcanzado los objetivos originales por los que se creó.
67 de 212

pobreza”38. La ley señala que las evaluaciones pueden realizarse por el CONEVAL o, cuando así se decida, por evaluadores externos39. En el ámbito de la política social, el CONEVAL ha desarrollado metodologías, estudios sobre la pobreza en nuestro país y ha coordinado diversas evaluaciones de los programas y acciones federales40.
Resulta interesante comentar que después de 1997, la Ley General de Desarrollo Social fue la primera iniciativa que pasó por unanimidad en el Congreso, sobre todo, fue una ley que durante su negociación reflejó los distintos intereses de los principales partidos políticos en la Cámara de Diputados: el interés de que las evaluaciones se realizaran cada año y por actores externos (Partido Acción Nacional); la medición periódica de la pobreza multidimensional (Partido de la Revolución Democrática), y la publicidad de los padrones de beneficiarios (Partido Revolucionario Institucional).
Posteriormente en 2006, con la aprobación de la Ley Federal de Presupuesto y Responsabilidad Hacendaria (LFPRH) se vinculó normativamente la información sobre el desempeño de los programas públicos con la asignación presupuestal (Montiel, 2011). A partir de esta ley se implementó una lógica presupuestal que principalmente busca el control y la racionalización del gasto. Se estableció un sistema de evaluación para todos los programas federales a fin de contar con información sobre desempeño de estas intervenciones para la toma de decisiones presupuestarias. El tema tomó mayor impulso porque coincidió con la llegada de un nuevo gobierno a la administración federal cuyo interés estaba en orientar los ejercicios de evaluación al Presupuesto basado en Resultados. “El objetivo final de este tipo de evaluación [era] favorecer una nueva
38 Artículo 81 de la Ley General de Desarrollo Social. 39 Evaluadores externos involucra instituciones de educación superior, de investigación científica u organizaciones no lucrativas. 40 Anualmente, CONEVAL solicita evaluaciones de desempeño a los programas sociales. Es frecuente encontrar que un programa público cuente con al menos dos evaluaciones de desempeño en el periodo 2008-2012.
68 de 212

racionalidad en la asignación del gasto público (por medio de la elaboración de presupuestos basados en resultados) que refle[jara] la efectividad y eficiencia de cada programa público” (González, 2010: 162). La implementación de este nuevo esquema, implicaba dejar de lado un proceso de asignación del gasto que respondía a lógicas inerciales y motivos discrecionales que poco decían sobre los resultados alcanzados anualmente por el gobierno (Zabaleta, 2008). Por lo tanto en el contexto del Presupuesto basado en Resultados, el gobierno estaría obligado a elegir aquellos programas que aseguraran una mejor utilización de los recursos limitados y contribuyeran a sus prioridades de políticas; en otras palabras, se trataba de hacer más con menos y de asignar recursos según el desempeño.
Para instrumentar dicho mandato, la Ley Federal de Presupuesto y Responsabilidad Hacendaria creó el Sistema de Evaluación del Desempeño (SED). El SED, tal como lo define la LFPRH, es “el conjunto de elementos metodológicos que permiten realizar una valoración objetiva del desempeño de los programas, bajo los principios de verificación del grado de cumplimiento de metas y objetivos, con base en indicadores estratégicos y de gestión que permitan conocer el impacto social de los programas y de los proyectos” 41. En otras palabras, el SED es el mecanismo que da seguimiento a las metas de las dependencias mediante el monitoreo de indicadores de desempeño clasificados en estratégicos y de gestión42 y las evaluaciones practicadas a los programas públicos. Dichos indicadores, junto con los resultados de las evaluaciones se comenzaron a usar en procesos de planeación y presupuestación en 2008. Cada trimestre, señala la ley, la Secretaría de Hacienda es la encargada de conjuntar los indicadores reportados por las
41 Artículo 2 de la Ley Federal de Presupuesto y Responsabilidad Hacendaria. 42 Los indicadores de desempeño se clasifican en dos tipos: los estratégicos, que miden el avance de los objetivos de las políticas públicas y programas presupuestarios y los de gestión, que miden el avance de los procesos y actividades que son generados y entregados dentro de un programa presupuestario.
69 de 212

dependencias y enviar los avances, con desglose mensual, a la Cámara de Diputados. Para la administración del SED, la Secretaría de Hacienda valida los indicadores estratégicos, mientras que la Secretaría de la Función Pública valida los indicadores de gestión, enfatizando en la calidad de los bienes y servicios públicos y en la satisfacción del ciudadano. Es importante resaltar que la LFPRH, contempla que las instancias a cargo de la evaluación del desempeño deben dar seguimiento a la atención de las recomendaciones que se emitan como resultados de evaluaciones (art. 110, LFPRH). Además, la ley señala que en la etapa de integración del presupuesto, las comisiones de la Cámara de Diputados –no indica a qué comisiones se refiere en particular- deben tomar en cuenta en sus consideraciones y propuestas de gasto, la evaluación de los programas y proyectos y las medidas que pueden impulsar para el logro de los objetivos y metas anuales.
Además de la publicación de la LFPRH, en 2008 se publicó un decreto para reformar el artículo 134 de la Constitución en materia de gasto público y fiscalización. Se estableció que los recursos de la federación serían evaluados por instancias técnicas independientes, que respectivamente establecerían el gobierno federal y las entidades estatales, a fin de que los recursos económicos se asignen con base en los criterios de eficiencia, eficacia, economía, transparencia y honradez. Asimismo, producto de la reforma constitucional, se fortalecieron las competencias de la Auditoría Superior de la Federación (ASF), órgano técnico de la Cámara de Diputados, para realizar auditorías de desempeño y emitir recomendaciones sobre los programas federales, así como de los recursos federales que ejercen las entidades federativas (art. 79 constitucional).
Antes de desarrollar los mecanismos que instrumentaron el marco legal es pertinente señalar que en el proceso histórico de la evaluación en México se pueden
70 de 212

ubicar tres principales motivaciones que justificaron la realización de evaluaciones y que aún siguen presentes: la lógica del control legal y auditoría; la modernización administrativa y mejora de la gestión; y, el control y racionalización del gasto público. Estas distintas justificaciones han provocado lógicas contrapuestas dentro y fuera de las dependencias públicas y esfuerzos inconexos que terminan por afectar el alcance del sistema de evaluación en México. Como señala González (2010:170) donde mejor se reflejan estas contradicciones es en el SED: “Por un lado, la Secretaría de Hacienda y Crédito Público tiene como objetivo fundamental la instrumentación de presupuestos basados en resultados, partiendo de la información generada por la evaluación de programas y de la gestión pública […] el incentivo que guiará dichos presupuestos será el ahorro y la racionalización del gasto público. Por su parte, la Secretaría de la Función Pública (por medio del Programa de Mejora de la Gestión) no tiene como propósito fundamental la racionalización del gasto por medio de la modificación presupuestal, sino el mejoramiento de los sistemas de gestión de las dependencias gubernamentales y la provisión al ciudadano de servicios públicos de mayor calidad. Estos procesos de modernización y de mejora podrían implicar, incluso, un mayor gasto en aquellas organizaciones con niveles más bajos de desempeño o madurez administrativa en un primer momento”. En contraste, el CONEVAL tiene como objetivo fundamental la mejora continua de los programas sociales a partir del uso de las evaluaciones. Este proceso de mejora tiene que ver con la gestión de los procesos y producción del programa. En particular, el CONEVAL promueve el uso inteligente de la información derivada de las recomendaciones y hallazgos de las evaluaciones que faciliten el aprendizaje organizacional y las mejores prácticas en el desempeño de los programas. Estas motivaciones diferentes han provocado propósitos diametralmente opuestos con
71 de 212

resultados también diametralmente distintos que se reflejan en una política desarticulada que afecta los alcances del sistema de evaluación mexicano.
Ahora bien, en cuanto a los mecanismos que se instrumentaron para evaluar a los programas públicos podemos mencionar, en primer lugar, la implementación de la Matriz de Indicadores. Esta matriz es un instrumento metodológico que sirve para estandarizar la presentación de los programas federales. Está conformada por la descripción de los principales ámbitos de acción del programa federal, los indicadores que serán monitoreados y evaluados, las fuentes de información utilizadas para calcular los indicadores y, la descripción de factores externos que pueden incidir en el incumplimiento de los objetivos del programa. Esta metodología permite alinear el fin, propósito, componentes y actividades43 de cada programa a los objetivos sectoriales de cada dependencia y éstos a su vez, con las metas del Plan Nacional de Desarrollo del gobierno federal. Todos los programas sujetos a Reglas de Operación, deben contar con una matriz de indicadores y se espera que los resultados de las evaluaciones contribuyan constantemente a mejorar dicha matriz. Los indicadores que se registran en el SED derivan de esta matriz.

La información que se integra en el Sistema de Evaluación del Desempeño no sólo es externa44, la Secretaría de Hacienda también realiza una evaluación de indicadores estratégicos y metas de los principales objetivos de los programas presupuestarios,

dichos indicadores se integran en los informes trimestrales anteriormente mencionados.

43 La MIR bien diseñada provee de coherencia lógica a los programas ya que involucra el objetivo

estratégico al cual contribuye el programa, el efecto esperado que se busca, los bienes y servicios que se

proporcionarán a los beneficiarios y las acciones requeridas para producir los beneficios esperados. Para

mayor información SHCP,

Sistema de Evaluación del Desempeño, México, 2008.

http://www.normateca.gob.mx/Archivos/51_D_1996_.pdf

44 Estas evaluaciones toman en cuenta información de las matrices de indicadores, que “proporcionan los elementos necesarios para la verificación y cumplimiento de los objetivos y metas de los programas presupuestarios” (SHCP 2008, p. 15).

72 de 212

Como sucede en otros países, la Secretaría de Hacienda es la encargada de administrar y coordinar el sistema de evaluación del desempeño, y junto con la Presidencia de la República y las dependencias que operan los programas, representan los principales actores del Poder Ejecutivo capaces de tomar decisiones sobre cambios en la operación de los programas públicos y el presupuesto que reciben anualmente.
Además de las dos leyes referidas, el marco normativo también considera los Lineamientos Generales para la Evaluación de los Programas Federales de la Administración Pública, éstos son un instrumento que estandariza la evaluación de los programas públicos y son de carácter obligatorio para las dependencias y entidades de la Administración Pública Federal responsables de operar programas federales. Estos lineamientos, publicados en 2007, contemplan la evaluación de todos los programas sujetos a Reglas de Operación y aquellos programas que determinen en su conjunto Secretaría de Hacienda, de la Función Pública y el CONEVAL. La Secretaría de Hacienda y la de Función Pública se encargan de “diseñar las directrices normativas, la coordinación institucional y la transformación final de los resultados de las evaluaciones en asignaciones finales de gasto, mientras que el CONEVAL se encarga de la coordinación técnica y el desarrollo de las metodologías pertinentes para la elaboración de las evaluaciones en el ámbito social” (González, 2010: 163).
Los Lineamientos contemplan distintos tipos de evaluaciones45, y los resultados de los indicadores evaluados se integran al SED a fin de contar con información disponible para el proceso presupuestario. Estos Lineamientos reconocen la obligatoriedad de atender las recomendaciones de las evaluaciones y de darles
45 Evaluación de consistencia y resultados, de indicadores, procesos, impacto, específica y estratégica. Para una definición completa de lo que incluyen estas evaluaciones consultar art. 16 de los Lineamientos.
73 de 212

seguimiento conforme a un convenio de compromisos que las mismas dependencias adopten46.
En cumplimiento al artículo 110 de la LFPRH también se creó el Programa Anual de Evaluación (PAE). Dicho programa comenzó a aplicarse a partir del 2007 y cada año se planean más de cien evaluaciones a nivel federal. El PAE tiene como objetivo determinar los tipos de evaluación que se aplicarán a los programas presupuestarios. Los criterios para elegir el tipo de evaluación que le corresponde a un programa los define la Secretaría de Hacienda, la de Función Pública y CONEVAL en el ámbito de su competencia. Sin embargo, la evaluación de programas federales depende del ciclo de vida en el que se encuentre47, es decir, las evaluaciones se van ejecutando de acuerdo al ciclo de vida de las políticas públicas (diseño, procesos, impacto), pero también se consideran las necesidades que manifiestan los responsables de los programas, las evaluaciones que se le aplicaron el año previo y las propuestas que conjuntamente hacen la Secretaría de Hacienda, de la Función Pública y el CONEVAL conjuntamente. Desde sus inicios, el PAE contempló que el calendario de ejecución de las evaluaciones estaría vinculado al calendario de programación y presupuesto del ejercicio fiscal del año siguiente, de tal forma que los resultados de las evaluaciones se conviertan en información disponible para la etapa de formación de presupuesto; en otras palabras, su objetivo es vincular los resultados de las evaluaciones como insumo relevante del presupuesto. Todos los programas federales sujetos a reglas de operación son objeto de
46 Aunque los Lineamientos establecen que para darle seguimiento a las recomendaciones derivadas de las evaluaciones se deberán firmar convenios “de compromisos de mejoramiento de la gestión para resultados” entre las dependencias ejecutoras y la Secretaría de Hacienda, de la Función Pública y el CONEVAL, éstos aún no se han establecido. 47 Después de un estudio de diagnóstico sobre la problemática que atiende el programa, en el primer año se debe realizar una evaluación de diseño; en el segundo se realizan evaluaciones de Consistencia y Resultados; para el tercer y cuarto años se planean evaluaciones de procesos y de impacto.
74 de 212

evaluación de consistencia y resultados48; los programas nuevos deben presentar un
diagnóstico que justifique su creación, y todas las dependencias y entidades están
obligadas a difundir, a través de sus respectivas páginas de internet, la información sobre
los resultados de las evaluaciones aplicadas.
Cabe señalar que el CONEVAL determina los términos de referencia que deben cumplir los programas sociales sujetos a evaluación49. Los términos de referencia “trazan
las líneas generales del trabajo que tiene que llevar a cabo el evaluador, las preguntas
que tienen que responderse y el calendario” (FIDA y PREVAL, 2006) al que se deben
sujetar. Estos lineamientos sirven para estandarizar los requisitos mínimos que se
esperan cumplan las evaluaciones de programas federales, pero también representan
límites explícitos a los potenciales hallazgos que pueda ofrecer una evaluación.
Asimismo, se hicieron modificaciones a la estructura del presupuesto. El objetivo
de este cambio fue “presentar una descripción que permita informar sobre la naturaleza
de los servicios gubernamentales y la proporción de los gastos públicos que se destinen a
cada tipo de servicio” (Centro de Estudios de Finanzas Públicas, 2012). La
implementación del SED incide sobre el modelo programático-presupuestario. A fin de
contar con una mayor coherencia, esta clasificación se concibió a la luz de la publicación
de la Ley Federal de Presupuesto y Responsabilidad Hacendaria (LFPRH) en el año 2006.
A partir de dichos cambios, se buscó modificar la estructura programática del
48 Las evaluaciones de consistencia y resultados son ejercicios que valoran al programa en matera de diseño, planeación estratégica, cobertura y focalización de la población a la que atienden, operación de los procesos, percepción de la población objetivo y en materia de resultados. Los programas que conforman el estudio de caso de la presente investigación, cuentan con al menos una evaluación de este tipo en el periodo 2008-2012. 49 La evaluación de consistencia y resultados, específica de desempeño, procesos y de diseño deben seguir los términos de referencia establecidos por CONEVAL; mientras que para los demás tipos de evaluación, los términos de referencia son diseñados por cada dependencia ejecutora dependiendo de las características particulares de cada evaluación.
75 de 212

presupuesto y se adicionó el renglón de Programa Presupuestario para vincular el
objetivo de cada programa público con las metas del Plan Nacional de Desarrollo y las de
las dependencias de gobierno, respectivamente. Esta clasificación agrupa los gastos por categorías50 y elementos programáticos51 de acuerdo a los propósitos a los que están
destinados. A su vez, los programas presupuestarios se clasificaron por modalidades de
gasto. Existen 23 modalidades que se ubican entre el gasto programable y el no programable52.
Esta nueva estructura, conocida como presupuesto por programa, tiende a ser
más abierta a la incorporación de la información sobre desempeño que aquella
modalidad conocida como presupuestos por línea que se han implementado en otros
países (OCDE, 2007). Es más abierta porque supone que la introducción de la categoría
Programa Presupuestario está relacionada con la aplicación de la Matriz de Indicadores.
A partir de esta clasificación, y dependiendo de la naturaleza del programa público, los
programas que cuenten con Matriz de Indicadores son sujetos a ejercicios de evaluación.
Los objetivos, indicadores y metas de los programas presupuestarios contenidos en la
50 La categoría programática permite desagregar la información hacia niveles más detallados. Se organiza por función, subfunción, programa sectorial, programa especial, programa presupuestario, proyecto institucional y proyecto de inversión. 51 Los elementos programáticos nos proporcionan información cualitativa de las categorías programáticas, es decir, explican la misión, el objetivo, indicador y su meta. 52Dentro del gasto programable se encuentran las modalidades relacionadas a Programas Federales y a Programas de Gasto federalizado. Dentro de los primeros se incluyen los programas que están dirigidos a subsidios (modalidades S y U), al desempeño de las funciones (modalidades E, B, P, F, G, A, R y K), a los programas administrativos y de apoyo (modalidades M, O, y W), a los relacionados con los compromisos del gobierno federal (modalidades L y N) y las relacionadas con las obligaciones del gobierno federal (J, T, Y, Z). La modalidad relacionada a Programas de Gasto federalizado (modalidad I) contempla las aportaciones federales a las entidades federativas y municipios mediante el Ramo 33. En total 20 modalidades de programas presupuestarios se encuentran en el gasto programable. Dentro del gasto no programable se encuentran las modalidades relacionadas con Participaciones (modalidad C), costo financiero (modalidad D) y los adeudos de ejercicios fiscales anteriores, Adefas, (modalidad H). Los programas de apoyos dirigidos a grupos prioritarios se clasificaron en la modalidad S.
76 de 212

Matriz de Indicadores son los elementos a los que se les da seguimiento durante el ejercicio fiscal en curso53. Mecanismos de instrumentación para el sistema de evaluación en México
El impulso del sistema de evaluación en México responde a lo que Méndez (1996) identifica como una confluencia de coaliciones políticas preparadas para usar “una crisis como una ventana de oportunidad” para sus proyectos y soluciones. Dicho de otra forma, a partir de 1997, debido al cambio en el sistema político mexicano, se abrió la oportunidad de acelerar reformas administrativas impulsadas por distintos actores de los Poderes Ejecutivo y Legislativo que facilitaron la creación de un sistema estandarizado de evaluación en el ámbito federal, y que permite contar con la medición del desempeño a través del monitoreo de indicadores y los resultados de las evaluaciones. Este sistema de evaluación se sostiene en un marco jurídico e institucional que delimita las funciones de los actores encargados de coordinar ejercicios constantes de evaluación; dichas evaluaciones se realizan anualmente por un grupo externo de distintos expertos, y los resultados derivados de dichas evaluaciones alimentan sistemas de información que aglutinan evidencia empírica sobre el desempeño de las diversas intervenciones públicas. Sin embargo, la explicación de esta dimensión no es suficiente para entender qué efectos tiene la evidencia recolectada por el Sistema de Evaluación del Desempeño y el conjunto de informes reportados al Congreso sobre los actores que toman decisiones relativas a la mejora continua del desempeño de programas públicos y en la implementación del Presupuesto basado en Resultados.
53 Para fines prácticos, la MIR es el instrumento de monitoreo de un programa público. 77 de 212

Esta segunda sección se enfocará en explicar cómo se utilizan los resultados de las evaluaciones en la toma de decisiones de la Administración Pública Federal desde el punto de vista de los mecanismos formales establecidos para ello.
Un primer acercamiento permite ubicar que a partir de 2008, el gobierno federal desarrolló un mecanismo de seguimiento a las recomendaciones adoptadas por las dependencias encargadas de operar los programas públicos. El objetivo de este mecanismo es hacer que los programas se comprometan con el uso efectivo de los resultados de la evaluación; en otras palabras se trata de hacer que las evaluaciones sean un factor de cambio en la implementación de la política pública. Este instrumento, conocido como el Mecanismo para el Seguimiento de Aspectos Susceptibles de Mejora derivados de informes y evaluaciones a los programas presupuestarios de la Administración Pública Federal, (en adelante Mecanismo de Seguimiento) se activa una vez que las recomendaciones emitidas por el evaluador son aceptadas por las áreas responsables de las dependencias. El proceso inicia cuando las áreas de planeación, evaluación, presupuestación y operación en las dependencias ejecutoras de programas públicos, se reúnen para seleccionar las recomendaciones y los hallazgos que consideran pertinentes darles seguimiento. Los parámetros para seleccionar dichas recomendaciones responden a criterios de claridad, relevancia, justificación y viabilidad para realizar los cambios sugeridos por las evaluaciones. Cabe señalar que una vez que el informe final de evaluación es conocido por la dependencia, ésta cuenta con la capacidad de publicar un documento, conocido como posición institucional, para explicar las razones por las que considera viable o no, adoptar las recomendaciones sugeridas por el evaluador.
78 de 212

Una vez seleccionadas las recomendaciones a las que se les dará seguimiento, formalmente conocidas como Aspectos Susceptibles de Mejora54 (ASM), se clasifican por el nivel de atención que requiere su seguimiento: específicos, cuando la unidad responsable del programa puede atenderlos; institucionales, si involucra a distintas áreas de la dependencia; interinstitucionales, cuando considera la participación de diversas entidades; e intergubernamentales, si requieren la atención de más de un nivel de gobierno.
Después de adoptados los aspectos que son susceptibles de mejora en el diseño de las políticas públicas y de los programas correspondientes, las dependencias preparan un plan de trabajo y se obligan, a través del Mecanismo de Seguimiento, a cumplir y reportar los avances de acuerdo con un calendario preestablecido: en el mes de marzo, se entrega un reporte a la Secretaría de la Función Pública, a la de Hacienda y al CONEVAL con los avances de los ASM comprometidos en ejercicios fiscales anteriores; en el mes de abril, se entrega un documento de trabajo que describe los nuevos aspectos comprometidos (que fueron clasificados como específicos) derivados de la última evaluación que realizaron, un documento institucional (en caso de que el ASM fuera clasificado como institucional) y un documento que sirve para que la dependencia documente su opinión del proceso de evaluación; en junio se informa sobre los compromisos interinstitucionales e intergubernamentales derivados del ejercicio fiscal anterior y además, el CONEVAL integra un informe que analiza los ASM de los programas de tipo social que cargaron avances en marzo. Finalmente, en septiembre las dependencias reportan avances de los ASM que cargaron en abril del ejercicio fiscal en
54 Los Aspectos Susceptibles de Mejora son “hallazgos, debilidades, oportunidades y amenazas identificadas en la evaluación externa, las cuales pueden ser atendidas para la mejora de los programas con base en las recomendaciones y sugerencias señaladas por el evaluador externo”, SHCP. http://www.shcp.gob.mx/EGRESOS/sitio_pbr/evaluacion/Paginas/ASM.aspx
79 de 212

curso y de ASM de años anteriores que no han llegado al cien por ciento de su cumplimiento. Este seguimiento periódico, supone un cumplimiento puntual de los compromisos adoptados. Es importante mencionar que todos los programas federales que tengan evaluaciones externas están obligados a inscribirse en el Sistema de Seguimiento a los Aspectos Susceptibles (SSAS) que administra el CONEVAL para reportar los avances de acuerdo a las fechas de entrega. En este sistema, las dependencias están obligadas a reportar en los meses de marzo y septiembre el porcentaje de avance de cada uno de los ASM comprometidos (Ver Figura 4).
Figura 4. Ciclo de seguimiento a los Aspectos Susceptibles de Mejora
Marzo del Año 2: Seguimiento a ASM comprometidos en Abril del año inmediato anterior y de años anteriores.

Septiembre del Año 1: Las dependencias reportan avances de los ASM cargados como nuevos en Abril y de aquellos que aún no concluyen de años anteriores

Proceso de seguimiento a los ASM

Abril del Año 1: Las dependencias cargan en el SSAS nuevos ASM derivados de la última evaluación.

Junio del Año 1: CONEVAL publica un informe de los avances que registraron los programas sociales del años anteriores.
Fuente: Mecanismo para el Seguimiento de Aspectos Susceptibles de Mejora derivados de informes y evaluaciones a los programas presupuestarios de la Administración Pública Federal
Es importante comentar que recientemente la Secretaría de Hacienda
implementó el Modelo Sintético de Información del Desempeño (MSD), un instrumento
diseñado al interior de la dependencia que califica el desempeño de los programas
presupuestarios a partir de correlaciones entre: eficiencia presupuestaria del programa
en los últimos cuatro años, las prioridades del gobierno en turno, los resultados del
80 de 212

análisis de la Matriz de Indicadores para Resultados, evaluaciones externas y el grado de cumplimiento a los Aspectos Susceptibles de Mejora. El modelo recopila la información a partir de lo que reportan las dependencias y el CONEVAL en el ámbito de la política social. Aunque los resultados de este modelo son generados por la Secretaría de Hacienda, aún está por validarse su lógica interna y funcionamiento transparente. Sin embargo, aspira a convertirse en una herramienta que facilite la asignación presupuestal con base en criterios de eficiencia y racionalidad del gasto. Además del MSD la Secretaría de Hacienda administra el Portal Aplicativo de la Secretaría de Hacienda y Crédito Público (PASH), una aplicación informática donde las dependencias registran la Matriz de Indicadores para Resultados, los resultados de sus evaluaciones, metas y avances de sus indicadores estratégicos y de gestión de los programas presupuestarios de la Administración Pública Federal.
Además, vale la pena mencionar que CONEVAL administra tres sistemas de información para la sistematización de las Evaluaciones Específicas de Desempeño (EED), las de Consistencia y Resultados (ECR), y el seguimiento de los ASM. Una Evaluación Específica de Desempeño es una valoración del desempeño de los programas y acciones federales que presenta una breve descripción del programa, el avance en los objetivos y las metas de los indicadores (de resultados y de servicios y de gestión), así como de la información relacionada con la evolución y cobertura de la población objetivo y del presupuesto y el cumplimiento de ASM. Por otra parte, la Evaluaciones de Consistencia y Resultados sirve para tener un diagnóstico acerca de la capacidad institucional, organizacional y de gestión de los programas hacia resultados. La finalidad de esta evaluación es proveer información que retroalimente el diseño, la gestión y los resultados de los programas.
81 de 212

En este sentido, el Sistema de Información de las Evaluaciones Específicas de Desempeño (SIEED) y el Módulo de Información para la Evaluación Específica de Desempeño (MEED), recientemente creados, sirven para que el CONEVAL sistematice todos los insumos y resultados de las evaluaciones externas. En el MEED los programas cargan toda la información que consideran útil para que los evaluadores tengan acceso a dicha información durante el proceso de evaluación; es un sistema que contiene las fuentes de información de los programas para que los evaluadores tengan acceso a éstas de forma más sencilla. A su vez, los evaluadores la analizan y en el SIEED cargan los resultados de las Evaluaciones Específicas de Desempeño que se indican en el PAE de cada año. A partir del SIEED se genera información estratégica para los tomadores de decisiones. Por ejemplo, del SIEED se obtienen los informes completos, ejecutivos y las Fichas de Monitoreo. Estas últimas son una forma de presentar de manera ejecutiva los datos generales del programa, análisis sobre su población objetivo y atendida, los indicadores estratégicos, el cumplimiento de metas y la evolución de su presupuesto. Estas fichas se envían a los actores involucrados en la integración del presupuesto.
El tercer sistema, Sistema de Seguimiento a los Aspectos Susceptibles (SSAS), es la herramienta que el CONEVAL implementó para cumplir con el Mecanismo de Seguimiento y “para el desarrollo de las actividades relacionadas con el seguimiento a los aspectos susceptibles de mejora”55. Este sistema permite integrar y monitorear el porcentaje de avances que cada dependencia reporta en los meses de marzo y septiembre.
Entonces, en el sistema de evaluación mexicano se pueden identificar al menos cinco sistemas de información: el Modelo Sintético de Desempeño, el Portal Aplicativo de
55 Numeral 20 del Mecanismo para el seguimiento a los aspectos susceptibles de mejora derivados de informes y evaluaciones a los programas presupuestarios de la Administración Pública Federal, 2011.
82 de 212

la Secretaría de Hacienda y Crédito Público, el Módulo de Información para la Evaluación Específica de Desempeño, así como el Sistema de Información de las Evaluaciones Específicas de Desempeño y el Sistema de Seguimiento a los Aspectos Susceptibles. Cada uno aporta información diferenciada y es un esfuerzo de las dependencias coordinadoras del sistema de evaluación para aportar información estratégica a los tomadores de decisión. Sin embargo, cada sistema responde a lógicas distintas según la dependencia o entidad que lo administre: el PASH y el MSD tienen fines de control presupuestal, mientras que el MEED, SIEED y SSAS del CONEVAL son sistemas de información que sirven para sistematizar los resultados de las evaluaciones y dar seguimiento a los principales resultados de éstas e integrar los aspectos que sean susceptibles de mejora.
En resumen, los esfuerzos gubernamentales de los últimos años buscan fortalecer a la evaluación como una práctica administrativa sistemática para generar insumos de información que nutran las decisiones de gobierno. Una vez obtenidos los resultados de las evaluaciones las dependencias se comprometen con acciones puntuales que se reportan a la Secretaría de Hacienda, la de Función Pública y el CONEVAL. En teoría si las acciones implementadas fueron correctas se logra el objetivo de mejorar la gestión de los programas públicos y en consecuencia, hay un efecto en su presupuesto. Sin embargo, el Mecanismo de Seguimiento es el último eslabón del ciclo de evaluación en México (Montiel en Cejudo y Maldonado, 2011) y no existe otro instrumento que permita conocer las motivaciones reales para implementar los cambios a los programas públicos ni los criterios aplicados al proceso presupuestal (Figura 5).
Dentro del ámbito del Poder Ejecutivo, la Secretaría de Hacienda, de la Función Pública y el CONEVAL se centraron en la creación, difusión y revisión de la información de desempeño, y además, diseñaron un mecanismo para promover el uso de las
83 de 212

recomendaciones derivadas de las evaluaciones por parte de los administradores de programas públicos. Este entramado institucional supone que los resultados de las evaluaciones contribuyen de forma directa a mejorar la gestión de los programas públicos; sin embargo, este mecanismo no alcanza a explicar cómo la utilización efectiva de las evaluaciones impacta en las decisiones del ámbito presupuestal, ni sobre la productividad de las acciones iniciadas a partir de las recomendaciones.
Figura 5. El ciclo de la evaluación en México

Lineamientos para la
evaluación y publicación
del PAE

Elaboración de la MIR por cada
dependencia

Evaluación externa anual
más otras evaluaciones

Difusión de resultados de las evaluaciones en los sitios web institucionales

Mecanismo de seguimiento

Fuente: Montiel en Cejudo y Maldonado, 2011

2.2. El sistema de evaluación y su vínculo con el presupuesto público Para conocer el entramado institucional del proceso presupuestario en México es necesario conocer las reglas del juego que regulan las actividades de los actores involucrados. Para tener un panorama completo, “lo que debemos diferenciar con claridad son las reglas y los jugadores” (North, 1993: 15), por esta razón, el presente apartado desarrollará las reglas formales reconocidas en leyes y reglamentos que delimitan el quehacer del Poder Ejecutivo y del Legislativo en la planeación y aprobación del presupuesto.
El proceso presupuestario incluye las etapas de planeación, programación, aprobación del presupuesto, ejercicio, seguimiento, evaluación y rendición de cuentas. El Presupuesto basado en Resultados busca vincular los resultados de desempeño con cada una de las etapas del proceso presupuestario. Como se podrá observar en el desarrollo

84 de 212

de esta sección, la integración de información sobre desempeño en el proceso presupuestario se divide en tres etapas que pueden llegar a traslaparse. La primera, consiste en la recepción y coordinación por parte de la Secretaría de Hacienda de toda la información de desempeño que le remiten las distintas dependencias; la segunda, es la etapa de negociación del presupuesto entre las dependencias y entidades públicas con la Secretaría de Hacienda y la tercera, es la negociación que involucra al Ejecutivo, encabezado por la Secretaría de Hacienda, con la Cámara de Diputados.
El proceso presupuestario en México se define por algunos artículos constitucionales, la Ley Federal de Presupuesto y Responsabilidad Hacendaria y, su respectivo reglamento. Las etapas de programación y formulación del proyecto de presupuesto corresponden a las facultades del Ejecutivo, mientras que la discusión y aprobación son funciones del Legislativo.
El artículo 74 constitucional establece que es obligación del Ejecutivo enviar la Ley de Ingresos y el Proyecto de Presupuesto de Egresos de la Federación a la Cámara de Diputados para su posterior aprobación56. El Ejecutivo se encarga de diseñar el proyecto de presupuesto mediante la participación de la Secretaría de Hacienda como la autoridad que centraliza las funciones de presupuestación57. Esta secretaría da seguimiento a los diversos ejecutores del gasto58. El control y la evaluación de dicho gasto son responsabilidad de la Secretaría de Hacienda y la de Función Pública, en el ámbito de sus respectivas atribuciones (LFPRH, artículo 6). Con sus contrapartes -las dependencias ejecutoras- la Secretaría de Hacienda mantiene una estrecha comunicación a lo largo del
56 La Ley de Ingresos es aprobada por ambas cámaras del Congreso, mientras que el decreto de presupuesto sólo le corresponde a la Cámara de Diputados. 57 Dentro de la SHCP, la Subsecretaría de Egresos es la autoridad que concentra las principales responsabilidades presupuestarias. 58 Por ejecutores del gasto se entiende el Poder Legislativo y Judicial, los entes autónomos y tribunales administrativos, la Procuraduría General de la República, Presidencia de la República, las dependencias y entidades (LFPRH, 2006).
85 de 212

año para negociar las propuestas de presupuesto y dar seguimiento a la ejecución del mismo. La definición de los objetivos de los programas presupuestarios, junto con sus indicadores y metas, son propuestos por las dependencias y entidades responsables de los mismos y autorizados por la Secretaría de Hacienda.
Dentro de todo este proceso, el Presidente de la República es la máxima autoridad en las decisiones presupuestarias aunque el liderazgo lo tiene la Secretaría de Hacienda para toda la etapa de formulación. Sin embargo, como señala la OCDE, el nivel de participación del Presidente en la formulación del presupuesto depende del estilo político del mismo. Algunas veces es un actor más involucrado que otras por ejemplo, durante el gobierno de Felipe Calderón, “el presidente [participó] en la apertura del proceso presupuestario para señalar las prioridades centrales de presupuesto que va a elaborarse [de acuerdo con el Plan Nacional de Desarrollo], acuerda los topes para el presupuesto total y para cada secretaría con la Secretaría de Hacienda, y participa también durante la etapa final antes de que se envíe la propuesta al Congreso” (OCDE, 2009: 53).
La formulación del presupuesto responde a las prioridades del Plan Nacional de Desarrollo (PND) de cada periodo presidencial, en otras palabras, al proyecto político de cada gobierno. En este sentido, los diferentes ejecutores del gasto en el Ejecutivo deben planear sus respectivos anteproyectos de acuerdo a las prioridades generales de política expresadas en el PND, o a las prioridades de corto plazo que se van identificando en el gobierno año con año. La LFPRH señala que la programación y presupuestación anual del gasto público debe considerar entre otros aspectos “la evaluación de los avances logrados en el cumplimiento de los objetivos y metas del Plan Nacional de Desarrollo y los programas sectoriales con base en el Sistema de Evaluación del Desempeño, las
86 de 212

metas y avances físicos y financieros del ejercicio fiscal anterior y los pretendidos para el ejercicio siguiente” (artículo 25, LFPRH).
Formalmente, la etapa de programación y formulación del presupuesto se desarrolla entre los meses de enero a julio de cada año. En el periodo de enero a marzo se formulan escenarios de gasto y de programas prioritarios; en el mes de abril, el Ejecutivo envía al Congreso un informe sobre las proyecciones macroeconómicas (crecimiento, inflación, tasa de interés y precio del petróleo) para el siguiente año fiscal. De abril al 15 de junio, las dependencias y entidades integran un informe del avance físico y financiero de los programas presupuestarios y posteriormente, el 30 de junio, el Ejecutivo presenta un segundo informe a la Cámara de Diputados donde detalla la estructura programática del presupuesto y los nuevos programas que se considerarán en el proyecto de presupuesto. Paralelamente, en los meses de junio y julio, cada dependencia inicia su anteproyecto de presupuesto con base en los presupuestos de años anteriores al que se suman criterios de inflación y de aumento de los ingresos (OCDE, 2009). Durante el mes de agosto, los ejecutores de gasto presentan formalmente sus presupuestos a la Secretaría de Hacienda y en un plazo de tres semanas ésta integra la propuesta de presupuesto que presenta el 8 de septiembre59 a la Cámara de Diputados.
Antes de la integración formal del proyecto del presupuesto, las dependencias y entidades junto con la Secretaría de Hacienda resolvieron previamente todo tipo de negociaciones sobre los topes presupuestarios para el siguiente año, aunque como reconoce la OCDE (2009), no obstante que el proceso de formulación comienza desde el
59 Junto con el Proyecto de Presupuesto de Egresos, el Ejecutivo presenta un conjunto de documentos conocido como Paquete Económico, este paquete está integrado por la exposición de motivos, el marco macroeconómico, la iniciativa de Ley de Ingresos y documentos de apoyo
87 de 212

mes de abril, “los pasos formales del proceso de formulación del presupuesto parecen encontrarse bastante sesgados hacia las últimas semanas justo antes de su envío a la legislatura […] y el control que ejercen la Presidencia y la Secretaría de Hacienda depende en cierta medida de la práctica administrativa del gobierno actual [del presidente Felipe Calderón] y menos de las instituciones formales”.
En esta etapa de formulación, las dependencias y entidades ejecutoras de gasto deben actualizar cada matriz de indicadores de resultados y considerar la información de desempeño que deriva de las evaluaciones llevadas a cabo. Para el caso mexicano, “por primera vez en 2008 se elaboró un resumen de la información de desempeño para todos los programas gubernamentales. El propósito de este resumen fue hacer accesible la información sobre desempeño para que los encargados de la toma de decisiones a niveles altos basaran sus fallos [… sin embargo], resulta difícil determinar su influencia precisa” (OCDE, 2009: 57). El propósito es asegurar que la información del SED se utilice en la toma de decisiones durante el proceso presupuestario.
Aunque formalmente la participación del Ejecutivo termina cuando la propuesta de proyecto de presupuesto se envía al Congreso, en el marco del Presupuesto basado en Resultados, su participación se extiende a todo el ciclo presupuestal. Además, cualquier dato o información que se solicite por los legisladores y los grupos parlamentarios deberá ser proporcionada por la Secretaría de Hacienda.
En lo que respecta al Legislativo, se puede señalar que este órgano cuenta con una serie de facultades constitucionales que le permiten participar en la vida pública a través de cinco grandes funciones: legislativa, de control político, impulso político, de información y la presupuestaria (Armienta, 2002). La función relativa al presupuesto está definida en el artículo 74 constitucional que reconoce como facultad de la Cámara de
88 de 212

Diputados aprobar anualmente el Presupuesto de Egresos de la Federación, previo examen, discusión y, en su caso, modificación del Proyecto enviado por el Ejecutivo Federal. El Proyecto de Presupuesto de Egresos de la Federación (PPEF) deberá ser aprobado por la Cámara de Diputados a más tardar el día 15 de noviembre, es decir, este órgano tiene alrededor de dos meses para el proceso deliberativo. Además, es facultad de los diputados “revisar la Cuenta Pública del año anterior, con el objeto de evaluar los resultados de la gestión financiera, comprobar si se ha ajustado a los criterios señalados por el Presupuesto y verificar el cumplimiento de los objetivos contenidos en los programas”. Para esta última facultad, la Cámara de Diputados se apoya en la Auditoría Superior de la Federación (ASF), órgano técnico, que como ya se había señalado, está facultada para realizar auditorías de desempeño y emitir recomendaciones sobre los programas federales, así como de los recursos federales que ejercen las entidades federativas. Una vez que las recomendaciones son conocidas por las dependencias, están obligadas a presentar ante el Congreso informes bianuales de seguimiento. Sin embargo, como menciona González (2010:160) aunque la Auditoría Superior de la Federación “ha complementado sus instrumentos tradicionales de vigilancia y revisión de la cuenta pública federal con auditorías de desempeño a programas y dependencias federales particulares […] se ha mantenido en un nivel legal-normativo y no ha profundizado en el análisis del desempeño objetivo de los programas públicos”. En otras palabras, a la Cámara de Diputados le corresponde discutir y aprobar el presupuesto, así como supervisar su ejecución y fiscalizar su cumplimiento.
Como el caso del Ejecutivo, la mayor parte de los detalles sobre las facultades que se le otorgan en exclusiva a la Cámara de Diputados, el procedimiento y los plazos para la aprobación del presupuesto se encuentra en la LFPRH. Sin embargo, aunque estas
89 de 212

facultades se reconocen formalmente en las leyes, la capacidad del Legislativo para influir en las decisiones públicas es relativamente reciente. Cabe resaltar que “en sistemas presidenciales, donde las elecciones para miembros de Legislativo son independientes de las elecciones para presidente, la legislatura es un poderoso actor para definir la agenda y para tomar decisiones” (Lienert, 2005:3).
En particular, la participación real de la Cámara de Diputados en la aprobación del presupuesto sólo se logró cuando se presentaron importantes cambios en el sistema político mexicano. A partir de 1997 el PRI, el partido en el poder que gobernó durante décadas, perdió la mayoría absoluta en la Cámara de Diputados y se vio obligado a negociar las distintas iniciativas de ley con los partidos de grupos opositores. El presupuesto no fue la excepción, la aprobación legislativa del pacto presupuestal ahora incluye a los partidos de grupos opositores que antes quedaban excluidos de la decisiones. Durante los años de gobierno del partido hegemónico priísta, el pacto presupuestal era una decisión centralizada que se alcanzaba sin mayores discusiones debido a que el partido con mayoría en la Cámara de Diputados era el mismo al que pertenecía el Presidente. Esta condición le permitió al Ejecutivo, por mucho tiempo, tener mayor control político sobre el Legislativo en las distintas etapas del proceso presupuestario hasta su aprobación final. “Durante los años de gobierno unificado, los legisladores priístas no cuestionaban públicamente al titular del Ejecutivo ni a sus altos funcionarios ya que la iniciativa del gobierno incluía las demandas de los actores políticos más significativos del régimen” (Puente, 2011: 217). Sin embargo, la presencia de partidos opositores detonó una reconfiguración de las relaciones de poder y provocó que la negociación del presupuesto se abriera a los distintos intereses y preferencias de los
90 de 212

actores políticos involucrados (para un análisis de la evolución institucional del Poder Legislativo mexicano en el proceso presupuestario ver Puente, 2011).
Luego de la recepción formal del proyecto de presupuesto, éste es turnado a la Comisión de Presupuesto y Cuenta Pública de la Cámara de Diputados que tiene 45 días60 para elaborar el dictamen del proyecto de presupuesto y turnarlo para votación en el Pleno hasta el 15 de noviembre como fecha límite61. Dentro de este periodo, la Comisión de Presupuesto, establece los mecanismos de participación de las comisiones ordinarias en el examen y discusión del presupuesto. Éstas deben considerar la disponibilidad de recursos, la información sobre la evaluación de los programas y proyectos y las medidas que permitan alcanzar los objetivos y metas anuales (artículo 42, LFPRH). Sin embargo, la participación de las comisiones sólo se limita a emitir opiniones y proponer enmiendas sin carácter vinculatorio y “la Comisión de Presupuesto no está obligada a integrar los montos en los términos aprobados por las comisiones” (Puente, 2011), de tal forma que la Comisión de Presupuesto es el espacio principal donde se deciden las modificaciones reales del presupuesto, antes de pasar al Pleno.
Es importante mencionar que la etapa de discusión sobre el presupuesto está abierta al público, las distintas comisiones ordinarias mantienen una etapa de audiencias públicas para recibir las demandas de distintos sectores: instituciones académicas, grupos de interés, gobernadores, las secretarías de estado, y la propia Secretaría de
60 Artículo 182 del Reglamento de la Cámara de Diputados. 61 Los documentos del presupuesto anteriores al año 2007 señalaban como obligatorio que las dependencias que realizaran evaluaciones debían presentar sus resultados a la Comisión de Presupuesto y Cuenta Pública de la Cámara de Diputados, a más tardar el 15 de octubre, a efecto de que los resultados fueran considerados en el proceso de análisis y aprobación del Presupuesto de Egresos de la Federación para el siguiente ejercicio fiscal. Sin embargo, a partir del PEF 2008 se amplió el número de actores que recibirían estos resultados, ahora también la Auditoría Superior de la Federación, las secretarías de Hacienda y Crédito Público, y de la Función Pública; así como el CONEVAL conocerían de los resultados de las evaluaciones, de acuerdo con los plazos previstos en el PAE.
91 de 212

Hacienda (Puente, 2011; OCDE, 2009). Además de estos actores, el reglamento de la LFPRH señala que los servidores públicos de las dependencias y entidades, podrán asistir a reuniones de trabajo con los legisladores para analizar la iniciativa de Ley de Ingresos, el proyecto de Presupuesto de Egresos y las iniciativas de reformas a las leyes fiscales. Asimismo, se le otorga un papel especial al Centro de Estudios de las Finanzas Públicas de la Cámara de Diputados (CEFP) para apoyar técnicamente la elaboración y aprobación tanto de la Ley de Ingresos, como del presupuesto. De acuerdo a dicha ley, este Centro de Estudios es el responsable de analizar los informes trimestrales que envía el Ejecutivo sobre los avances del presupuesto62 y el cumplimiento de metas de los programas públicos. Aunque el tema del presupuesto es una función centralizada por la Secretaría de Hacienda, la ley permite mayor interacción entre el resto de las dependencias y la Cámara de Diputados.
Una vez que el presupuesto es aprobado, en lo general y lo particular, en el Pleno de los diputados, deberá publicarse el decreto en el Diario Oficial de la Federación. Después de publicado, el Ejecutivo deberá enviar a la Cámara de Diputados todos los tomos y anexos del Presupuesto, con las modificaciones respectivas, que conformarán el presupuesto aprobado.
Como se ha podido observar, la utilización de la información sobre desempeño en el proceso presupuestario carece de mecanismos institucionales que obliguen a los actores a considerar la información en la aprobación del presupuesto. Aunque se asuma que se utiliza información sobre desempeño, su aplicación no parece necesariamente sistemática. Como señala Puente (2011) “del análisis del contenido del decreto
62 Además, el CEFP también analiza los informes sobre la situación de las finanzas públicas; el informe de implementación del Plan Nacional de Desarrollo; y, cualquier ley o iniciativa relacionada a temas presupuestales (OCDE, 2009).
92 de 212

presupuestal se pueden conocer a qué partidas o sectores se han asignado recursos económicos, pero no los criterios o razones para asignarlos”.
2.3. Descripción de los casos de estudio Los programas que a continuación se describen integran la temática de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades elaborada a partir de una evaluación integral de desempeño publicada por CONEVAL en el año 2011. Los cinco programas considerados para el análisis atienden diversas carencias de grupos poblacionales distintos: adultos mayores de 70 años y más, jornaleros agrícolas y sus familias, mujeres, así como diversos grupos en situación de vulnerabilidad. Su operación está a cargo de la Secretaría de Desarrollo Social, del Instituto de Desarrollo Social (órgano desconcentrado de Secretaría de Desarrollo Social) y del Instituto Nacional de las Mujeres (organismo sectorizado a la Secretaría de Hacienda). Cabe señalar que aunque el Programa de Fortalecimiento a la Transversalidad de la Perspectiva de Género está enfocado a promover la inclusión de políticas públicas en las entidades federativas para evitar la violencia contra las mujeres, y el programa de Apoyo a las Instancias de Mujeres en las Entidades Federativas para Implementar y Ejecutar Programas de Prevención de la Violencia Contra las Mujeres (PAIMEF) está dirigido a apoyar acciones concretas de las Instancias de Mujeres en las Entidades Federativas para prevenir y atender la violencia contra las mujeres, ambos entregan apoyos que entregan presentan coincidencias e incluso atienden a la misma población objetivo.
Esta sección presentará una breve descripción de cada programa así como, los resultados y observaciones de las evaluaciones realizadas en el periodo 2008-2012 (Ver tabla 3) y la evolución de su presupuesto. Los cinco programas seleccionados dan cuenta
93 de 212

de una enorme heterogeneidad en la justificación que les dio origen, la población objetivo que atienden, los apoyos que otorgan y la calidad de sus evaluaciones. El grado de maduración y las diferencias atribuibles a cada programa influyeron en los resultados de sus evaluaciones, sin embargo, el objetivo de este ejercicio es identificar, y se podrá apreciar de forma más clara en el capítulo cuatro, las distintas capacidades de los programas para apropiarse de los hallazgos y resultados y la respuesta diferenciada que cada uno recibió en materia presupuestal. Se trata de identificar las variables que más influyeron para cumplir el propósito de la utilización instrumental de las evaluaciones.

Tabla 3. Evaluaciones realizadas a los Programas federales de Atención a Grupos Prioritarios y

Fortalecimiento de Capacidades en el periodo 2008-2012.

Periodo de Evaluación

Jornaleros Agrícolas

70 y más

PAIMEF

Coinversión Social

Fortalecimiento Transversalidad

2008-2009

EED

EI/ EED

EED

EP

S/E

2009-2010

EED

EED /EPB

EP /EED

EED

S/E

2010-2011

EED

Diagnóstico/ EED

EED

EED/ EE

ED / EED

2011-2012

ECR

ECR

ECR

ECR

ECR

2007-2012

Metaevaluación Metaevaluación Metaevaluación Metaevaluación S/E

Fuente: Elaboración propia con base en el PAE 2008-2012 y revisión de los portales de SEDESOL e

INMUJERES. EED: Evaluación específica de desempeño

EI: Evaluación de impacto

ECR: Evaluación de consistencia y resultados

EP: Evaluación de Procesos

EE: Evaluación especial

ED: Evaluación de diseño

EPB: Evaluación de percepción de beneficiarios

S/E: Sin evaluación

Programa de Atención a Jornaleros Agrícolas (PAJA) Este programa inició en 1990 y está dirigido a mujeres y hombres de 16 años o más y sus familias que laboran como jornaleros agrícolas63. Este grupo de la sociedad presenta condiciones de vulnerabilidad y exclusión social debido a las precarias condiciones de

63 El Programa depende de la Secretaría de Desarrollo Social (Sedesol) y está a cargo de la Dirección General de Atención a Grupos Prioritarios (DGAGP). Este programa está alineado con el Eje 3 “Igualdad de Oportunidades” del Plan Nacional de Desarrollo 2007-2012 y con el Objetivo 2 del Programa Sectorial de Desarrollo Social que busca: “Abatir la marginación y el rezago de los grupos vulnerables para proveer igualdad en las oportunidades, permitiéndoles desarrollarse con independencia y plenitud”.
94 de 212

trabajo que enfrentan: carencias de infraestructura básica y de servicios, oportunidades
de trabajo insuficientes, migración, trabajo infantil, deterioro de la salud y transmisión
intergeneracional de la pobreza. Las cifras para el año 2010 registraban que 69.7% de los
jornaleros agrícolas era pobre y 24.7% se encontraba en extrema pobreza. La mayoría de
estos trabajadores oscilan entre los 12 y 40 años de edad. Los niños empiezan a trabajar entre los 7 y 8 años y según la ENIGH64 2010, 52.56% de los jornaleros agrícolas enfrentaba rezago educativo y 35.22% no tenía la primaria completa65.
De acuerdo a la Evaluación de Consistencia y Resultados 2011 (ECR), el Programa
estimó una población potencial de “aproximadamente 3.3 millones de personas que
representa poco más de 621 mil hogares (68.6% de los hogares de jornaleros
identificados)”. Su población objetivo se define a partir del Sistema de Regiones de
Atención a la Población Jornalera Agrícola (175 regiones de atención jornaleras, en 1,095 municipios y 118,079 localidades distribuidas en 27 estados)66 diseñado y estimado por
SEDESOL. Dicha población objetivo representa 20.1 % de la población potencial que
incluye a los jornaleros agrícolas y miembros de su hogar (ECR, 2011).
Ante esta problemática, el gobierno federal implementó, desde 1990, el
Programa de Atención a Jornaleros Agrícolas a fin de contribuir a la protección social de
los jornaleros agrícolas y los integrantes de su hogar. Su objetivo específico es:
“Contribuir a la ampliación de capacidades de los jornaleros agrícolas y los integrantes de
64 Encuesta Nacional de Ingresos y Gastos de los Hogares 65 Evaluación Integral del Desempeño de los Programas Federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades 2010-2011. 66 Una de las observaciones reiteradas del Programa en el documento “posición institucional” es que la cuantificación de la población potencial se dificulta debido a las características de los jornaleros agrícolas y a los problemas que genera la migración para la focalización de este grupo. Por ello, la revisión y actualización de la población potencial está en función de la disponibilidad de información tanto de la ENIGH (cada 2 años), Censos (cada 10 años), y la ENJO (Encuesta Nacional de Jornaleros agrícolas que no tiene fecha de levantamiento específica), situación que hace más difícil la planeación de mediano y largo plazo.
95 de 212

su hogar, otorgando apoyos en alimentación, salud, infraestructura, educación e
información, y promoviendo su acceso a los servicios básicos” (Reglas de Operación,
2012) y atiende las carencias de este grupo de la población mediante un conjunto de
apoyos clasificados en Apoyos Directos a la Población Jornalera Agrícola67; Apoyos para
infraestructura68, y Acciones para el Desarrollo de la Población Jornalera69.
A partir de 2008, el Programa ha sido sujeto de evaluación dentro de la lógica de
orientación por resultados que implementó el gobierno federal. En un periodo de cuatro
años, el Programa tuvo en tres ocasiones (2008-2009, 2009-2010 y 2010-2011)
evaluaciones específicas de desempeño70; en 2011 tuvo una evaluación de consistencia y
resultados y una metaevaluación que incluyó el periodo 2007-2012.
67 Apoyos Alimenticios a los Niñas y Niños (consisten en hasta dos alimentos diarios con costo de la dieta por un monto máximo de $480.00 mensuales por niño o niña); Estímulos para la Asistencia y Permanencia Escolar (apoyos económicos a los padres o tutor que cumplan con la corresponsabilidad de asistencia regular de los niños de hogares jornaleros, incluidos los niveles: preescolar, primaria y secundaria. Los montos varían por nivel y grado, en secundaria además se considera el sexo) y Apoyo Económico al Arribo (un apoyo económico de $800.00 al jefe o jefa del hogar jornalero por un máximo de tres ocasiones en el ejercicio fiscal cuando notifiquen su condición de migrante). 68 Subsidios para la construcción, rehabilitación, ampliación, acondicionamiento y equipamiento de infraestructura para atender a la población jornalera agrícola en las subregiones de atención jornalera. Incluyen los rubros de desarrollo infantil, como guarderías y estancias; servicios de atención a la salud; espacios para la estancia temporal, como albergues y vivienda temporal; infraestructura para la atención de la población jornalera agrícola; mesas de atención temporales como las ventanillas; y atención, alojamiento temporal e información como las mesas de atención permanentes. 69 Servicios de acompañamiento a la población jornalera agrícola (acciones de atención, información y orientación y además, se ofrecen apoyos temporales de alojamiento, alimentación y almacenamiento de pertenencias); Acciones de promoción y participación social (promoción de los derechos humanos, derechos del niño y derechos laborales; educación para la protección contra la explotación y abuso sexual de los menores; violencia de género; migración; hábitos saludables; saneamiento básico; contraloría social; desarrollo personal; cuidados de la salud; cuidado del medio ambiente; educación para aminorar los daños provocados por desastres naturales, entre otros); Apoyos especiales para contingencias (gastos por contingencias como transportación de regreso a su lugar de origen, pago de servicios médicos y sanitarios, y gastos funerarios); Acciones para potenciar el desarrollo (vinculación con otras instituciones para que tengan acceso a los apoyos de otros programas, como el de Desarrollo Humano Oportunidades y del Desarrollo de Zonas Prioritarias). 70 Las observaciones de las evaluaciones específicas de desempeño se circunscriben a los resultados anuales que arroja el Programa, se puede decir que este tipo de evaluaciones aportan información sobre una fotografía en el tiempo porque no capta los cambios que tiene el programa en un periodo más amplio. En general, se reportan los avances en materia de indicadores conforme a la información disponible así como se identifican los avances de los Aspectos Susceptibles de Mejora.
96 de 212

Aunque esta investigación no pretende evaluar a los programas o la calidad de sus
evaluaciones, es importante resaltar que en conjunto, las evaluaciones observaron
importantes cambios en la definición de los objetivos del programa, la modificación
gradual de los apoyos entregados y la redefinición de la población objetivo. El Programa
ha utilizado los resultados de las evaluaciones externas para mejorar su operación. La
última evaluación realizada, consistencia y resultados 2011 (ECR, 2011), señala que el
Programa ya se encuentra alineado con los objetivos del Programa Sectorial de
Desarrollo Social 2007-2012 y con el Plan Nacional de Desarrollo 2007-2012; cuenta con
padrón de beneficiarios y reglas de operación que se actualizan anualmente. Además, ha
mejorado el diseño de su matriz de indicadores y en consecuencia, redefinió indicadores
y algunas actividades y procesos; asimismo, cuenta con instrumentos de planeación y
orientación, y con una recolección sistemática de información. La ECR 2011 señala que a
partir de 2007, se observaron avances en el cumplimiento del 95% a las
recomendaciones derivadas de las evaluaciones externas. En particular, destaca el
informe, la dependencia adoptó 14 Aspectos Susceptibles de Mejora que se reflejaron en
23 actividades de mejora implementadas a partir de 200871.
71 Dichos compromisos se ven reflejados en Aspectos Susceptibles de Mejora encaminados a 1) Establecer metas retadoras y factibles de alcanzar para todos los indicadores de la Matriz de Indicadores para Resultados 2012 del programa; 2) Realizar un documento de Planeación Estratégica, que incluya metas de mediano y largo plazo; 3) Expresar claramente el diseño del programa en las Reglas de Operación y la Matriz de Indicadores dando mayor claridad y congruencia a sus diversos elementos; 4) Cuantificar la población potencial y objetivo; 5) Especificar indicadores de resultados en relación a la población objetivo en la matriz de indicadores; 6) Realizar una evaluación de satisfacción de la población atendida; 7) Realizar un diagnóstico del programa identificando el problema que el programa pretende resolver; 8) Revisar los tipos de apoyo que otorga el programa considerando la posibilidad de concentrar esfuerzos en aquéllos que tienen mayor impacto en la población; 9) Definir claramente la población potencial y objetivo de acuerdo con el problema que el programa pretende resolver y a las restricciones institucionales; 10) Mejorar la información de los beneficiarios tanto en los padrones como en las bases de datos del programa, para conocer con qué tipo de apoyos fue beneficiado cada uno; 11) Definir metas viables para los indicadores, en función de la población que se desea atender; 12) Contar con una agenda de evaluación de resultados de los programas sociales, privilegiando las evaluaciones de impacto y de seguimiento a beneficiarios, previo análisis de factibilidad; 13) Continuar con el Proceso de mejora de las Matrices de Indicadores para Resultados documentando la solidez técnica de los indicadores, su relevancia, el
97 de 212

Sin embargo, las evaluaciones encontraron “posibles coincidencias en los componentes y población” de otros programas federales72; y además, es reiterada la
observación sobre la necesidad de definir de forma más clara a la población objetivo.
También señala que aunque cuenta con un diagnóstico del problema que atiende, falta
por definir el alcance de lo que debe entenderse por “condiciones de vulnerabilidad” y
“exclusión social” en la operación del Programa. Asimismo, aunque el Programa cuenta
con una matriz de resultados, aún existen problemas en la lógica vertical de ésta. Ante la
ausencia de evaluaciones de impacto u otros estudios o investigaciones nacionales o
internacionales sobre intervenciones similares, no es posible conocer los impactos que
éste ha generado.
Por su parte, la metaevaluación señala que aún existen ambigüedades e
inconsistencias en el problema focal. Recomienda alinear conceptualmente las
definiciones del diseño con el fin y propósito del programa; asimismo, sugiere empatar el
objetivo general con el específico y finalmente, propone una agenda de evaluación para
el nuevo periodo de la administración federal (2013-2018).
En materia presupuestal (ver Tabla 4), podemos observar que el programa tuvo
en promedio incrementos presupuestales del 25 por ciento aún con las observaciones
hechas por las evaluaciones en el sentido de mejorar su focalización. Sin embargo, en el
establecimiento de líneas de base y metas, y 14) Actualizar y difundir los diagnósticos de los problemas que atienden los programas sociales, documentando la medición de la población potencial y objetivo para su incorporación en las estrategias de cobertura, cambios en el diseño y definición de estrategias óptimas de atención. 72 Entre los mencionados se encuentran el Programa 3x1 con el Subprograma de Movilidad Laboral Interna del Programa de Apoyo al Empleo de la Secretaría del Trabajo y Previsión Social; Programa de Desarrollo Humano Oportunidades, de la Secretaría de Desarrollo Social; Programa de Estancias Infantiles para Apoyar a Madres Trabajadoras, SEDESOL; Programa de Abasto Rural a cargo de Diconsa, SEDESOL; Programa de Becas para Madres Jóvenes y Jóvenes Embarazadas Programa de Educación Básica para Niños y Niñas de Familias Jornaleras Agrícolas Migrantes, SEP; Programas de acciones compensatorias para abatir el rezago educativo en educación inicial y básica (CONAFE); y con el Programa Vete Sano y Regresa Sano de la Secretaría de Salud y el Programa de Desarrollo de Zonas Prioritarias de la SEDESOL, respectivamente.
98 de 212

año 2011 cuando los resultados de la ECR fueron más favorables el presupuesto tuvo un decremento del 25 por ciento, este comportamiento del presupuesto pareciera reflejar que no hay relación entre resultados de evaluaciones y asignación presupuestal. En el periodo considerado, los presupuestos tuvieron diferencias con respecto al monto original, pero se puede observar que las diferencias más significativas fueron en los años 2010 y 2011, la Evaluación de Consistencia y Resultados señaló que la diferencia para el 2011 se debió a cambios de la oferta y la demanda en la producción agrícola73. Sin embargo, para el último año de la administración del ex Presidente Felipe Calderón el presupuesto se recuperó nuevamente un 25 por ciento.

Tabla 4. Presupuesto del programa Jornaleros Agrícolas 2008-2012

Presupuesto (millones de pesos)

Año

Original

Modificado

Ejercido

porcentaje

Incremento

ejercido

porcentual

2008

199.88

196.69

178.97

90.99

*

2009

256.22

241.01

239.76

97.6

22.53

2010

316.39

306.26

269.14

87.9

27.07

2011

301.05

228.52

202.01

88.4

-25.38

2012

290.68

286.23

275.71

96.3

25.25

Fuente: Cuarto informe trimestral sobre el presupuesto ejercido 2008, 2009, 2010, 2011

y 2012, SEDESOL. Nota: pesos constantes con año base 2012. *= No se tomó en cuenta el

año 2008 porque a partir de ese año se implementó el Mecanismo de Seguimiento.

En los siguientes capítulos se describirán los factores que explican la aparente falta de

relación entre los resultados de las evaluaciones y las asignaciones presupuestales, en los

casos en lo que se presenta.

73 La Evaluación de Consistencia y Resultados (2011: 42) señala que la planeación del presupuesto de este Programa es “vulnerable a cambios de oferta y demanda en la producción de los subyacentes agrícolas. En este año [2011], hubo problemas climáticos (heladas y sequías) que influyeron en el movimiento migratorio de los jornaleros y con ello en la planeación presupuestaria de algunos apoyos del Programa”.S65
99 de 212

Programa 70 y más para adultos mayores
El programa 70 y más74 inició en el año 2007 como un programa que otorgaba un apoyo
económico de 500 pesos mensuales, que se entrega de forma bimestral, a personas
mayores de 70 años ubicadas en localidades rurales de hasta 2,500 habitantes. Además,
contemplaba talleres y actividades de promoción y participación social. El antecedente
inmediato de este Programa fue el componente que, en el año 2006, fue integrado al
Programa Oportunidades que atendía a adultos mayores de 60 años. La justificación que
dio origen a este tipo de intervención fue el diagnóstico75 en torno al problema que
enfrenta este grupo de la población, y a la experiencia de programas similares en otros
países, por ejemplo Chile. De acuerdo a la ENIGH 2010, 21.39% de los adultos mayores
formaba parte de la Población Económicamente Activa (PEA)76. Asimismo, 21.9% no tuvo
acceso a la seguridad social en ese mismo año; 10.9% presentaba carencias asociadas a la
calidad y espacios de la vivienda, y 16.7% carecía de acceso a servicios básicos en la
vivienda77. (Ver tabla 5)
74 El Programa depende de la Secretaría de Desarrollo Social (Sedesol) y su ejecución está a cargo de la Dirección General de Atención a Grupos Prioritarios (DGAGP). Este programa está alineado con el Eje 3 “Igualdad de Oportunidades” del Plan Nacional de Desarrollo 2007-2012; con el Objetivo 2 del Programa Sectorial de Desarrollo Social que busca: “Abatir la marginación y el rezago de los grupos vulnerables para proveer igualdad en las oportunidades, permitiéndoles desarrollarse con independencia y plenitud” y con la Estrategia 2.2: "Atender desde el ámbito del desarrollo social, las necesidades de los adultos mayores mediante la integración social y la equiparación de oportunidades y promover la asistencia social a los adultos mayores en condiciones de pobreza o vulnerabilidad, dando prioridad a la población de 70 años y más, que habita en comunidades rurales con los mayores índices de marginación". Para 2013 la población objetivo se orientó a la población de 65 años y más. 75 Los adultos mayores presentan rezago educativo; baja participación en el mercado laboral; mayor incidencia de enfermedades; mayor atención y cuidados médicos; exclusión social; dependencia de terceros para el desarrollo de las actividades diarias; carencia de redes sociales y de asociaciones destinadas a la atención de este segmento de la población. Estas condiciones de precariedad se agravan mucho más en áreas rurales. 76 Evaluación Integral del Desempeño de los Programas Federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades 2010-2011. 77 Datos obtenidos de la Evaluación Integral del Desempeño de los Programas Federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades 2010-2011, CONEVAL.
100 de 212

Tabla 5. Porcentaje de adultos mayores que viven en pobreza, 2010

Tipo de localidad

Pobreza*

Pobreza extrema*

Urbano

40.9%

6.3%

Rural

63.0%

18.9%

Total

46.9%

9.7%

Fuente: Evaluación Integral del Desempeño de los Programas

Federales de Atención a Grupos Prioritarios y Fortalecimiento de

Capacidades 2010-2011. *Son pobres quienes tienen al menos una

carencia social y un ingreso menor a la línea de bienestar (suma del

costo de la canasta alimentaria y la no alimentaria). ** La población en

pobreza extrema es la que tiene tres o más carencias sociales y un

ingreso menor a la línea de bienestar mínimo (costo de la canasta

alimentaria).

Ante esta problemática, el Programa busca “contribuir a abatir el rezago que

enfrentan los adultos mayores de 70 años y más mediante acciones orientadas a fomentar su protección social”78. Los apoyos entregados al beneficiario consisten en cuatro tipos: apoyos económicos79; acciones para aminorar el deterioro de la salud física y mental80; acciones para la protección social81 y, apoyos para la incorporación al sistema financiero nacional82.

Este Programa cuenta con un diagnóstico (2010); una evaluación de impacto

(2008-2009); tres de desempeño (2008-2009, 2009-2010 y 2010-2011), una de

consistencia y resultados (2011-2012), una metaevaluación (2007-2012), y además,

cuenta con una evaluación de satisfacción del usuario (2011); en todas éstas se

analizaron diversos aspectos específicos asociados a su diseño, operación y resultados.

De la revisión global de todas las evaluaciones se puede señalar que el Programa ha

78 Objetivo del nivel Fin, Matriz de Indicadores 2011. 79 Apoyos económicos mensuales con entregas bimestrales de 500 pesos y pago de marcha por única ocasión de 1,000 pesos. 80 Grupos de crecimiento, campañas de orientación social y jornadas y sesiones informativas. 81 Son servicios o apoyos para atenuar los riesgos por pérdidas en el ingreso o salud a través de la credencial del Instituto Nacional de las Personas Adultas Mayores (INAPAM), promoción de acceso a los servicios de salud (Seguro Popular) y promoción de la atención a la salud (Metaevaluación, 2007-2012). 82 Incorporación de los beneficiarios al esquema de bancarización. El programa asume los costos relacionados con la entrega de una tarjeta electrónica de una cuenta bancaria hasta por un monto de 300 pesos por ejercicio fiscal y por beneficiario (Metaevaluación, 2007-2012).

101 de 212

incorporado, en su mayoría, las recomendaciones de las evaluaciones externas. Las distintas evaluaciones hacen referencia a documentos de trabajo adoptados por la Dirección de Atención de Grupos Vulnerables de SEDESOL para dar seguimiento a los Aspectos Susceptibles de Mejora derivados de las evaluaciones externas. Los hallazgos de estas evaluaciones sirvieron para que el Programa modificara gradualmente los tipos de apoyo; fortaleciera las redes sociales con las que opera; mejorar la matriz de indicadores de resultados, tanto en su resumen narrativo como en los indicadores para monitoreo; mejorara los procesos relacionados con las condiciones en que se entregan los apoyos económicos; estandarizara otros procesos de operación del programa y, desarrollara acciones de coordinación y vinculación interinstitucional con otras instancias en diversos estados. La metaevaluación señala que existen “esfuerzos constantes por mejorar el programa a través de evaluaciones que retroalimentan su diseño, operación y resultados”.
Una de las evidencias más significativas del Programa, que la evaluación de impacto encontró, fue el efecto positivo de las transferencias otorgadas sobre las necesidades de alimentación y salud de los beneficiarios83. Además, se evidenció que el Programa contribuye a que una gran proporción de adultos mayores pueda dejar de trabajar, y la transferencia monetaria recibida permite incrementar el gasto total del hogar. A partir de estos resultados, el Programa decidió extender la cobertura a localidades de hasta 20,000 habitantes.
Las evaluaciones de desempeño y de consistencia y resultados identificaron cambios en los criterios de cuantificación y definición de la población potencial; se definió con
83 La evaluación de impacto encontró que el Programa influyó sobre una mejor percepción del estado de salud de los beneficiarios, mayor capacidad de decisión sobre sus gastos y mayor empoderamiento con respecto a sus decisiones, reducción de síntomas depresivos y de inseguridad alimentaria, mayor satisfacción con la vida y un efecto sobre la dieta y el consumo de ciertos alimentos.
102 de 212

mayor claridad el problema que atiende y se modificaron las reglas de operación;
asimismo, se alcanzaron las metas de los indicadores; se modificó tanto el Propósito
como el Fin de la MIR 2011 y se elaboró un documento de planeación estratégica. Se
tiene identificado que el programa está alineado al Programa Sectorial de Desarrollo
Social y al Plan Nacional de Desarrollo. Estas evaluaciones señalan que en los periodos
evaluados, la atención de la población objetivo rebasó las metas inicialmente planteadas.
Cabe señalar a partir del segundo semestre del 2009, el Programa se extendió a localidades de hasta 30, 000 habitantes84 y en el 2012, las Reglas de Operación
incorporaron a todas las localidades urbanas y rurales, con la única condicionante de que
el beneficiario no recibiera alguna otra pensión contributiva.
Finalmente, la metaevaluación recomendó, para los próximos años, planear una
nueva agenda de evaluación que considere el diagnóstico del problema, evaluación de
diseño, impacto, procesos y de consistencia y resultados debido a que la ampliación de la
cobertura de adultos mayores en localidades urbanas y rurales, redefinió el objetivo
original y los alcances del mismo. Además, insistió en darle seguimiento a algunas
recomendaciones no atendidas identificadas en las evaluaciones anteriores.
Asimismo, podemos observar que aunque las evaluaciones señalaron los cambios de
mejora que realizó el programa en este periodo, el presupuesto que recibió tuvo un
incremento promedio del 19 por ciento para los años 2009, 2010 y 2012, excepto para el
año 2011 cuyo monto disminuyó alrededor del 3 por ciento (Ver tabla 6). Para los años
84 La evaluación de consistencia y resultados recomendó una serie de acciones: integrar en un solo documento la estrategia de planeación y los planes anuales de trabajo; documentar las buenas prácticas de los gestores voluntarios para utilizarlas en las estrategias de mejora de la participación comunitaria y en la capacitación de los propios gestores voluntarios; actualización del diagnóstico que privilegie el estudio de la población de localidades urbanas para las cuales no se ha realizado una evaluación de impacto y finalmente, incluir un apartado en el que se señale que los adultos mayores de 70 años que se encuentren enfermos o discapacitados de manera permanente puedan solicitar su registro en el Programa aplicando el mismos procedimiento establecido para quienes no pueden ir a recibir el apoyo, incluyendo la visita del personal de la SEDESOL y la expedición de acreditación de la autoridad oficial.
103 de 212

2009 y 2012 el presupuesto tuvo aumentos significativos del 25.73 y 31.56, respectivamente; sin embargo, para el año 2010 apenas aumentó medio punto porcentual. Una explicación preliminar de estos cambios es que la lógica para realizar los incrementos obedeció más a la dinámica de cambio y al objetivo central de incrementar la cobertura, que a consideraciones rigurosas sobre el desempeño del programa.

Tabla 6. Presupuesto del Programa 70 y más, 2008-2012

Presupuesto (millones de pesos)

Año

Original

Modificado

Ejercido

porcentaje Incremento

ejercido porcentual

2008 2009

11,529.59 14,791.16

11,125.75 13,988.35

11,088.17 13,951.82

99.66 99.70

* 25.73

2010 2011

14,086.91 13,761.35

14,042.38 13,590.02

13,966.01 13,547.01

99.50 99.70

0.39 -3.22

2012

18,821.20

17,878.79

17,703.70

99.00

31.56

Fuente: Cuarto informe trimestral sobre el presupuesto ejercido 2008, 2009, 2010,

2011 y 2012, SEDESOL. Nota: pesos constantes con año base 2012. *=No se tomó

en cuenta el año 2008 porque a partir de ese año se implementó el Mecanismo de

Seguimiento.

Programa de Apoyo a las Instancias de Mujeres en las Entidades Federativas para Implementar y Ejecutar Programas de Prevención de la Violencia contra las Mujeres (PAIMEF) La atención del gobierno para erradicar la violencia contra las mujeres ha sido reciente. En los últimos años se comenzó a cuantificar, legislar y proponer una respuesta institucional ante este problema. Datos de la Encuesta Nacional sobre la Dinámica de las Relaciones en los Hogares 2006, revelan que a nivel nacional, 67 de cada 100 mujeres de 15 años y más vivieron algún incidente de violencia de pareja, comunitaria, laboral, familiar o docente, a lo largo de su vida. La violencia más frecuente es la que viven de la pareja (43.2%), le sigue la comunitaria (39.7%), la laboral (29%), la de tipo familiar

104 de 212

(15.9%) y la escolar (15.6%)85. Además, el Diagnóstico del PAIMEF 2009, reveló que estas
respuestas tardías para atender el problema responden a una “limitada capacidad
institucional para tomar acciones” en la materia86.
Ante este panorama, en 200587 el Estado decidió responder con una incipiente
política pública para atender el problema de la violencia por motivos de género a cargo
del Instituto Nacional de las Mujeres (INMUJERES), y a partir de 2006 la responsabilidad
quedó a cargo del Instituto Nacional de Desarrollo Social (INDESOL).
El objetivo general del programa88 es: “Contribuir a prevenir y atender la violencia
contra las mujeres, a través de las acciones que realizan las Instancias de Mujeres en las
Entidades Federativas” (Reglas de Operación, 2012). Para ello, se fortalecen las Instancias
de Mujeres en las Entidades Federativas (IMEF) mediante recursos federales destinados a
realizar acciones en la materia. Es decir, son las IMEF la población objetivo y para
beneficiarse de los recursos, éstas deben presentar proyectos que cumplan con ciertos
criterios y requisitos de participación según las Reglas de Operación y las mesas de
85 Datos obtenidos de la Evaluación Integral del Desempeño de los Programas Federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades 2010-2011. 86 El Diagnóstico 2009 señala que las causas principales del problema son: 1) la deficiente procuración e impartición de justicia, 2) instancias de mujeres en las entidades federativas con limitaciones institucionales, 3) escasa y deficiente oferta institucional de servicios especializados de atención directa a las mujeres en situación de violencia, 4) no reconocimiento de la violencia contra las mujeres como problema y 5) escasa coordinación entre actores sociales. En consecuencias, existe pérdida de credibilidad en las instituciones y el no ejercicio de derechos; ineficaz ejercicio de recursos, limitada y desigual cobertura de servicios que en conjunto, provocan alta incidencia y prevalencia de casos de violencia contra las mujeres. 87 Este programa surgió de la iniciativa de la Cámara de Diputados para cumplir con los compromisos internacionales suscritos por México en la materia en el marco de la Convención Interamericana para prevenir, sancionar y erradicar la violencia, conocida como la “Convención Belem do Para”; en la Convención sobre la eliminación de todas las formas de discriminación contra la mujer (CEDAW, por su acrónimo en inglés), en el marco de las Naciones Unidas, y en la Declaración y Plataforma de Acción de Beijing. 88 Este programa está alineado con el Eje 3 “Igualdad de Oportunidades” del Plan Nacional de Desarrollo 2007-2012; con el Objetivo 2 del Programa Sectorial de Desarrollo Social que busca: “Abatir la marginación y el rezago de los grupos vulnerables para proveer igualdad en las oportunidades, permitiéndoles desarrollarse con independencia y plenitud”.
105 de 212

revisión que sirven para dictaminar los proyectos aprobados. Gran porcentaje de los
recursos de este programa se opera a nivel estatal mediante otros actores sociales como
las instituciones estatales y las organizaciones de la sociedad civil especializadas en la
materia. Los apoyos del Programa consisten en recursos federales como subsidios para apoyar el fortalecimiento institucional89.
Entre 2008 y 2012 se realizaron un total de seis evaluaciones externas al
Programa, en las cuales se analizaron diversos aspectos específicos asociados a su
diseño, operación y resultados. Se llevaron a cabo tres evaluaciones de desempeño
(2008, 2009 y 2010), una de procesos (2009), una de consistencia y resultados (2011) y
como los programas anteriormente analizados, una metaevaluación (2007-2012). Por
recomendación de estas evaluaciones se elaboró un marco lógico, árbol de problemas y
se rediseñó la matriz de indicadores. A partir de las recomendaciones de evaluaciones
anteriores se instalaron mesas de revisión de los proyectos presentados por las IMEF;
mecanismos para detectar duplicidades con otros programas, y se elaboró un diagnóstico
del problema que atiende (Evaluación de Desempeño, 2008). Además, se rediseñaron los
indicadores para corregir la unidad de medida, frecuencia de medición y método de cálculo; se elaboró un índice de medición para transparentar los recursos del Programa90;
89 Se llevan a cabo acciones y prácticas de prevención y detección de la violencia contra las mujeres dirigidas a la población en general; generación y difusión de estudios, investigaciones, sistemas de información y bases de datos en la materia y, creación de refugios, casas de tránsito, unidades móviles, módulos de atención y orientación, líneas telefónicas y ventanillas de información para las mujeres y sus hijos que sufren violencia
90 En el periodo 2006-2007 la distribución de los recursos entre las IMEF fue equitativa. Sin embargo, para 2008 se consideraron otros factores que permitieran reconocer las diferencias entre las entidades federativas. Se utilizó el Índice de Rezago Social del CONEVAL y el porcentaje de mujeres mayores de 15 años con algún tipo de violencia establecido en el Índice de Rezago Social de la Encuesta Nacional sobre la Dinámica de las Relaciones en los Hogares (ENDIREH 2006), De esta forma, 15% de los recursos eran asignados según el componente del Índice de Rezago Social y para 2011, también se incluyó un componente poblacional (15%) derivado de la Encuesta Nacional de Ocupación y Empleo (ENOE) del INEGI (Metaevaluación, 2012).
106 de 212

se afinaron los procesos relativos a la presentación de proyectos, financiamiento y ejecución de los mismos (Evaluación de Desempeño, 2009). La Evaluación de Desempeño 2010, no emitió valoración de los indicadores de resultados y de gestión, situación que no permite conocer si los indicadores cumplieron con un buen diseño y desempeño.
A partir de la evaluación de procesos (2009), las siguientes evaluaciones coincidieron en señalar que aunque los indicadores del Programa superaban las metas planeadas, el diseño y el propósito del programa eran incompatibles: por una parte, se buscaba fortalecer las capacidades institucionales de las IMEF y por otra, atender el problema de la violencia contra las mujeres en los estados. Este problema en la lógica causal del Programa estaba provocando problemas de planeación entre las IMEF y el PAIMEF. La evaluación de consistencia y resultados (2012) insistió en cambiar la redacción de nivel Fin y Propósito, señaló que el indicador de Fin aún presentaba problemas. Señaló que no se había atendido la recomendación relativa a la elaboración de planeación estratégica91. Además, menciona que el Programa no cuenta con información sistematizada que permita conocer la demanda total de apoyos y características de los solicitantes, ni tampoco cuenta con instrumentos para medir la satisfacción de las IMEF. Esta evaluación así como la metaevaluación 2012, recomendó aumentar el presupuesto que recibe.
La metaevaluación 2012 señaló además que el programa no tiene evaluaciones que reflejen sus resultados tanto en la disminución de la violencia contra las mujeres, como en el fortalecimiento institucional de las IMEF, e insistió en las inconsistencias y ambigüedades de la lógica causal del programa: “El problema focal del programa, centrado en la capacidad institucional limitada de las IMEF para prevenir y atender la
91 A enero de 2011 el programa ya contaba con un documento de planeación con un 70% de avance. 107 de 212

violencia contra las mujeres, no es consistente con el objetivo general, centrado la

prevención y atención de la violencia contra las mujeres, trata dos problemas distintos”.

De la misma manera que las metaevaluaciones de los otros programas analizados, se

recomendó una agenda de evaluación para los próximos seis años.

Finalmente, en materia de presupuesto podemos observar que el programa sólo

tuvo un incremento significativo (casi del 17 por ciento) hasta el último año de la gestión

del ex Presidente Felipe Calderón (Ver tabla 7). En los años anteriores sólo se puede

observar que el presupuesto disminuyó o que el incremento solamente alcanzó el uno

por ciento. De las evaluaciones se puede señalar que durante el periodo analizado, el

PAIMEF tuvo muchos cambios que mejoraron su implementación pero aún tiene

pendientes importantes por resolver, sobre todo en la lógica causal del programa. En

este sentido, los resultados de las evaluaciones no permiten realizar una explicación

preliminar de la lógica que motivó la asignación presupuestal. En principio, parecería que

no hay ninguna relación, y que el incremento del último año sólo se explica por criterios

discrecionales.

Tabla 7. Presupuesto del programa PAIMEF, 2008-2012

Presupuesto (millones de pesos)

Año

Original

Modificado

Ejercido

porcentaje Incremento

ejercido porcentual

2008

228.81

228.81

227.45

99.4

*

2009

220.91

207.49

207.31

99.9

-9.32

2010

210.24

209.76

209

99.5

1.1

2011

210.21

207.37

206.46

99.6

-1.14

2012

250

242.53

241.91

99.7

16.95

Fuente: Cuarto informe trimestral sobre el presupuesto ejercido 2008, 2009, 2010,

2011 y 2012, SEDESOL. Nota: pesos constantes con año base 2012. *=No se tomó

en cuenta el año 2008 porque a partir de ese año se implementó el Mecanismo de

Seguimiento.

108 de 212

Programa de Coinversión Social
Este Programa fue creado desde 1993 y dependía de la Unidad de Concertación Social de
SEDESOL como Fondo de Coinversión Social. Sin embargo, a partir de 1995 este fondo se transformó en Programa de Coinversión Social92 y en la actualidad INDESOL está a cargo
de ejecutarlo. Su objetivo, según las Reglas de Operación 2012, es “contribuir a la
generación de capital social mediante el fortalecimiento de actores sociales”. Su objetivo
específico es “fortalecer a los actores sociales que promueven el desarrollo social de los
grupos en situación de vulnerabilidad y rezago”. La población objetivo que atiende son
actores sociales clasificados en tres tipos: instituciones de educación superior, centros de investigación y organizaciones de la sociedad civil93 que realizan actividades para
promover el desarrollo social de los grupos prioritarios.
En 2009 se identificó, a partir del Diagnóstico realizado, que el problema central
que atiende el Programa es la presencia de actores sociales débiles y desarticulados para
promover el desarrollo social de los grupos prioritarios. Entre las causas identificadas se
encuentran: prácticas autogestivas limitadas; mecanismos limitados de participación
ciudadana; sinergias limitadas entre actores sociales; desarrollo institucional limitado y
recursos financieros y materiales limitados. Por esta razón, el programa entrega recursos
económicos, clasificados como subsidios, para la ejecución de proyectos de coinversión
social. A su vez, los actores sociales beneficiados llevan a cabo proyectos que contribuyen
a la promoción del desarrollo humano y social de la población vulnerable;
92 Al igual que los programas sociales anteriormente explicados, Coinversión Social está alineado con el Eje 3 “Igualdad de Oportunidades” del Plan Nacional de Desarrollo 2007-2012 y con el Objetivo 2 del Programa Sectorial de Desarrollo Social que busca: “Abatir la marginación y el rezago de los grupos vulnerables para proveer igualdad en las oportunidades, permitiéndoles desarrollarse con independencia y plenitud”. 93 Hasta el año 2010, este Programa también atendía a los municipios, sin embargo, como consecuencia del diagnóstico elaborado en 2009, se determinó sacar a estos actores de la población objetivo argumentando que los municipios no son actores de la sociedad sino una de las tres instancias de gobierno.
109 de 212

fortalecimiento y profesionalización de los actores sociales, y realizan investigación que contribuya a generar conocimiento sobre la temática.
En el periodo 2008-2012, el programa fue sujeto a seis ejercicios de evaluación: una de procesos (2008), dos de desempeño (2009 y 2010), una evaluación especial para conocer los efectos del programa en la construcción de capital social (2010), una de consistencia y resultados (2011) y una metaevaluación (2007-2012). Mediante un análisis conjunto de las evaluaciones se puede señalar que el programa cumplió con un importante porcentaje de Aspectos Susceptibles de Mejora. Entre los cambios identificados se encuentra: una constante revisión de sus indicadores que reflejan los componentes de la matriz de indicadores; cuenta con un diagnóstico del problema; tiene una presentación clara de su diseño y componentes; cuenta con un sistema que le permite monitorear su desempeño; presenta una evolución de su cobertura, tiene una medición del grado de satisfacción de la población atendida y ha dado seguimiento a los requerimientos institucionales de orientación presupuestaria a resultados. La Evaluación de Consistencia y Resultados (2011) señala: “Es un programa abierto a la evaluación continua y dispuesto a mejorar aspectos de su desempeño que surgen de ejercicios como el que ahora se presenta”.
La evaluación de procesos (2008) encontró como hallazgos que el programa no contaba con mecanismos para el seguimiento de proyectos; la operación no estaba alineada con lo establecido en la matriz de indicadores; los procesos se orientaban más a apoyar a las organizaciones de la sociedad con experiencia que a las nuevas; no se contaban con mecanismos sistematizados de difusión de resultados y era necesario realizar la planeación estratégica para dar rumbo al programa. Le evaluación de desempeño 2009, recomendaba modificar los indicadores de resultados (Fin y
110 de 212

Propósito); sugería definir “capital social” y “actores sociales fortalecidos”; sistematizar el seguimiento a proyectos apoyados; documentar casos exitosos e implementar una estrategia de difusión del programa. Muchos de los hallazgos señalados los retoma de la evaluación de procesos 2008, así como también lo hace la evaluación de desempeño 2010. Esta última señala que se modificó el resumen narrativo del Fin en la matriz de indicadores, y este cambio se reflejó en las Reglas de Operación (ROP) del siguiente año. Se estableció coordinación con la Comisión Nacional para el Desarrollo de los Pueblos Indígenas para la difusión del programa y se mejoró el proceso de dictaminación de los proyectos aprobados.
La evaluación complementaria sobre los efectos del programa en la construcción del capital social 2010, permitió definir el concepto capital social y fortalecimiento institucional y se recomendó vincularlos al proceso operativo del programa; propuso la creación de una cédula de identificación de los actores sociales con mayor o menor fortalecimiento institucional y capital social; modificar los formatos de presentación de los proyectos que recibe el programa para definir claramente la población objetivo que es beneficiada, los objetivos, los bienes y servicios que se entregan y la zona de influencia de los proyectos; mayor coordinación interinstitucional para promover sinergias con programas similares; fortalecer las redes de vinculación y colaboración entre los actores sociales; establecer mecanismos para identificar proyectos exitosos y/o buenas prácticas, así como la sistematización de las personas atendidas por los actores sociales. Se concluyó que este programa tiene efectos en el fortalecimiento institucional de los actores sociales y en el capital social de los mismos. La evaluación de consistencia y resultados 2011, señaló que el programa no presenta duplicidad con algún otro programa del gobierno federal y que de los 32 aspectos susceptibles de mejora,
111 de 212

específicos e institucionales, todos se resolvieron. Sin embargo, existen 21

recomendaciones no atendidas de la evaluación de procesos y recomienda hacer una

evaluación de impacto.

Finalmente, la metaevaluación 2012 señala que no existe una claridad en la

consistencia lógica del programa: no se identifica una relación causal entre el problema

que atiende y los objetivos del programa. Cuestiona la definición de la población objetivo

y potencial: “Ambas se centran en los actores sociales y no propiamente en los grupos

vulnerables, y no queda clara la justificación para apoyar a los actores sociales por sí

mismos”. Además, señala que los componentes del programa no son suficientes para el

logro de resultados; no se conoce el desempeño y los resultados reales de los proyectos

apoyados. Se recomienda redefinir el problema focal y alinear la nueva población

objetivo.

Tabla 8. Presupuesto del programa Coinversión Social, 2008-2012

Presupuesto (millones de pesos)

Año
2008 2009

Original
239.72 396.36

Modificado
318.85 383.90

Ejercido
317.12 378.04

porcentaje ejercido 99.5 98.5

Incremento porcentual
*
20.40

2010

377.22

444.29

442.80

99.7

2011

360.20

370.20

367.45

99.3

15.73 -16.67

2012

395

432.31

430.57

99.6

16.78

Fuente: Cuarto informe trimestral sobre el presupuesto ejercido 2008, 2009, 2010, 2011 y

2012, SEDESOL. Nota: pesos constantes con año base 2012. *=No se tomó en cuenta el año

2008 porque a partir de ese año se implementó el Mecanismo de Seguimiento.

En materia de presupuesto, el programa tuvo un incremento promedio de 17.63 por ciento para los años 2009, 2010 y 2012. Como en los otros programas considerados para el análisis, en el año 2011 también disminuyó su presupuesto (16.67 por ciento); sin embargo, pareciera que esa misma cantidad se compensó para el siguiente año. Cabe destacar que aunque la Evaluación de Consistencia y Resultados 2011 señaló que el programa aún tenía 21 recomendaciones pendientes por atender, los recursos para el

112 de 212

siguiente año aumentaron casi 17 por ciento. El incremento del presupuesto de 2011 a 2012 no encuentra ninguna justificación ante el panorama descrito, lo que sugiere necesariamente, como en el caso de los programas PAJA y PAIMEF, discrecionalidad, criterios diversos o compromisos clientelares con los beneficiarios. (Ver tabla 8) Programa de Fortalecimiento a la Transversalidad de la Perspectiva de Género Este programa fue creado a finales de 2009 por el Instituto Nacional de las Mujeres94, organismo sectorizado a la Secretaría de Hacienda, sin embargo, comenzó a operar como un programa sujeto a Reglas de Operación a partir del 2010. Su implementación responde a la legislación nacional y compromisos internacionales95 sobre la materia. Su objetivo, según las Reglas de Operación 2011, es: “Contribuir a la institucionalización de la perspectiva de género en las políticas públicas en las entidades federativas para lograr la disminución de las brechas de desigualdad entre mujeres y hombres”.
Así como el PAIMEF, este programa también identifica como población objetivo a las 32 Instancias de Mujeres en las Entidades Federativas (IMEF). Sin embargo, entrega recursos a las IMEF para financiar proyectos que fortalezcan su capacidad de incidencia en las instancias de gobierno de las entidades federativas, municipios y órganos legislativos a fin de que incorporen políticas públicas y cultura institucional con equidad de género.
94 Este programa es la continuidad del Fondo de Fomento para la Transversalidad de la Perspectiva de Género creado en 2008, producto de la fusión con el Fondo de apoyo a los mecanismos para el adelanto de las mujeres en las entidades federativas para la atención integral de las mujeres víctimas de la violencia de género. 95 Ley General para la Igualdad entre Mujeres y Hombres; Ley General de Acceso de las Mujeres a una Vida Libre de Violencia; Programa Nacional para la Igualdad entre Mujeres y Hombres y a la Convención sobre la eliminación de todas las formas de discriminación contra la mujer de las Naciones Unidas.
113 de 212

Debido a su reciente creación, el Programa96 sólo cuenta con tres evaluaciones en el periodo 2008-2012: una de diseño (2010), una de desempeño (2010) y una de consistencia y resultados (2011-2012). La primera evaluación señaló que la falta de un diagnóstico integral del problema que atiende dificulta una comprensión clara de la lógica causal que le dio origen. Esta situación provoca que los objetivos a nivel de Componente y Actividades deban ser reformulados, se alineen adecuadamente los indicadores a los objetivos procurando una relación lógica entre ellos, se atienda la falta de lógica vertical y horizontal de la matriz de indicadores, y se definan los medios de verificación de la matriz. Además, se recomienda mantener estrecha coordinación con el PAIMEF porque comparten algunos objetivos y su población objetivo97.
La evaluación de desempeño señala que debido a la reciente creación del programa, hasta 2010 no estaba sujeto al Mecanismo de Seguimiento derivados de informes y de evaluaciones externas, fue a partir de 2011 que el programa los implementó. Reconoce que las recomendaciones derivadas de la evaluación de diseño se implementaron en las Reglas de Operación 2011, sin embargo, insistió en realizar un ejercicio sistemático para identificar y caracterizar el problema central en el que se propone incidir, sugiere revisar detalladamente las definiciones de población potencial,
96 Este programa está alineado con el Eje 3 “Igualdad de Oportunidades” del Plan Nacional de Desarrollo 2007-2012; así como al Programa Nacional para la igualdad entre Mujeres y Hombre96 (PROIGUALDAD) del Inmujeres. 97 Se encontró complementariedad con otros programas federales: Estancias infantiles para apoyar a madres trabajadores y Programa de Apoyo a las Instancias de Mujeres en las Entidades Federativas para Implementar y Ejecutar Programas de Prevención de la Violencia contra las Mujeres ( PAIMEF) de Sedesol; Organizaciones productivas para mujeres indígenas de la Comisión Nacional para el Desarrollo de los Pueblos Indígenas; el Fideicomiso del Programa del fondo de microfinanciamiento a mujeres rurales de la Secretaría de Economía; Programa de la mujer en el sector agrario de la Secretaría de la Reforma Agraria, y el Fondo para el desarrollo de las instancias municipales de las mujeres también de Inmujeres.
114 de 212

objetivo y atendida, y realizar revisiones continuas de la lógica vertical y horizontal en la

matriz de indicadores

Finalmente, la evaluación de Consistencia y Resultados 2012 reitera que la falta

de un diagnóstico del problema incide en la ambigüedad de la población potencial y la

población objetivo. Señala que no existe una justificación que sustente el tipo de

intervención que ha realizado; y, recomienda replantear el árbol de problemas y el de

objetivos; alinear la matriz de indicadores, mejorar las reglas de operación y definir

planes estratégicos y de trabajo anuales. Aunque el programa ya cuenta con un sistema

de información para verificar las etapas de recepción, registro, trámite de solicitudes de

apoyo, selección de proyectos y seguimiento a la ejecución de obras y acciones, no

cuenta con instrumentos de medición del grado de satisfacción de los beneficiarios, ni

tampoco de los efectos del programa en las políticas públicas con perspectiva de género.

Tabla 9. Presupuesto del programa de Fortalecimiento a

la Transversalidad de la Perspectiva de Género, 2008-2012

Presupuesto (millones de pesos)

Año

Original

Modificado

Ejercido

porcentaje

Incremento

ejercido

porcentual

2008

130.2196597

ND*

ND*

ND*

*

2009

260.7707836 198.3564247 197.7951445

99.7

*

2010

215.0466223 198.8643639 171.9405268

86.46

0.26

2011

209.8500692 151.478981 151.4479105

99.98

-23.83

2012

230.2

138.41

138.41

100

-8.63

Fuente: Informes Sobre la Situación Económica, las Finanzas Públicas y la Deuda Pública,

Anexos 2008, 2009, 2010, 2011, 2012 y 2013 de la Secretaría de Hacienda y Crédito Público.

Nota: pesos constantes con año base 2012. *=No se tomó en cuenta el año 2008 porque a

partir de ese año se implementó el Mecanismo de Seguimiento.

Debido a la falta de datos, sólo se puede mencionar que en materia de presupuesto este programa terminó el sexenio del ex Presidente Felipe Calderón con decrementos presupuestales. La disminución más importante fue en el año 2011, sin embargo, esta disminución coincide con el año en el que los otros programas analizados también presentaron el mismo comportamiento. Asimismo, cabe destacar que aunque el

115 de 212

programa es de reciente creación (2009), el incremento que obtuvo en materia de presupuesto para el siguiente año apenas fue del 0.26 por ciento. Una posible explicación al comportamiento de los recursos durante los tres años que operó bajo la administración del ex Presidente Calderón, quizá se deba a las continuas observaciones sobre las áreas de oportunidad que señalaron todas las evaluaciones. (Ver tabla 9)
Vale la pena comentar que además de la revisión de cada una de las evaluaciones que se aplicaron a los cinco programas, esta investigación también consultó la Valoración general del desempeño de los programas de desarrollo social, una herramienta de consulta pública del CONEVAL que contiene una valoración categórica de los programas sociales en temas como la forma en que los programas documentan sus impactos, seguimiento a beneficiarios; avance de los indicadores de fin y propósito de las matrices de indicadores (MIR) de los programas; valoración de las recomendaciones atendidas derivadas de evaluaciones externas; valoración de la evolución de la cobertura del programa, cumplimiento presupuestal, entre otras variables. Mediante un sistema de semáforos, esta base de datos realiza una valoración sintética de acuerdo con los siguientes rangos: Destacado, Adecuado, Moderado, Oportunidad de Mejora o ND, cuando no se cuenta con información disponible para la variable. Uno de los componentes de mayor valor de esta herramienta es que permite identificar el grado de progresividad de los programas. Para CONEVAL se considera “un programa muy progresivo o progresivo cuando distribuye, más que proporcionalmente, los bienes y/o servicios que otorga a beneficiarios de menores ingresos. En caso contrario, es decir cuando destina sus bienes o servicios a grupos de mayores ingresos, se considera
116 de 212

regresivo o muy regresivo”. En este sentido con base a una metodología rigurosa98, solamente el programa 70 y más es calificado como muy progresivo, para el resto de los cuatro programas no existe información disponible.
98 El Grado de Progresividad se mide con base en el Coeficiente de Concentración de los recursos del Programa presentado en el estudio "Gasto Público y Desarrollo Humano" realizado por John Scott para el Informe de Desarrollo Humano en México 2008-2009, y que el CONEVAL retomó en su Informe de Evaluación de la Política de Desarrollo Social en México, 2011. Si el coeficiente toma el valor igual o menor a 1.5 y mayor o igual que 1.25 entonces se considera que el programa es MUY PROGRESIVO; menor que 1.25 y mayor que 1 y es PROGRESIVO; menor que 1 y mayor que 0.75 es REGRESIVO y, un valor menor que 0.75 cuando es MUY REGRESIVO. En el caso de no conocer el grado de progresividad/regresividad se considera SIN INFORMACIÓN.
117 de 212

Capítulo 3. El comportamiento de los programas dirigidos a Grupos Vulnerables a partir de los resultados de las evaluaciones.
Este capítulo presenta la evidencia empírica para contestar las preguntas de investigación planteadas al inicio de esta tesis. A partir del universo de factores descritos en el marco teórico de esta investigación, se identificó que para el caso mexicano en las decisiones de mejora de los programas públicos de tipo social, influyen más el liderazgo y compromiso del operador del programa, la capacidad organizacional y la factibilidad de las recomendaciones que hacen los evaluadores. Estos tres elementos pertenecen a factores de tipo organizacional y también están relacionados con las características de las evaluaciones. Por otro lado, cuando el objetivo es aprobar el presupuesto, los criterios que mejor explican el comportamiento para asignar los recursos presupuestales son el factor político y el diseño institucional del sistema de evaluación.
Después de analizar la información recolectada se concluyó que no todos los factores mencionados en el capítulo uno, influyen de forma determinante en el caso mexicano, tal es el caso del factor relacionado a la accesibilidad a los resultados de las evaluaciones. Aunque no todos los actores involucrados en la toma de decisiones de política pública revisan sistemáticamente los informes de evaluaciones, la información de éstas es pública, cualquier ciudadano puede acceder a la información publicada en los portales de las dependencias y del CONEVAL y además, existen páginas de internet especializadas que en lenguaje ciudadano traducen los datos técnicos que producen las evaluaciones y el proceso presupuestal99. De igual manera, después de analizar de forma integral la influencia de los factores considerados se identificó que el factor relacionado con la oportunidad temporal con que están disponibles los informes de evaluaciones
99 Por ejemplo, www.transparenciapresupuestaria.gob.mx de la Secretaría de Hacienda.
118 de 212

para la toma de decisiones es un factor que está más relacionado con las características del diseño del sistema de evaluación que con las características propias de la evaluación. En este sentido, el marco legal del sistema indica las fechas en que esta información debe estar disponible para la consulta de los tomadores de decisiones, sobre todo para el proceso presupuestal, y como se desarrolla más adelante, los márgenes de tiempo o no coinciden o son muy reducidos para el análisis técnico que se requiere. De tal forma que la oportunidad temporal con que se presentan los resultados y hallazgos de estos informes es un factor que afecta más a las decisiones del presupuesto que a las decisiones de mejora de política pública.
El presente capítulo se divide en dos secciones: la primera se refiere a los cambios que realizaron los programas a través de los Aspectos Susceptibles de Mejora (ASM) en el marco de las decisiones del ciclo de mejora continua y además, describe cómo los factores que más influyeron en este tipo de decisiones afectaron a las cinco experiencias documentadas. La segunda sección se refiere a los factores que influyeron en las decisiones de tipo presupuestal para la distribución final de los recursos presupuestarios.
3.1. Acciones de Mejora que se tradujeron en ASM de los programas de Atención a Grupos Vulnerables. De acuerdo con la información disponible, el siguiente análisis se centra en el avance y cumplimiento de los aspectos específicos e institucionales reportados por los cinco programas de Atención a Grupos Vulnerables con la finalidad de identificar qué acciones fueron seleccionadas directamente por los programas como compromisos de mejora. Los ASM específicos e institucionales son los únicos compromisos asumidos directamente por los programas para darles cumplimiento y el resto, los de tipo interinstitucional e
119 de 212

intergubernamental, son compromisos que se integran en un documento que el CONEVAL entrega a la Comisión intersecretarial de Desarrollo Social y a la Comisión Nacional de Desarrollo Social para que éstas determinen a los actores responsable, así como las acciones de solución para atenderlos. Por esta razón, esta tesis solamente centra su atención en el cumplimiento de los ASM específicos e institucionales. Recordemos que el Mecanismo de Seguimiento es un instrumento que tiene la finalidad de implementar un proceso de mejora continua en las áreas de oportunidad de los programas federales. En este sentido, el presente apartado permite conocer en qué grado los programas sociales analizados realizaron cambios para la mejora y en qué áreas específicas los implementaron.
Sin embargo, recordemos que la selección de ASM resulta de un proceso de discusión al interior de la dependencia que involucra a los actores que operan los programas y a veces, otras áreas de la dependencia que también participan, de tal forma en la actualidad es difícil conocer con precisión las razones que explican la selección de ciertas recomendaciones sobre el total de las sugeridas por los evaluadores. La información más cercana a este proceso fueron las opiniones que se publican por las dependencias en el documento de Posición Institucional, que sirve como justificación a las decisiones de implementar algunas acciones como ASM. De tal manera que el análisis que se presenta a continuación se hizo a partir de los Documentos de Trabajo que el Mecanismo de Seguimiento obliga a elaborar a las dependencias. En estos documentos sólo se registra la información relativa al ASM y sus respectivas actividades, el área responsable de implementarlas, fecha de término, los resultados esperados de estas acciones y los resultados concretos que se planean alcanzar. La calidad de los documentos de trabajo es variable, los casos documentados dan evidencia de que en
120 de 212

ocasiones existe diferencia en la claridad de la redacción, pero en otros casos, la calidad

se refleja en el alcance de acciones con las que los programas se comprometen. Por

ejemplo, un programa puede comprometerse con generar documentos y metodologías

sustantivas para la operación de los programas, mientras que en otro se limita a producir

documentos de planeación de reuniones y procesos administrativos que no se traducen

en una mejora real de la condición real de los beneficiarios.

A partir de la Tabla 10 se puede identificar que el caso de estudio conformado por

los cinco programas registró 96 ASM en el periodo 2008-2012, que se clasificaron de la

siguiente manera: 54 aspectos específicos, 32 institucionales, un interinstitucional, un

intergubernamental y ocho se reportaron sin datos por el Instituto Nacional de las Mujeres100. Es decir, más de la mitad están a cargo de las Unidades Responsables de

operar los programas y 33 por ciento involucra a otras áreas internas de la dependencia;

esto se traduce en que la mayor parte de los cambios que sugieren las evaluaciones

están en el campo de acción de las propias dependencias, y muy pocos dependen de

decisiones en el ámbito intersecretarial o intergubernamental.

Tabla 10. Número de ASM por programa 2008-2012

Programa

Específicos Institucionales Interinstitucionales Intergubernamentales

S/D

PAJA

2

13

0

0

0

70 y más

5

7

0

0

0

PAIMEF

14

7

0

0

0

PCS

31

5

0

0

0

Fortalecimiento a

la Transversalidad

2

0

1

1

8

Total

54

32

1

1

8

Fuente: Elaboración propia con base en información de los programas.

Si de estos 96 ASM desglosamos el avance y cumplimiento porcentual de los aspectos específicos e institucionales que deben reportar las Unidades Responsables de
100 Para conocer cada uno de los ASM seleccionados por los programas ver Anexo 1. 121 de 212

las tres dependencias (SEDESOL, INDESOL e INMUJERES), tenemos que 45 aspectos específicos (46.8 por ciento) y 28 aspectos institucionales (29 por ciento) fueron concluidos en el periodo 2008-2012, es decir, 76.04 por ciento del total de ASM fueron concluidos en un periodo de cinco años (Ver Gráfico 1). Los aspectos que están por debajo del cien por ciento, 11 ASM en total, continuarán con el proceso de cumplimiento en ciclos posteriores. Sobre este último punto vale la pena mencionar que todas las recomendaciones que se convierten en ASM son compromisos que se dan por cumplidos hasta que llegan al 100 por ciento de su avance en cada una de sus actividades. Como se mencionó en el capítulo anterior, las dependencias tienen la posibilidad de decidir las fechas límites para cumplir al 100 por ciento sus compromisos y en este sentido, solamente factores externos como la fusión de programas de un ejercicio fiscal a otro, la desaparición de éstos o cambios sustantivos en la operación de los mismos pueden ser motivos para que los ASM no lleguen a su cumplimiento total. En caso contrario, los ASM tarde o temprano se cumplen.
Gráfico 1. Avance porcentual de los ASM específicos e institucionales de los programas de Atención a Grupos Vulnerables.
Fuente: Elaboración propia con base en información de los programas.
Por otra parte, de acuerdo al gráfico 2, los cinco programas federales de las tres dependencias muestran, en conjunto, un avance en la conclusión de sus ASM de 84.3 por
122 de 212

ciento en el mismo periodo 2008-2012 (esto incluye ASM de tipo específico, institucional, interinstitucional e intergubernamental), lo que representa un alto nivel de cumplimiento formal. Por ejemplo, los programas PAJA y 70 y más reportaron la conclusión de sus ASM en más del 90 por ciento del total comprometido, mientras que el programa Coinversión Social concluyó el 77.7 por ciento en el mismo periodo.
Gráfico 2. ASM concluidos por programa 2008-2012
Fuente: Elaboración propia con base en información de los programas.
Sin embargo, un análisis más sustantivo de los ASM permitiría conocer de forma más específica cómo contribuyeron éstos al cambio de la política social relacionada con decisiones de mejora continua de los programas analizados. Para obtener este resultado, se aplicó un ejercicio de identificación de ASM con base en la información publicada en los Documentos de Trabajo por las dependencias, así como en la metodología del CONEVAL que clasifica el tipo de cambio en la política pública de acuerdo a las acciones que el programa decide implementar, y que a continuación se describe:
 Decisiones encaminadas a corregir actividades o procesos, es decir, aquellos programas que hicieron cambios relacionados con las actividades registradas en la MIR, cambios en sus procesos operativos, indicadores y todo lo relacionado a modificaciones no sustantivas de las Reglas de Operación;
123 de 212

 Reorientación del propósito del programa, son aquellas decisiones que llevan a cabo una mejor definición de la población objetivo, planeación estratégica, alineación de la MIR y una definición clara del problema que atienden;
 Modificar apoyos del programa, son aquellos cambios orientados a modificar los componentes de la MIR del programa, es decir, modificaciones o mejoras en los bienes o servicios que brinda;
 Adicionar o reubicar el programa, ASM que buscan reforzar el programa por medio de la generación de sinergias con otros o, incluso, la integración de dos o más programas en uno solo, así como acciones para que el programa sea operado por otra dependencia, entidad o unidad responsable; y finalmente,
 Suspender el programa, decisiones que resultan en la interrupción parcial o total del programa.
A partir de este ejercicio, ppodemos observar (Tabla 11) que del total de aspectos comprometidos en un periodo de cuatro años, las decisiones por las que más optaron los programas fueron corregir sus actividades o procesos operativos y reorientar sustancialmente su propósito. Nunca estuvo dentro de sus consideraciones suspender total o parcialmente el programa ni tampoco, fusionarse con algún otro. Evidentemente, no es una decisión que se tome frecuentemente al interior de la dependencia, este tipo de acciones se deciden desde la Secretaría de Hacienda o en la Cámara de Diputados. En este sentido, 52 ASM se orientaron por corregir actividades o procesos: los programas que más decidieron corregir actividades y procesos fueron PAIMEF (14 acciones) y Coinversión Social (25 acciones); 40 ASM estuvieron relacionados con la reorientación
124 de 212

del propósito del programa, destacan PAJA (10 acciones) y Coinversión Social (11

acciones); sólo 2 ASM orientados a modificar los componentes de la MIR, es decir

cambios en los bienes o servicios que se entregan directamente a la población

beneficiada; y finalmente, 2 ASM relacionados con decisiones de generar de sinergias

con otros programas, como fue el caso del programa 70 y Más y el programa de

Fortalecimiento a la Transversalidad de la Perspectiva de Género, pues cada programa

implementó acciones en conjunto con otro para alcanzar de forma más eficiente el

cumplimiento de sus objetivos.

Tabla 11. Tipo de cambios que realizaron los programas de Atención a Grupos Vulnerables 2008-2012

PAJA

Corregir 3

Modificar 2

Reorientar 10

Adicionar 0

Suspender 0

70 y más

6

0

5

1

0

PAIMEF

14

0

7

0

0

PCS

25

0

11

0

0

Fortalecimiento a la

Transversalidad

4

0

7

1

0

Fuente: Elaboración propia con base en información de los programas.

Es importante aclarar que el análisis del conjunto de los programas estudiados

debe realizarse considerando en todo momento el grado de heterogeneidad que existe

entre éstos y el nivel de maduración que cada uno tiene. Cada programa presenta

necesidades distintas, más aún si consideramos que la población objetivo y los apoyos

que ofrecen son muy diferentes entre sí.

125 de 212

Ajustes de Mejora

Tabla 12. Decisiones implementadas por las dependencias ejecutoras y la

Cámara de Diputados a partir de los resultados de las evaluaciones

Jornaleros

Fortalecimiento

Tipo de Decisión

Agrícolas 70 y más PAIMEF

PCS

a la

Transversalidad

Corrección de procesos y actividades











Modificación de apoyos (productos y servicios)











Modificación sustancial de propósitos











Fusionar o reubicar











Suspensión











Cambio de presupuesto











Sin cambio de presupuesto











Asignación presupuestal

Creación de nuevo











programa

Fuente: Elaboración propia con base en información de los programas.

Ahora bien, con respecto a las decisiones presupuestales, como se puede observar en la Tabla 12, de forma general todos los programas presentaron modificación en su presupuesto anual. Algunos años se obtuvieron incrementos en sus partidas y en otros, disminuyó. Como se señaló en el capítulo 2, a partir de la información oficial publicada en los portales de las dependencias no se pueden identificar los criterios y motivaciones que expliquen las decisiones que se tomaron para asignar el presupuesto de los cinco programas. El caso más peculiar fue el del programa de Fortalecimiento a la Transversalidad de Género porque terminó, a diferencia del resto de los programas que recibieron un aumento presupuestal, con menos recursos. La respuesta a este comportamiento de los recursos públicos y a las motivaciones que tuvieron los programas para llevar a cabo cambios relacionados con la mejora continua, será desarrollada en el resto del capítulo.

126 de 212

3.2. Factores que explican las decisiones de mejora de los programas públicos Factores organizacionales En el ámbito de las organizaciones públicas, el liderazgo del operador de un programa público difícilmente se puede medir, pero sin un compromiso expreso por parte de éste la operatividad diaria del programa tiene resultados muy distintos. Cuando observamos de cerca el desempeño de un programa, se puede identificar que el primer factor que salta a la vista es el compromiso del responsable del programa, pues éste es quien enfrenta los problemas diarios en el terreno de la acción. El operador del programa es el actor principal que cuenta con información de primera mano sobre las fortalezas, debilidades, oportunidades y amenazas que tienen el programa y por lo tanto, es la persona que mejor conoce la operación y las áreas de mejora que se pueden implementar. En este sentido, su participación durante el proceso de evaluación es muy importante para que ésta se realice porque es la persona que proporciona toda la información útil referente al programa que se evalúa (reglas de operación, padrón de beneficiarios, informes de indicadores, presupuesto, por mencionar algunos documentos), así como la información adicional que el evaluador hubiere considerado necesario para justificar su análisis. Si el ejercicio de evaluación no es internalizado como un proceso sistemático dentro de la implementación del programa, el operador difícilmente colabora y los resultados de este ejercicio apenas producen resultados útiles. De esta forma, el liderazgo y compromiso del operador son un factor central que incide en las decisiones orientadas a realizar ajustes constantes que mejoran la operación del programa y que terminan por convertirse en Aspectos Susceptibles de Mejora. Esta observación compartida por la Directora General de Adjunta de Evaluación del CONEVAL:
127 de 212

En mayor medida, lo que pesa más en la práctica es el liderazgo del operador en el sentido de estar metido en la operación y quiere hacer ajustes constantes. La segunda tiene que ver con recursos presupuestales y humanos, cuando tú quieres hacer ajustes a un programa va a haber un costo por menor que sea. [Entrevista realizada el 25 de enero de 2013]
Para fortalecer este argumento, se puede mencionar que a partir de las entrevistas
también se pudo identificar que además de la normatividad que obliga a las
dependencias a evaluar sus programas, algunos operadores, como el caso de PAIMEF,
perciben a las evaluaciones como una herramienta que pueden utilizar a su favor cuando
previamente éstos han detectado áreas de mejora. Dicho de otra manera, cuando el
operador identifica las ventajas de evaluar, existe mayor disponibilidad para cooperar
con la evaluación porque los resultados que ésta arroje le permiten sustentar de mejor
forma la necesidad de cambios al interior del programa; incluso, esta información sirve
como evidencia al interior y exterior de la dependencia para legitimar sus decisiones. Al
respecto, una ex operadora del PAIMEF explicó lo siguiente:
Una de las características de mi gestión es que yo no me peleaba ni con las auditorías, ni con las evaluaciones. Al contrario, dada mi competencia, lo que yo les decía era “a ver lo que yo observo es que esto no está funcionando” y lo ponía a prueba un año antes y después con las auditorías yo les pedía que me hicieran esas recomendaciones para que yo las pudiera institucionalizar. Mira el liderazgo es indispensable, pero yo creo que se necesita mucho entendimiento de la naturaleza del problema que atiende el programa y eso en mi experiencia ha sido un poco complicado porque tiene que ver con mucho de eso que se le llama voluntad política. [Entrevista realizada el 25 de abril de 2013]
Otra opinión al respecto la expresó el ex titular de la Unidad de Planeación y Relaciones
Internacionales de SEDESOL, quien señaló lo siguiente:
Dependiendo del tipo de evaluación son las mejoras. Aplicar recomendaciones depende de qué tanto los titulares se tomen en serio que la evaluación les está ofreciendo un diagnóstico. El primero que tiene internalizar la utilidad de la evaluación es el gerente. Muchas veces los gerentes del programa ya saben los cambios que se deben hacer. El autodiagnóstico del programa también es útil y los Aspectos Susceptibles de Mejora permiten que también se use cualquier información disponible que pueda ayudar. [Entrevista realizada el 31 de octubre de 2012]
128 de 212

En este sentido, una de las propiedades del liderazgo al interior de los programas es que además de que el operador posea la información de cómo opera su programa, conozca las ventajas que puede aprovechar de un proceso de evaluación y tenga la capacidad para convertir las recomendaciones de los evaluadores en acciones de mejora operables.
Una segunda dimensión del liderazgo, es el papel de las Unidades de Evaluación en las dependencias, estas áreas internas que poco a poco se han ido incorporando en las dependencias y entidades de la Administración Pública Federal juegan un papel muy importante de contrapeso en el proceso de evaluación. Las Unidades de Evaluación, además de estar en contacto directo con los operadores de los programas, son las ventanillas de atención a los requerimientos de información de las entidades coordinadoras del sistema de evaluación federal como el CONEVAL, Hacienda y Función Pública, pero también son las áreas mediadoras entre el evaluador externo y el programa que se está evaluando. Por ejemplo, en la relación con el CONEVAL las UE son las áreas que informan periódicamente sobre el avance en el cumplimiento de los ASM y también están presentes en los espacios donde se definen los ASM que se van a seleccionar una vez que el programa recibe el informe de evaluación y sus recomendaciones. Estos espacios de debate provocan que los resultados de las evaluaciones se socialicen al interior de la dependencia, y que áreas distintas a la Unidad Responsable se involucren para discutir acciones de mejora constantes. Asimismo, son las áreas encargadas de informar sobre el estatus del programa a la Comisión de Desarrollo Social de la Cámara de Diputados. En su relación con la Secretaría de Hacienda, las UE son las encargadas de registrar el avance de los indicadores de la MIR en el portal aplicativo PASH. Al respecto, una evaluadora externa expresó lo siguiente:
129 de 212

Si por supuesto, son varios factores. Por ejemplo, en INDESOL eran los operadores, que eran los dueños del programa, los responsables del programa, los que podían empujar o no que una recomendación cambiara, que cambiara algo en realidad. Los impedimentos más grandes a nivel organizacional pueden ser por ejemplo, normatividades que no se pueden cambiar, restricciones de recursos humanos que impidan modificar los procesos, etc. En el caso de otras instituciones, Oportunidades, por ejemplo SEDESOL, un aspecto que ayuda mucho es en qué medida el área de evaluación impulsa estas recomendaciones con los programas. En el caso de INDESOL es interesante porque no hay un área de evaluación, entonces es muy directa la relación con los programas, eso ha ayudado, pero en otros casos la presencia de un área de evaluación fuerte es la que ayuda. [Entrevista realizada el 3 de abril de 2013]
En este sentido, el liderazgo y la constante presencia de las Unidades de Evaluación
también influyen para innovar más allá de las evaluaciones mandatadas en el Programa
Anual de Evaluación que se define anualmente entre el CONEVAL, Hacienda y la Función
Pública. Por ejemplo, en 2012 la Unidad de Evaluación de SEDESOL tuvo la iniciativa de
realizar metaevaluaciones a veinte programas a su cargo. Las metaevaluaciones son un
análisis de las evaluaciones previas de los programas. Los cuatro programas de SEDESOL
que esta tesis analizó fueron sujetos de este tipo de evaluación, y su objetivo fue aportar
una visión global sobre los cambios que realizó cada programa a partir de las distintas
evaluaciones practicadas durante el sexenio del expresidente Felipe Calderón además de
proveer información sobre las áreas de oportunidad que cada programa tiene para los
siguientes años. Asimismo, las Unidades de Evaluación, fungieron como las áreas de
apoyo técnico para el proceso de evaluación, estas áreas revisan las metodologías
aplicadas por los evaluadores o la capacidad técnica de un programa para llevar a cabo cierto tipo de evaluaciones, como es el caso de las evaluaciones de impacto101. En este
sentido, existe un trabajo muy estrecho entre las Unidades de Evaluación y las Unidades
101 Para llevar a cabo una evaluación de impacto, los programas sociales deben presentar previamente ante el CONEVAL la metodología para evaluar un programa antes de iniciar el proceso de contratación de los evaluadores externos.
130 de 212

Responsables de los programas. En los casos estudiados, todos los programas expresaron cercanía con las Unidades de Evaluación de SEDESOL, INDESOL e INMUJERES.
La influencia del liderazgo de los operadores de los programas se puede identificar con mayor facilidad en las decisiones relacionadas con la mejora continua que en las decisiones presupuestales. En otras palabras, el liderazgo no es un factor relevante en las decisiones en torno al presupuesto porque éstas responden en mayor medida a lógicas distintas de grupos e intereses partidistas que a la decisión de un solo individuo. Mejorar un programa público es una decisión que se define en mayor medida por los responsables directos y actores más cercanos a los programas, en cambio asignar recursos públicos es una negociación que involucra a muchos actores de distintos ámbitos del gobierno.
Por otra parte, dentro de la dimensión organizacional, otro factor que también influye es la capacidad técnica de los programas para utilizar de una forma más productiva la información derivada de las evaluaciones. Para esto primero deben cubrirse requisitos previos en materia de capacidades; es decir, para que los tomadores de decisión aprovechen la información producida primero deben tener capacidad para recabar información útil para el proceso de evaluación, construir indicadores pertinentes, seleccionar metas reales y lo más importante, contar con la habilidad para utilizar las recomendaciones y los hallazgos de la evaluación una vez que llega a sus manos. En este sentido, a continuación se presentan algunos ejemplos de cómo los casos documentados contaron con esta capacidad técnica.
Un primer caso es el PAIMEF, a partir de una recomendación que sugirió mejorar la definición de lo que el programa entendía como “fortalecimiento institucional”. Para definir este concepto y “aterrizarlo”, el programa trabajó en la creación de un indicador a
131 de 212

nivel de Propósito para medir cuál era el impacto real de la intervención en el
fortalecimiento institucional de las instancias estatales de mujeres. Posteriormente, a
partir de la implementación de este indicador, el programa pudo negociar con la
Secretaría de Hacienda que el uno por ciento de su presupuesto se dedicara a fortalecer
las capacidades estatales de estas instancias mediante talleres de formación en materia
de marco lógico, y cursos de capacitación básica relacionados con el fortalecimiento
institucional. Al respecto, la evaluadora externa referida en párrafos anteriores expresó
lo siguiente:
“Después de la evaluación de procesos [del PAIMEF] en la que se señalo que INDESOL tenía que invertir en el fortalecimiento institucional y que tenía que definir claramente qué iba a entender por fortalecimiento institucional, al momento que se desarrolló ese indicador, también se acompañó al PAIMEF en un proceso para negociar un presupuesto de 1% que se quedara, siendo capítulo 4000, es un presupuesto que en lugar de repartirse en proyectos estatales para atención de la violencia, se centralizó en las oficinas de INDESOL para entonces hacer acciones para fortalecer parejo a todos los institutos de la mujer. Por ejemplo, ofrecer talleres y cursos, o alguna capacitación básica, entonces ese 1 por ciento esa es la utilidad que ha tenido, hasta el año pasado siguió operando. Primero fue en PAIMEF, si no me equivoco fue en 2011 el primer año, y el año pasado en 2012, también lo pudieron negociar para el PCS [programa de Coinversión Social]. Del lado del PAIMEF, supe que con una parte de ese 1 por ciento se dieron talleres que se llamaban de fortalecimiento institucional […] El evaluador puede detectar una recomendación y hacerla pero si no se había implementado no forzosamente es porque no lo habían pensado, sino porque hay alguna limitante legal, o porque no se ha hecho el estudio de factibilidad, etc. Entonces a veces, una recomendación va a requerir más de investigación o de un estudio o contratar a alguien para que apoye en su realización”. [Entrevista realizada el 3 de abril de 2013]
En particular, la capacidad del PAIMEF para abrirse a las recomendaciones provocó
una cascada de beneficios tanto a nivel federal como en el ámbito estatal, porque la
Secretaría de Hacienda incrementó el presupuesto de este programa y, además, porque
en los estados las instancias de mujeres fueron beneficiadas con cursos de capacitación
en materia de evaluación, sobre todo, se socializó el “nuevo lenguaje” de gestión por
resultados que se utiliza a nivel federal.
132 de 212

Otro caso que ejemplifica esta capacidad técnica también se refleja en el proceso de mejora de los indicadores de Fin y Propósito de la MIR y en los constantes cambios que buscaban focalizar mucho mejor los objetivos de los cinco programas a fin de captar de una forma más clara la teoría de cambio que sostiene cada intervención. Por ejemplo, el caso del PCS refleja esta situación. Las distintas observaciones de sus evaluaciones señalaban que la falta de claridad de sus beneficiarios finales provocaba ambigüedad en los objetivos del programa. Ante estas recomendaciones, el PCS comenzó a trabajar para identificar su teoría de cambio: una primera solución fue identificar como un resultado intermedio el fortalecimiento institucional de las Organizaciones de la Sociedad Civil y posteriormente, como resultados de impacto, definieron que el programa busca generar capital social entre los grupos vulnerables.
No obstante, el tema de la capacidad técnica no depende solamente de la habilidad del operador para traducir recomendaciones en acciones puntuales, también resulta de la capacidad de actores externos involucrados en la implementación de los programas. Por ejemplo, PCS y PAIMEF enfrentan el problema de que sólo sus áreas de evaluación dominan el “lenguaje de orientación a resultados”, y el resto de las áreas administrativas, también involucradas en los procesos de implementación de los programas, carecen de la socialización de este lenguaje. Al respecto, la ex titular del INDESOL señaló lo siguiente:
Esta área [la de evaluación] debe ser auxiliada por prácticamente todas las áreas del instituto: por administración y finanzas, de fomento, investigación, de equidad de género. Sería valioso que hubiera conocimientos de evaluación en las áreas distintas al área de evaluación. [Entrevista realizada el 31 de octubre de 2013]
Un caso distinto a los programas aquí estudiados pero que sirve para ejemplificar otra forma de implementar acciones puntuales de mejora, fue la materialización de un sistema de información compartido entre el Consejo Nacional de Fomento Educativo
133 de 212

(CONAFE) y el programa PAJA, como solución a los problemas que este último tenía para
que las distintas instancias de educación en las entidades federativas donde opera el
programa, reconocieran el avance en los grados de educación que tenían los niños, hijos
de jornaleros agrícolas, de un año a otro. Antes de esta decisión conjunta, la movilidad
geográfica que tienen los jornaleros agrícolas en diferentes periodos del año provocaba
que los registros del avance escolar de sus hijos se perdieran cuando migraban de una
entidad a otra. La coordinación entre CONAFE y PAJA permitió mejorar los resultados de
uno de los componentes del programa, el que estaba dirigido a otorgar apoyos directos a
la población agrícola.
Por otra parte, esta falta de capacidad técnica también afecta la operación con las
entidades federativas cuando los programas se coordinan desde el gobierno federal y las
delegaciones estatales sólo se encargan de operarlos. Existen diversos estudios que han
documentado rezagos en los gobiernos estatales para implementar legislaciones, mecanismos e instituciones en materia de evaluación del desempeño102. Una dato que
refleja esta heterogeneidad de las capacidades estatales es que en 2011 la entidades
federativas con mayor avance en monitoreo y evaluación fueron el Distrito Federal,
Estado de México y Guanajuato; y, las de menor avance fueron Baja California Sur, Tlaxcala y Morelos103. En particular, este problema lo podemos ver reflejado en el caso
102 CIDE-Centro CLEAR para América Latina, 2013, Fortaleciendo la Gestión para Resultados en el Desarrollo en México: Oportunidades y Desafíos, México http://www.clear-la.cide.edu/node/114; SHCP, 2012, Diagnóstico de implementación del PbR-SED en las entidades federativas, México, http://www.transparenciapresupuestaria.gob.mx/ptp/contenidos?id=10&group=Evaluaciones%3Cbr%3E% C2%A0&page=Resultados#diag; Maldonado C. y Galíndez, C, 2013, Monitoreo, Evaluación y Gestión por Resultados. Aprendizaje y Cooperación Sur-Sur para la Innovación: El Papel de los Actores Subnacionales, CIDE-Centro CLEAR para América Latina, México. 103 Véase Martínez, E. et. al. (2013) en CIDE-Centro CLEAR para América Latina, 2013, Fortaleciendo la Gestión para Resultados en el Desarrollo en México: Oportunidades y Desafíos, México http://www.clearla.cide.edu/node/114
134 de 212

particular del programa Fortalecimiento a la Transversalidad de Género, la ex Directora
de Evaluación de INMUJERES explicó el problema que este programa enfrenta:
Estos programas no son operados sino coordinados por INMUJERES entonces, la capacidad técnica, de operación y la capacidad administrativa en las entidades federativas pues son elementos fundamentales. Pero el tema de la mejora también tiene que ver con algunos aspectos que van más allá que el simple ejercicio de los recursos, y que tiene que ver con la calidad de estudios, investigaciones, capacitaciones o elaboración de encuestas que planean las entidades federativas y ahí el obstáculo mayor. El obstáculo mayor es de carácter técnico en la formación del personal en las entidades para desarrollar estudios e investigaciones y también, a veces, la escasa vinculación que se tiene con el sector académico, que tengan estudios de calidad. Otra dificultad, es que hay mucha dispersión de acciones y tomar como un sólo criterio de recomendaciones es difícil. [Asimismo], un obstáculo es que el personal del programa no era personal de INMUJERES sino personal eventual y el proceso de aprendizaje se truncaba ahí mucho y eso afectaba la posibilidad de corregir con más éxito. Otra, es la formación técnica del personal, hay poca cultura del registro de información o del uso de tecnologías para la administración del programa que ha impedido tener total transparencia, y cuando digo total transparencia no es que uno no pueda proporcionar información a la ciudadanía cuando te la piden, sino más bien, que esté disponible de forma permanente y sistemática. [Entrevista realizada el 29 de octubre de 2012]
En este sentido, el liderazgo y el compromiso de un operador debe estar
acompañado de una formación de capacidades para traducir recomendaciones en
acciones puntuales que mejoren la productividad del programa, en otras palabras, que
utilice de forma instrumental esta herramienta en el proceso cotidiano de operación.
Características de las evaluaciones
El tema de la capacidad viene de la mano con otro factor considerado importante
para esta investigación: la factibilidad de las recomendaciones. Una recomendación es
factible cuando el operador de un programa coincide con la recomendación elaborada
por el evaluador y encuentra la forma de implementarla. Como se mencionó en los
capítulos previos, la factibilidad se sustenta principalmente en temas relacionados con la
disponibilidad presupuestal, el ámbito de competencias en la estructura organizacional,
135 de 212

marco normativo, acceso a cierto tipo de información o cuestiones metodológicas acerca de cómo medir e implementar acciones, indicadores, etc. En este sentido, la factibilidad influye en las acciones de mejora que pueden implementar los programas. Como señala el Secretario Ejecutivo del CONEVAL:
Una evaluación que sólo muestra fallas y no tiene como objetivo el perfeccionamiento continuo de los programas y estrategias será siempre una evaluación sesgada. Para aplicar las mejoras necesarias es importante dialogar productivamente con los funcionarios responsables y contar con su apoyo. Un ánimo punitivo de la evaluación llevaría a que se esconda la evidencia, se maquillen los datos y se resistan o posponga la implementación de mejoras.104 Si la recomendación del evaluador no está dentro del espacio de acción de lo que el operador puede implementar, existe una baja probabilidad de que la recomendación se apropie como parte de los cambios necesarios del programa y sobre todo, que se convierta en un ASM que los programas puedan implementar. Como señaló el ex titular de la Unidad de Evaluación del Desempeño de la Secretaría de Hacienda: Hay veces que el evaluador determina recomendaciones que no son viables, que implican cambios legales, que implican cuestiones políticas, estructuras de las dependencias, cosas presupuestarias que el operador de la dependencia no puede comprometerse a cumplir. [Entrevista realizada el 24 de octubre de 2012]
Entonces, si partimos de que los tomadores de decisiones no son páginas en blanco que se apropian automáticamente de una solución, como se señaló en el capítulo uno, un proceso exitoso de evaluación es aquél que en las distintas etapas del proceso evaluativo procura la retroalimentación constante entre evaluado y evaluador. Al respecto, la ex titular de INDESOL comentó lo siguiente:
104 Hernández Licona, G. (2014), “Acerca de la autonomía”, México social, disponible en http://www.mexicosocial.org/index.php/colaboradores/colaboraciones-especiales/item/518acerca-de-la-autonomia
136 de 212

Siempre tenemos una reunión con los evaluadores y a veces no todos los evaluadores conocen los programas a fondo y creemos que a veces es necesario hacer una aclaración. Pero esos espacios involucran a los equipos estratégicos de cada uno de los programas que nos permiten ir tomando decisiones específicas que se traducen en todo el ciclo de cada programa: desde la planeación del año siguiente, que empieza por definir las Reglas de Operación, las convocatorias del programa PCS, durante el ejercicio de cada uno de los procesos, en la capacitación de los dictaminadores, la dictaminación de proyectos, hasta el proceso de evaluación. [Entrevista realizada el 31 de octubre de 2013]
Este ejercicio continuo de comunicación directa, permite que el evaluado
encuentre mayores incentivos a incorporar las recomendaciones sugeridas en el proceso
decisorio y que al mismo tiempo, el evaluador se sensibilice ante las características
particulares del programa que analiza. Este proceso de acompañamiento entre el
programa y el evaluador externo, facilita la construcción de recomendaciones factibles
que cuenten con mayor probabilidad de adoptarse como verdaderos cambios. Como
señala la evaluadora externa:
“Me ha tocado leer informes de evaluaciones que dicen recomendaciones muy amplias, muy vagas y me parece por supuesto que el evaluador diga cómo, quién y cuándo se deben hacer ciertas cosas ayuda a su implementación. Entonces, es un tema de ser muy concretos, y en ese sentido creo que lo más importante para que una recomendación sea aplicada es que sea, lo digo entre comillas, “construida con el operador”, es decir, el evaluador tiene un hallazgo y tiene una recomendación general pero ya el aterrizaje del cómo es importante validarlo y construirlo junto con el operador para que se vayan apropiando de la evaluación desde el momento en que se está diseñando. Los procesos de evaluación en el que a nosotros nos ha tocado participar sí prevén varias reuniones con el programa en presentaciones de avances, en momentos claves de la evaluación. Porque por ejemplo, si ya hiciste el análisis de gabinete y presentas un primer resultado, ellos te leen y te dicen si hay algo que se interpretó mal; después, por ejemplo, del proceso del levantamiento en campo, en ese caso al regresar del campo presentamos los avances y los hallazgos todavía en bruto, porque obviamente regresa uno de campo con más dudas de las que se fue, entonces ahí es otro momento para entrevistar a los operadores con más conocimiento para que nos ayuden a aclarar. Entonces, de entrada ahí en el proceso de la evaluación lo que quieres es una cercanía. Y después, ya que se desarrollan las conclusiones y se presentan las recomendaciones hay un proceso de discusión que permite afinarlas, porque de repente lo que nos puede pasar a los evaluadores es que caigamos en generalidades que no aplican realmente a todo el programa, o a ciertos aspectos del programa, entonces vale la pena precisar con ellos. Entonces, me parece que ese proceso de construcción en conjunto es el que puede ayudar a que la recomendación sea realmente bien recibida, para que no sea una sorpresa. Si los operadores se ven reflejados en la evaluación, en el sentido de que digan
137 de 212

“efectivamente estás captando lo que yo percibo como realidad o estás percibiendo algo que yo no me había dado cuenta”, cuando eso sucede, es más fácil que se adopte una recomendación y muchas veces les sirven porque muchas veces es una voz externa diciendo algo que ellos ya había detectado o que ellos necesiten impulsar”. [Entrevista realizada el 3 de abril de 2013].
La Directora General Adjunta de Evaluación en CONEVAL lo explica con otras palabras: [Se busca] que el evaluado sepa de qué se trata, cómo va el resultado, que se sienta parte del proceso, me parece un incentivo y un factor fundamental que permite tener una relación más pareja entre el evaluador y evaluado” [Entrevista realizada el 25 de enero de 2013].
Un caso que ejemplifica los obstáculos que produce la poca comunicación en las evaluaciones son las observaciones que hicieron algunos de los entrevistados sobre el proceso para hacer las primera Evaluaciones Específicas de Desempeño realizadas en 2009, porque se convirtió en un ejercicio incomunicado entre el evaluador y el evaluado debido a que el primero solamente realizaba un análisis de gabinete y pocas veces procuró la retroalimentación con el operador del programa. Esta dinámica provocó que en los resultados finales, el operador del programa se viera obligado a precisar algunos datos de información en el documento de Posición Institucional, como cifras de presupuesto, población atendida, o incluso, recomendaciones que el operador ya había implementado anteriormente y que de cierta forma, provocó que los resultados y hallazgos fueran ajenos al operador del programa. La consecuencia de esta falta de comunicación provocó que pocas recomendaciones hechas por el evaluador se convirtieran en ASM. Por ejemplo, dentro de los documentos de Posición Institucional de los programas PAIMEF y PCS se encuentran párrafos que señalan “Para cada una de las debilidades, la evaluación contempla una recomendación, las cuales son claras y
138 de 212

relevantes, pero únicamente algunas de ellas son factibles [énfasis de la autora] y
justificables de atención”.105
Otros ejemplos más específicos son los señalados por el Programa 70 y Más
respecto a las recomendaciones de elaborar una planeación estratégica y a la medición
de temas de percepción:
La UR comparte la recomendación de la evaluadora en relación a la elaboración de un documento de planeación estratégica que englobe los horizontes de corto, mediano y largo plazo, sin embargo, es necesario considerar que la nueva cobertura definida para el Programa 70 y más (universal para adultos mayores de 70 años que no reciban una pensión de tipo contributivo) requerirá no sólo de definiciones estratégicas para el Programa, sino de una política de estado para atender a los adultos mayores y el financiamiento de un esquema universal de pensiones. Respecto a la recomendación de que la medición de la percepción de los beneficiarios se realice a través de instancias externas de la UR del Programa, se revisará la factibilidad económica de dicha propuesta en función de los escasos recursos de operación con los que cuenta el Programa.106
Por lo tanto, retomando el espíritu de esta sección, es importante resaltar que
para evitar resistencias desde el inicio, la cooperación entre el evaluado y el evaluador es
un factor primordial para que los informes finales reflejen información útil para el
proceso de mejora continua, de lo contrario, sólo se provoca que estos informes se
guarden en un cajón y no se vuelvan a consultar.
A estas alturas de la investigación, una duda válida que el lector podría plantearse
es sobre la variación en el grado de influencia que tiene cada uno de los factores hasta
ahora sustentados (liderazgo, capacidad técnica y factibilidad) para que los ASM
105 Documento de opinión sobre los resultados, hallazgos, fortalezas, debilidades, amenazas y recomendaciones que derivan de las evaluaciones realizadas al Programa de Apoyo a las Instancias de Mujeres en las Entidades Federativas, para implementar y ejecutar Programas de Prevención de la Violencia contra las Mujeres y Documento de opinión sobre los resultados, hallazgos, fortalezas, debilidades, amenazas y recomendaciones que derivan de las evaluaciones realizadas al Programa Coinversión Social. Publicado en www.sedesol.gob.mx 106 Programa 70 y Más, Evaluación de consistencia y Resultados 2011-2012. Posición institucional. Abril de 2012. p.4. Publicado en www.sedesol.gob.mx
139 de 212

finalmente lleguen a su total cumplimiento. Sin embargo, cabe recordar que el Mecanismo de Seguimiento señala que las Unidades Responsables, las de Evaluación, así como cualquier otra área que participe en la selección de ASM deben considerar durante el proceso de selección argumentos y criterios de claridad, relevancia, justificación y factibilidad al momento de elegir entre el universo de recomendaciones, los compromisos con los que se quedarán para su seguimiento. Con esto quiero decir que los ASM son el resultado de un análisis previo que considera la capacidad técnica, la factibilidad y que implícitamente están influidos por el liderazgo, y una vez definido un ASM éste tiene que cumplirse en una fecha definida. En este sentido, es muy difícil determinar el grado detallado de influencia que cada factor juega en las decisiones para implementar mejora, pero lo que sí se puede identificar mediante un análisis de discriminación a partir de la evidencia son los factores que más influyeron en las decisiones de mejora en el caso mexicano del universo que señala la literatura. Por ejemplo, se encontró que algunos factores como la premura de un individuo por tomar una decisión en un contexto de crisis organizacional, la calidad de las evaluaciones o la disponibilidad de información resultaron contra intuitivos en la influencia que tienen para que una evaluación se utilice de forma instrumental. Los actores entrevistados para esta investigación no expresaron información relevante que pudiera ser considerada como un factor adicional en su proceso de toma de decisiones. Respecto al tema de la calidad de las evaluaciones, una posible respuesta sobre la influencia limitada de esta característica es que para un tomador de decisión resulta más importante que la información de la evaluación coincida con su conocimiento previo que la calidad de ésta, como se señaló en el capítulo 1. En este sentido, la relación que mejor explica el uso intensivo de las evaluaciones en decisiones de mejora de los programas de Atención a
140 de 212

Grupos Prioritarios es la presencia del liderazgo de los operadores de los programas y de sus Unidades de Evaluación; así como a la capacidad operativa de las organizaciones públicas y la factibilidad de las recomendaciones hechas por el evaluador.
3.3. Factores que explican las decisiones presupuestales Ahora bien, en las decisiones relativas al presupuesto, los factores que permiten explicar los diversos comportamientos de los recursos públicos que recibieron los cinco programas analizados son el factor político y el diseño institucional del sistema de evaluación. A continuación, se explicará de qué manera influyó cada uno de estos.
Factores políticos Con respecto al factor político, es importante señalar que el impulso que tuvo la política de evaluación en México durante los últimos años se explica en gran parte porque a la llegada del ex Presidente Felipe Calderón se abrió una ventana de oportunidad que alineó algunos valores del gobierno en turno con los objetivos de mayor transparencia, rendición de cuentas, control presupuestario, etc. principios de una corriente administrativa que se promovió, como se mencionó al inicio de este estudio, internacionalmente por organismos (OCDE, Banco Mundial) en regiones como América Latina. Una explicación al respecto, la ofreció el ex Secretario de Hacienda de esa administración:
Yo creo que es una de las banderas del Partido Acción Nacional el tema de la rendición de cuentas, de la transparencia y de hacer más con menos y en buena medida esto responde a eso. En buena medida responde a transparentar pues todas las asignaciones presupuestales que se hacen, y al menos conocer si los programas están dando los resultados esperados. Es sorprendente como antes pues los programas no se evaluaban, programas tan grandes como Solidaridad pues no existía una sola evaluación seria que nos permitiera saber si este programa funcionaba o no, bajo un diseño metodológico serio, riguroso. Entonces pues,
141 de 212

nosotros si tenemos esa convicción y pues esto empezó a ser una de las mejores prácticas a nivel internacional que México adoptó en el año 2006. Yo te diría que cuando llegué a la Subsecretaría de Egresos, el 1 de diciembre de 2006, esto era una idea que se venía manejando, se venía considerando la posibilidad de emprenderla y había algunos esfuerzos con Carlos Hurtado que era el Subsecretario de Egresos en esa época y empezaban de manera incipiente a ver esto. Nosotros llegamos en 2006 y adoptamos la idea, nos gustó la idea y consideramos que era perfectamente compatible con lo que estábamos buscando de poder asignar los recursos en aquellos programas que tuvieran mejores resultados y también era un tema de transparencia. [Entrevista realizada el 3 de mayo de 2013]
El diseño y la aprobación del presupuesto es la manifestación de las prioridades de
un gobierno, de ahí que el proceso de negociación siga una lógica esencialmente política
y en este proceso México no es la excepción. En la etapa de planeación, la Secretaría de
Hacienda considera criterios técnicos que se derivan tanto de la información de
desempeño del Modelo Sintético del Desempeño, como de temas relacionados con la
inflación, deuda, precios internacionales, entre otros, pero como señala el ex titular de la
Unidad de Evaluación del Desempeño de esta Secretaría, también se tienen muy
presentes los proyectos y programas prioritarios para el presidente de la República, en
particular las políticas planteadas en el Plan Nacional de Desarrollo. En el PND un
gobierno establece los compromisos de mediano y largo plazo que señala como propios
en el periodo de su administración:
Se toman muchísimas variables. En primer lugar, cuáles son las prioridades de la administración, hay que recordar que los gobiernos, sus prioridades de planeación se hacen con base en una propuesta política y que el proceso presupuestario no es un proceso matemático, es un proceso político y ese tipo de consideraciones nunca van a estar ajenas a este proceso de asignación presupuestaria. ¿Para qué te sirve la información de desempeño? Te sirve para tomar mejores decisiones o tomar decisiones más informadas. La información de las evaluaciones se integra en el Modelo Sintético del Desempeño, que es un modelo que sirve para integrar información de desempeño que no solamente viene de evaluaciones sino también viene del propio ejercicio presupuestal, de cómo esta diseñada la matriz de indicadores, de cómo han avanzado los programas en cuanto al logro de sus metas que se han establecido en la propia matriz, viene también de contrastar cómo ha evolucionado el presupuesto de ese programa y cómo han evolucionado las metas. [Entrevista realizada el 24 de octubre de 2012]
142 de 212

Sin embargo, la conformación de la propuesta final del presupuesto es un proceso
que se vuelve más complejo cuando llega a la Cámara de Diputados, debido a la
participación de más actores en el proceso. Es importante mencionar que los
entrevistados pocas veces se refirieron a los casos de estudio de esta investigación a
pesar de que las preguntas tenían este énfasis. Durante la sistematización de las
entrevistas se enfrentó un gran problema de información porque los distintos
entrevistados se referían a grandes partidas presupuestales en lugar de programas tan
específicos como los estudiados en la presente investigación.
Como se mencionó en el anterior capítulo, una vez que el proyecto de presupuesto
llega a la Cámara de Diputados, la Comisión de Presupuesto y Cuenta Pública es el
principal actor que decide los cambios en el PEF y el proceso de análisis, discusión y
aprobación que se lleva a cabo dentro de este espacio, carece de criterios técnicos y
sistemáticos que consideren los resultados de las evaluaciones porque aún siguen
dominando criterios políticos para asignar el presupuesto en nuestro país. Se generan
incentivos en función de intereses y demandas particulares que se traduzcan en una
mayor exposición política para los diputados. La asignación de los recursos dentro de
este foro se sigue haciendo bajo criterios que van cambiando de acuerdo a los intereses
de cada partido y en particular, a las políticas públicas de mayor interés para el gobierno
en turno. Al respecto, un ex integrante del equipo técnico en la Comisión de Desarrollo
Social de la LXI Legislatura explicó lo siguiente: Dependiendo del año, en el primer año de la legislatura cambiaron de los 20 programas que se sugirieron cambiaron tres, a los tres que habíamos sugerido cambiamos. O sea digamos de los 20 programas te vas sobre uno, dos o tres: Diconsa, Liconsa, Oportunidades, Espacios Públicos, Guarderías. Dependiendo de la presión que haya es a donde vas a hacer. A Oportunidades no le puedes hacer grandes cambios ¿porque? porque tienes ya un irreductible, tienes ya sujetos con derechos adquiridos a los cuales no puedes cortarle el 50 por ciento, el 60 por ciento. El 80 por ciento del presupuesto del Ramo 20 es Oportunidades, ¿qué mueves? un 20
143 de 212

por ciento y eso en qué, cuáles programas, cuál dices, cuál es el mejor. Por más que esté muy bien evaluado que este otro proyecto lo que puedas conseguir es marginal […] Digamos, en el tercer año se defendió muchísimo Diconsa y Liconsa. Eso es prácticamente cada año, si tú ves el comportamiento del presupuesto, cada año se les aumentaba mil, o de mil doscientos a mil quinientos cada año porque así llegaba la instrucción, de que necesitaban eso, por los precios internacionales, porque no había leche. Entonces sobre esa prioridad llegaban los panistas y decían “no le podemos mover a esto, muévele a todo lo demás”. Por ejemplo 70 y Más se universalizó al final en el tercero [año]. 70 y Más fue muy bien evaluado. 70 y Más desde que se creó es un artículo diferente en el PEF, vaya si tú ves todo el presupuesto de egresos, el decreto de presupuesto de egresos es un articulado. En el cincuenta y tantos tienes toda la cuestión de las evaluaciones y en el cincuenta y tres tienes uno que nada más tiene que ver para el 70 y Más. ¿Cómo lo metieron ahí?, quién sabe pero es un artículo específico para 70 y Más y es ahí donde se le asignó directamente. O sea, por más que nosotros pudiéramos moverle acá, éste se discutía directamente. Es completamente diferente la lógica, pasó de 7 mil millones a 13 mil millones y la discusión ahí fue fuertísima porque por más que estuviera mejor evaluado, no puede ser que un programa pase de un año a otro al doble, por más que quieras universalizar si tenías subejercicio con los 7 mil millones cómo le vas a dar 13 mil millones. Pero la discusión estuvo fuera de tu ámbito, estuvo directamente en la de Presupuesto y directamente en la discusión esa noche en el Pleno, porque en el Pleno se puede reservar cualquiera de los diputados o fracciones parlamentarias ese artículo, entonces ya la discusión es muy cerrada porque el tema es 70 y Más. ¿Habrá tenido que ver que era prioridad de gobierno? Sí, desde luego. Desde aquí, desde que nosotros empezamos a hacer la opinión hacia adentro de la Comisión ya cada bancada trae línea de su propio Grupo Parlamentario y en este caso del PAN qué defender. [Entrevista realizada el 15 de abril de 2013].
Este comportamiento sucede porque en materia de gasto público aún falta mayor
transparencia en las negociaciones para modificar el presupuesto. En este proceso siguen
imperando criterios partidistas y lógicas inerciales y se carece de procedimientos claros y
mecanismos institucionales para procesar sistemáticamente la información sobre el
desempeño de los programas. De hecho, el escaso conocimiento de los legisladores en
materia presupuestal limita su habilidad para hacer un uso instrumental de las
evaluaciones. Este problema se explica en parte, porque los periodos de tres años que
dura un legislador en funciones no son suficientes para adquirir experiencia en materia
de presupuesto, ni mucho menos para hacer análisis más complejos entre gasto público y
resultados de desempeño. Incluso, siendo más estrictos, la experiencia efectiva de un
legislador se reduce aún más si tomamos en cuenta que existe una curva de aprendizaje
144 de 212

cuando los diputados inician el periodo legislativo. Al respecto, el ex titular de la Unidad
de Evaluación del Desempeño de la Secretaría de Hacienda opinó lo siguiente:
Ahí te enfrentas al problema institucional del Congreso que podría generar una derrama de incentivos positivos que es la ausencia de relección. En ausencia de relección, la conexión entre electorado-legislador se rompe y los incentivos para hacer un mejor trabajo se pierden y los criterios se vuelven políticos e inmediatos. Lo que debería pasar para incentivar a lo legisladores a utilizar la información de desempeño es que esta información sea utilizada por los miembros de la sociedad civil, por la academia y por los medios de comunicación para generar un debate más informado el cual necesariamente va a incidir sobre las decisiones de los legisladores. [Entrevista realizada el 24 de octubre de 2013].
Otros entrevistados resaltaron que además del incremento de los precios de los
alimentos y la inflación, en la discusión parlamentaria sobre el gasto los legisladores
también responden al apoyo de grupos organizados con influencia en sus carreras
políticas. Este fenómeno se presenta con más frecuencia en programas de política social
porque su presupuesto está muy comprometido a la existencia de beneficiarios con
derechos adquiridos a los que difícilmente se les puede quitar de un año a otro los
recursos asignados.
La asignación del presupuesto pasa por el resultado de las evaluaciones pero también pasa por ponderaciones de tipo político, pasa por proyectos de gobierno en el orden federal y en lo local, políticamente los gobernadores negocian por aquellos temas a los cuales ellos en su ejercicio de gobierno les dan prioridad [Ex integrante del equipo técnico de la Comisión de Grupos Vulnerables en la LXI Legislatura].
Esta dinámica provoca que aunque exista información técnica derivada de estudios
y evaluaciones sobre los programas sociales, el presupuesto se asigne a partir de
intercambios clientelares que garanticen el apoyo electoral para las carreras políticas de
los actores. Al respecto un entrevistado explicó lo siguiente:
“[El presupuesto] es bastante inercial y es difícil retirarle presupuesto a un programa porque salió mal evaluado porque al final de cuentas este programa tiene una población objetivo que no puedes retirarle los recursos o el apoyo presupuestal. Entonces, lo que se hace cuando un programa sale mal evaluado se trata de corregir de acuerdo a las evaluaciones que se tienen para que cumpla mejor con su objetivo y
145 de 212

ciertamente no tiene un crecimiento tan importante. Aquellos programas que salen muy bien evaluados si tienen crecimientos importantes. […] La asignación del presupuesto tiene que ver con presupuesto asignado del año anterior, tiene que ver con la ampliación de cobertura del programa. Si es un programa que está en expansión pues requiere de una mayor ampliación de recursos, requiere también de actualizaciones por temas inflacionarios o por incrementos en el tema de la comida, tiene que ver, por supuesto, con los resultados de los programas. [Entrevista realizada el 15 de abril de 2013 a un ex integrante del equipo técnico en la Comisión de Desarrollo Social de la LXI Legislatura].
Los criterios mencionados por el entrevistado provocan que dentro de la
Cámara de Diputados exista un uso limitado de la información derivada de las
evaluaciones y que las decisiones del gasto se vean más influidas por criterios
políticos que por elementos técnicos, incluso como lo señaló el mismo
entrevistado, la alineación con el PND y la presencia de cabilderos son factores que
también se deben tomar en cuenta para la negociación del presupuesto, así como
las decisiones previamente tomadas como la ampliación de la cobertura de un
programa.
En este sentido, la falta de criterios técnicos en el proceso de aprobación
provoca que los diputados se concentren más en partidas locales que les garantizan
mayor rentabilidad política que en el resto del presupuesto que se considera
comprometido. Un diputado señala lo siguiente:
El gobierno federal tiene secuestrado el proceso. ¿Cómo atomiza el gobierno federal la perspectiva nacional? le dijo a cada Grupo Parlamentario, tienes tantos diputados entonces tus diputados tienen problemas en sus demarcaciones de que si les piden una banqueta, de que si le piden una carretera, entonces les da. Paradójicamente aunque la atribución es del Congreso, pero les da: a ver tú vas a etiquetar 30 millones en tu municipio o en el distrito en el que fuiste electo, que si una planta potabilizadora, que si una carretera, que si una escuela, que si un Cendi, etc. Entonces qué es lo que pasa, pues que mete a todos los diputados en su localidad y entonces el diputado ya está pensando qué es mejor, “construyo la escuela o meto alumbrado público, o hago una carretera, qué hago” y olvídate de los programas de desarrollo social y olvídate de todos lo demás temas. Entonces es un tema muy especializado, que a lo mejor los que somos economistas le medio entendemos y no le entendemos a todo, no tienes los antecedentes tampoco y si no los sabes buscar tampoco lo encuentras. Yo creo que estos esquemas de evaluación se hacen un poco más para
146 de 212

legitimar los programas sociales. [Diputado de la Comisión de Presupuesto y Cuenta Pública de la LXI Legislatura, entrevista realizada el 12 de abril de 2013]
De tal manera que los diputados utilizan la información de desempeño de forma
simbólica, en lugar de buscar fines instrumentales. En otras palabras, esta información la
utilizan cuando coincide con alguna posición política entre los legisladores que sirva para
legitimar y apoyar decisiones previamente tomadas dependiendo del ámbito en el que se
desenvuelven. Por ejemplo, dependiendo del partido del diputado y sus objetivos
específicos votará por disminuir o aumentar el presupuesto de un programa,
independientemente de los resultados de desempeño. En este sentido, los diputados del
partido en el gobierno tienden a apoyar los programas prioritarios para la agenta del
Presidente. Al respecto, el mismo entrevistado explicó lo siguiente:
Dependiendo también de tu posicionamiento hacia adentro de la Comisión, es un juego político, si tu quieres golpear una posición entonces te vas a sentar “a ver el mes pasado hay un subejercicio en Oportunidades de 50 mil millones de pesos, qué pasó con eso, hay que citar al director de Oportunidades porque tenemos que decir que... o al secretario mismo”. Dependiendo de qué quieres, si el diputado quiere carne ahí vas sobre los informes para eso les sirven. Cada grupo parlamentario tiene un coordinador y entonces tu si no eres… digamos la bancada del PRI tiene 7 esos 7 obedecían al coordinador, entonces la posición que planteaba el coordinador era la que se llevaba. El PAN igual, el coordinador del PRI, por ejemplo, decía “queremos que se le bajen recursos a Oportunidades, ¿por que? porque vean la evaluación dice…” entonces ahí sacan todo lo que tenían de... les sirve para argumentar a favor o en contra. La asignación del presupuesto es una asignación política, no es una asignación técnica. No somos contadores. En una Cámara en donde hay negociaciones políticas de grupos políticos se asigna políticamente el presupuesto. En Estados Unidos es lo mismo, tienes un estira y afloje del presupuesto. El programa estrella del Presidente, Medicare, Medicaid, tienes que negociar fuerza política para que vaya adelante por más bien evaluado que resulte, por más gran programa técnico que sea, no pasa si no hay discusión política. La presupuestación en el fondo es política. [Entrevista realizada el 15 de abril de 2013 a un ex integrante del equipo técnico en la Comisión de Desarrollo Social de la LXI Legislatura]
Un caso que ejemplifica lo anteriormente descrito es el programa Oportunidades,
los resultados de sus evaluaciones permitieron legitimar esta intervención pública en la
147 de 212

transición a un nuevo gobierno de diferente partido. Al respecto, el Director General
Adjunto de Enlace para Evaluaciones Externas del Programa Oportunidades señaló lo
siguiente:
Al principio del programa era evaluado por dos razones: saber la eficacia de la intervención, si realmente el programa tenía los resultados que se esperaban de él a partir de cómo se diseñó, y también se investigaron algunos efectos como en aspectos comunitarios. Entonces la evaluación sirvió para demostrar un objetivo técnico para demostrar la eficacia de su creación y luego también para un objetivo político que fue validar la intervención; o sea presentarla ante los tomadores de decisión, senadores, diputados, grupos políticos porque era un programa focalizado y eso produjo mucha controversia, entonces una manera de focalizar que era un intervención efectiva pues fue a través de sus evaluaciones. A partir de eso se logró la continuidad de un gobierno priista a uno panista e incluso se amplió. [12 de noviembre de 2012].
Otra razón que explica el uso limitado de la información derivada de las
evaluaciones es el desconocimiento por parte de los diputados de la disponibilidad de
resultados de desempeño. Por ejemplo, debido a que no todos los informes de
evaluaciones llegaban a la Comisión de Grupos Vulnerables en la LXI Legislatura, ésta
acostumbraba reunirse con las dependencias para que presentaran los avances y la
información necesaria durante el periodo de negociación presupuestal. Al respecto, un
ex integrante del equipo técnico de esta Comisión explicó lo siguiente:
Sólo en la etapa de aprobación aumenta el flujo de información. Cuando tú dices "reciben la información" no es de que te la envíen, recibes información no porque te la mandan, sino porque la solicitas. La cadena de la información es amplia, porque a lo mejor hay información que le llega al presidente de la Cámara como titular y esta se publica en la gaceta parlamentaria y entonces ahí ya se cumplen los efectos de publicidad, pero hay una información que llega a la oficina para su análisis. En mi experiencia yo no identifico que alguna Secretaría de manera periódica te vaya, al menos a grupos vulnerables, informando de determinados programas. [Entrevista realizada el 22 de marzo de 2013]
Incluso, el desconocimiento de que dicha información existe, también afecta a los
legisladores que integran a la Comisión de Presupuesto y Cuenta Pública:
[Las evaluaciones] no se las mandan a la Comisión de Presupuesto, podrían mandárselas a la Comisión de Desarrollo Social. En la Comisión de Presupuesto no recibimos los informes trimestrales, no como diputado integrante del Congreso. Tal
148 de 212

vez lo puede enviar, como te lo señalo, o a la Mesa Directiva o a la Comisión de Desarrollo Social […] La negociación está secuestrada por los grupos parlamentarios y de entre ellos por sus coordinadores. Entonces, realmente hay un problema de funciones donde nosotros como diputados no tenemos mucho que hacer o mucho qué decir. Las reuniones las tienen los grupos parlamentarios a nivel de sus coordinadores. Hay un hecho muy lamentable que pasa aquí en la Cámara, que es que se generan bolsas compensatorias por Grupo Parlamentario que es un hecho, no sé si es sin precedentes, pero también es un hecho nuevo aquí en la Cámara. Los grupos parlamentarios negociaron bolsas para proyectos específicos que los diputados destinaron a sus entidades o municipios. Entonces cuál es la gravedad de esto que te estoy diciendo, que le quitan al legislador la perspectiva general y lo llevan a la perspectiva particular. [Diputado de la Comisión de Presupuesto y Cuenta Pública de la LXI Legislatura, entrevista realizada el 12 de abril de 2013]
Diseño Institucional
Por otra parte, el diseño institucional del sistema de evaluación es un factor que influye
tanto en las decisiones de mejora de los programas públicos, como en la asignación del
presupuesto. Sin embargo, influye de forma distinta en cada propósito porque los
incentivos para cada tipo de decisión funcionan de forma diferente. No obstante, como
se presentará de forma más clara en los siguientes párrafos, el diseño institucional con el
que se configuró el sistema de evaluación en México tiene mayores repercusiones en las
decisiones del presupuesto.
Por el lado de la influencia que tiene el diseño institucional en las decisiones de
mejora de los programas sociales, como primer punto se puede señalar que las
motivaciones diferenciadas que persiguen Hacienda, Función Pública y el CONEVAL al
coordinar las evaluaciones influyen en la forma en la que cada uno de estos actores
utiliza la información de desempeño. Por una parte, la Secretaría de Hacienda utiliza la
información con fines de control presupuestario; por otras, a partir de la misma
información, el CONEVAL busca generar una lógica de mejora continua entre las
dependencias y finalmente, la Función Pública utiliza la información a partir de una lógica
orientada al cumplimiento de la norma y la auditoría. Esta contradicción de propósitos
149 de 212

afecta los incentivos de las dependencias porque llega a provocar que en lugar de que los
resultados de desempeño sean información estratégica para oportunidades de mejora,
esta información es sujeta a valoraciones para la asignación de recursos u observaciones
de auditorías. En este sentido, hay ocasiones que los programas comprometen Aspectos
Susceptibles que les significan compromisos fácilmente ejecutables en detrimento de los
cambios profundos que requieren para verdaderamente mejorar al programa. Esta
motivación se explica porque los ASM se convierten en objeto de seguimiento de los
Órganos Internos de Control (OIC) de las dependencias, figuras que desde su origen
fueron creados para velar por el cumplimiento de normas y procedimientos
administrativos, en lugar de la orientación a resultados.
Un ejemplo de esta dinámica se presentó con el programa PCS, los responsables
de este programa tienen que estar constantemente pendientes de que la operación de
éste es sujeta al seguimiento que hace su OIC. Al respecto, la ex titular del INDESOL
señaló lo siguiente: Creo que faltan mecanismos institucionales para garantizar que esas recomendaciones se utilicen. Nosotros en particular tenemos una relación fructífera con el OIC y tenemos una comisaria de la Secretaría de la Función Pública que si está muy atenta a los resultados de las recomendaciones y que en la reuniones de comité de control y desempeño institucional nos pide rindamos cuenta sobre el seguimiento que damos a esas recomendaciones sin embargo desconozco si es una cuestión personal o si es una cuestión más institucional, en nuestro caso si tenemos ese diálogo muy fructífero. Pero continuamente, trimestralmente, revisamos la evolución del seguimiento a esas recomendaciones. [Entrevista realizada el 31 de octubre de 2013].
Lo mismo podemos señalar para el caso de la Secretaría de Hacienda que entiende
los ejercicios anuales de evaluación sólo en el contexto del proceso presupuestal. A
propósito de esta lógica, el director general adjunto de la Unidad de Evaluación del
Desempeño de esta Secretaría señaló lo siguiente:
150 de 212

Las evaluaciones son sólo una vertiente para poder conocer cabalmente cómo se comporta un programa presupuestario. Además de las evaluaciones, tu tienes cómo gasta un programa, segundo, con qué efectividad gasta los recursos, o sea cuál es la relación entre avances de la metas de acuerdo a recursos asignados, luego tienes la evaluación, pero además tienes el tema de prioridades. Entonces, las evaluaciones son instrumentos que te permiten mejorar un programa. Las evaluaciones no tienen sentido si no las relaciones en el ciclo programático presupuestal. El PBR tu lo haces cuando los resultados de la información de desempeño los utilizas para afectar cada uno de esos tiempos del ciclo programático presupuestal y entonces sí, la evaluación incidirá en todo el presupuesto. Si no es así, no tiene ningún sentido. Lo importante es que una evaluación se utilice para mejorar la programación y presupuestación, y depende de qué tipo de evaluación estés hablando. [24 de octubre de 2013].
La visión del CONEVAL es distinta. Según la Directora General Adjunta de Evaluación de
este Consejo en el marco del sistema de evaluación esta institución tiene otro propósito
distinto:
No, nosotros no creemos en eso, lo que nosotros creemos es qué tanto el programa atiende o no y está resolviendo la problemática para el cual fue creado. Un ejemplo es Caravanas de la Salud, y cuyo costo de operación era muy alto y se le quería quitar más dinero, nosotros apoyamos que se le diera más dinero para tener más resultados dados los resultados de evaluación; otro ejemplo, es el programa de vacunación nacional. En mi experiencia me parece que no hay un sólo país en el mundo que tenga esta racionalidad, ni siquiera Corea, y más allá de eso, al final tú no buscas que la evaluación te diga que si le subes o le bajas a un programa, porque eso del presupuesto es una de las decisiones más políticas en cualquier país. Entonces más bien, lo que quiere aportar la evaluación en este tramo específico es más bien dar más información por un lado, de los objetivos nacionales y por otro, del resultado de los programas y que cuando los programas toman esa información para mejorar ya están haciendo PBR, porque están haciendo una reorientación de sus propios recursos hacia los objetivos o alcances para los que fueron creados. [Entrevista realizada el 25 de enero de 2013].
Estas lógicas encontradas provocan que los propósitos por los que se evalúan
programas sean tres: control administrativo y auditoría, control presupuestario y mejora
continua de las intervenciones públicas. Esta multiplicidad de propósitos convierte a la
evaluación en una política federal desarticulada que lleva a las instituciones
coordinadoras por caminos diferentes; incluso, a nivel operativo esta dispersión de
objetivos provoca que los programas atiendan demandas desvinculadas en lugar de
focalizarse hacia el logro de resultados y en la acumulación incremental del aprendizaje
organizacional.
151 de 212

Un segundo punto relacionado con la influencia del diseño institucional en las decisiones de mejora es el relacionado con la implementación del Mecanismo de Seguimiento de ASM. El proceso que siguen los programas para comprometerse con Aspectos Susceptibles de Mejora se sujeta a criterios internos de las propias dependencias y no existen procesos institucionales externos o incentivos que procuren la calidad de los ASM, así como tampoco consecuencias claras cuando el grado de cumplimiento de éstos resulta deficiente. Aunque se entiende que el proceso para comprometer ASM es un espacio de decisión para los programas, ya que son éstos los que mejor conocen las necesidades y los tiempos para atenderlos, se requiere crear un cuerpo colegiado externo que funcione como contrapeso a las decisiones de las dependencias. La presencia de este cuerpo colegiado también contribuiría a hacer más transparentes los procesos de decisión que marcan el rumbo de las políticas públicas. Aunque el documento normativo del Mecanismo de Seguimiento emitido en el año 2011 señala en el numeral 17, que la Secretaría de Hacienda, de la Función Pública y el CONEVAL pueden fungir como este cuerpo colegiado para “seleccionar a un grupo de programas federales y/o presupuestarios para analizar los resultados de las evaluaciones, y el proceso de seguimiento a los aspectos susceptibles de mejora derivados de los informes y las evaluaciones externas y, en su caso, sugerir y/o solicitar modificaciones y adiciones a los aspectos susceptibles de mejora y a las acciones que deriven de éstos”, en realidad esto no sucede. En este sentido, el Mecanismo de Seguimiento aún carece de un sistema de consecuencias que genere incentivos negativos para aquellos programas que no colaboren con el espíritu del Mecanismo, ni tampoco cuenta con la fuerza suficiente para fungir como contrapeso al proceso de discusión y análisis interno de los programas. El funcionamiento que actualmente tiene el Mecanismo de Seguimiento limita que los
152 de 212

cambios verdaderamente necesarios que requieren los programas se implementen con
mayor probabilidad cuando están presentes únicamente la capacidad técnica y el
liderazgo del operador, porque el Mecanismo no provee de mayores incentivos. Es
necesario establecer mecanismos para vincular el cumplimiento de los ASM con acciones
como influencia en la decisiones presupuestales, responsabilidades puntuales hacia los
servidores públicos, reconocimiento público, por mencionar algunas.
Ahora bien, como se señaló al inicio de este apartado la carencia de incentivos en
el diseño institucional del sistema de evaluación en nuestro país afecta de forma más
clara en las decisiones del presupuesto. Como lo explica el director general adjunto de la
Unidad de Evaluación del Desempeño de la Secretaría de Hacienda: En México el PBR-SED todavía adolece de incentivos, no tienes ni incentivos positivos, ni negativos. El mejor incentivo es que te digan “oye que bien estás haciendo el programa” o en sentido negativo que te jalen las orejas, pero no tienes dientes que te permitan normar la conducta de los agentes públicos o privados, ese es el problema. A mi me gustaría explorar el tema contractual de la evaluación, porque si tu logras hacer convenios de desempeño, como en CFE o PEMEX, yo pienso en un convenio que puedas establecer un compromiso con la alta gerencia de un programa y que a través de ese convenio corrija el programa. Entonces los Aspectos Susceptibles de Mejora son insuficientes.
Otra de las razones por las cuales el diseño institucional afecta más las decisiones
del presupuesto es la oportunidad temporal en que se presentan los resultados de las
evaluaciones. La fecha en la que se tienen los informes finales de evaluación no coincide
con la etapa de formulación y negociación del ciclo presupuestario. Para analizar este
tema conviene centrarnos en la coincidencia entre el calendario del proceso
presupuestario con el calendario del Programa Anual de Evaluación y aquél que le da
seguimiento al cumplimiento de los Aspectos Susceptibles de Mejora. (Ver Tabla 13 y 14)
Como se mencionó en el capítulo uno, para que una recomendación sea oportuna
la información sobre los resultados y hallazgos de las evaluaciones debe estar disponible
153 de 212

en la etapa de toma de decisiones. Cuando un sistema de evaluación, como el caso

mexicano, está orientado al Presupuesto basado en Resultados, el seguimiento a la

implementación de las recomendaciones debe coincidir y retroalimentar el ciclo

presupuestal.

En México, el Presupuesto basado en Resultados y el Sistema de Evaluación del

Desempeño tienen una lógica anual, sin embargo, como se puede observar en la Tabla

14, el calendario de entrega de resultados señalado en el Programa Anual de Evaluación

no necesariamente coincide con el proceso presupuestal y el calendario del Mecanismo

de Seguimiento.

Tabla 13. Información que coincide con la etapa de planeación del presupuesto.

Tipo de Evaluación

Resultados disponibles Información disponible sobre cumplimiento

de los Aspectos Susceptibles de Mejora

Específica de Desempeño





Diseño





Programas nuevos





Procesos





Impacto





Consistencia y Resultados





Fuente: elaboración propia con base en los calendarios del PAE y del Mecanismo de

Seguimiento.

A partir de estos calendarios, podemos observar que sólo los resultados de la Evaluación Específica de Desempeño, la de diseño y de los programas nuevos alcanzan a considerarse en la planeación del siguiente ejercicio presupuestal. Los resultados de las evaluaciones de procesos (que se entregan en diciembre), de impacto y, de consistencia y resultados (cuya entrega de resultados está sujeta a las fechas establecidas por las dependencias) quedan fuera de la lógica anual que sigue el presupuesto. De hecho, los informes de evaluación se concluyen una vez tomadas las decisiones sobre el presupuesto del siguiente año fiscal. Esto no descarta que se considere dicha información en otros momentos, sobre todo si la decisión es ajustar el programa, pero la probabilidad de considerarla en decisiones presupuestales posteriores disminuye debido al volumen
154 de 212

de información al que están sujetos los diputados en distintos periodos del trabajo legislativo.
Para cuando la Secretaría de Hacienda entrega, el 8 de septiembre, el proyecto de presupuesto del siguiente año fiscal a la Cámara de Diputados, las dependencias, al último día del mismo mes, apenas informan sobre los avances de seguimiento del Mecanismo de Seguimiento en curso. En otras palabras, para estas fechas la Secretaría de Hacienda ya no tuvo oportunidad de considerar los avances de los ASM para la planeación del siguiente ejercicio fiscal. Por su parte, los actores entrevistados de la Cámara de Diputados señalaron que desconocían un informe de seguimiento a los avances de los ASM porque esta información no se les entregaba.
En síntesis, existe un desfase entre la generación de resultados de las evaluaciones y los tiempos de la negociación presupuestal. Este desfase puede provocar que la información sobre evaluación recibida por los actores encargados de dar seguimiento a los compromisos de las dependencias -CONEVAL, Secretaría de Hacienda y Función Pública- no refleje el esfuerzo de los programas que hicieron para implementar acciones de mejora.
155 de 212

Tabla 14. Comparación de los calendarios para el ciclo presupuestal, del Mecanismo de

Seguimiento y del Programa Anual de Evaluación en el caso mexicano.

Fecha

Proceso Presupuestal*

Seguimiento al Mecanismo para el
seguimiento Aspectos Susceptibles de Mejora (ASM)107

Programa Anual Evaluación**

de

Las Secretarías entregan un reporte a

la Secretaría de la Función Pública y al

Consejo Nacional de Evaluación un

Marzo

reporte de los avances en el cumplimiento de las actividades

relacionadas con los ASM derivados de

Mecanismos de Seguimiento

anteriores.

El Ejecutivo presenta al Congreso Entrega del documento de trabajo,

las

proyecciones documento institucional y documento

1 de abril macroeconómicas del siguiente de opinión de la Secretaría (posición

ejercicio fiscal.

institucional) sobre el Mecanismo de

Seguimiento en curso.

Las Secretarías comienzan a Las Secretarías informan sobre los Entrega de resultados de

Junio

redactar sus propuestas de aspectos interinstitucionales e la evaluación específica de

presupuesto.

intergubernamentales derivados del desempeño108

Mecanismo de Seguimiento inmediato

anterior.

Las Secretarías deben presentar

Entrega de resultados de

sus proyectos multianuales de inversión a la Secretaría de

la evaluación de diseño y de programas nuevos109

Julio

Hacienda. Esta última establece el tope agregado para el

presupuesto y circula el manual

para programar y presupuestar (la

circular del presupuesto anual).

1 a 4 de agosto

La Secretaría de Hacienda comunica los topes por sector a las Secretarías.

Las Secretarías presentan sus

11 a 22 de presupuestos de manera

agosto

electrónica a la Secretaría de

Hacienda.

25 de

La Secretaría de Hacienda integra

agosto

la propuesta de presupuesto.

25 de

Se realizan las revisiones finales

agosto a 8 antes de presentar el presupuesto

septiembre al Congreso

Se entrega el proyecto de Entrega de avances del cumplimiento

Septiembre

Presupuesto de Egresos de la Federación al Congreso (8 de

de actividades relacionadas con los ASM derivados del Mecanismo de

septiembre)

Seguimiento en curso110.

Antes de El Congreso aprueba el

15 de

presupuesto

noviembre

Diciembre

Entrega de resultados de la evaluación de procesos

Nota: Los resultados de la evaluación de impacto, de consistencia y resultados se entregan de acuerdo a las

fechas establecidas en los términos de referencia respectivos establecido por cada programa. *Calendario

consultado en OCDE, 2009. **Fechas de entrega consultadas en PAE de los años 2008 a 2012. Fuente:

Elaboración propia con base en OCDE, 2009; Mecanismo para el seguimiento a los Aspectos Susceptibles de

Mejora derivados de informes y evaluaciones a los programas presupuestarios de la Administración Pública

Federal, 2011; Programa Anual de Evaluación 2008-2012.

107 El calendario con las fechas de entrega fue consultado en http://www.shcp.gob.mx/EGRESOS/sitio_pbr/evaluacion/Paginas/ASM.aspx 108 A más tardar el último día hábil del mes junio. 109 Último día hábil del mes julio. 110 A más tardar el último día hábil del mes septiembre.
156 de 212

Año 1 Ejecución del programa
Año 2 Evaluación del programa
Año 3
Registros y avances de ASM
Año 4 Conclusión de ASM

Para explicar mejor las consecuencias que esta situación tiene, se debe mencionar que el ciclo de evaluación de un programa dura aproximadamente un periodo de cuatro años desde que éste se ejecuta, evalúa y finalmente, da por concluido el cumplimiento de los ASM. (Ver Figura 6)
Figura 6. Ciclo de evaluación y cumplimiento de ASM
Fuente: Elaboración propia con base en información de CONEVAL.
Aunque el Mecanismo de Seguimiento señale como uno de sus objetivos que el seguimiento de los ASM debe contribuir a mejorar el proceso programático presupuestal, el ciclo natural de una evaluación imposibilita que los ASM retroalimenten completamente al presupuesto bajo una lógica anual. Por ejemplo, supongamos que en el 2008 (año 1) el programa X ejecuta sus actividades; en 2009 (año 2) el programa se evalúa; para abril de 2010 (año 3) el programa registra por primera vez sus ASM y para el mes de septiembre de ese mismo año, el programa registra el porcentaje de avances de los ASM registrados a principios de ese año. Finalmente, para marzo de 2011 (año 4) el programa da por concluido el cumplimiento, siempre y cuando el programa haya planeado que implementar las actividades programadas del ASM le llevaría solamente un año. Los casos documentados dan cuenta de que generalmente los programas se comprometen a concluir sus ASM en un periodo promedio de dos años. Entonces en sentido estricto, los avances reales del programa X se pueden considerar para la
157 de 212

planeación del presupuesto hasta el quinto año de su operación. El tiempo que transcurre entre que el programa se ejecuta e integra los reportes finales de sus avances, puede provocar el incentivo negativo de que los actores clave opten por no considerar esta información para las decisiones presupuestales (Ver Figura 6). En otras palabras, el problema es que el ciclo de seguimiento de una evaluación y cumplimiento de los ASM dura al menos un periodo de cuatro años y el calendario presupuestario tiene una lógica anual. Sin embargo, como señaló Ernesto Cordero, ex Secretario de Hacienda, aunque este desfase de información existe, lo que se hace al momento de integrar el presupuesto es tomar la última información disponible.
Cabe mencionar que las entrevistas que se realizaron para esta tesis se hicieron durante los últimos meses de 2012 y los primeros de 2013. Aunque los entrevistados expresaron que la falta de coincidencia en la disponibilidad de información era un problema para las decisiones de presupuesto, las modificaciones que se hicieron al PAE 2013 aseguraron que, al menos, los resultados de las Evaluaciones Específicas de Desempeño estuvieran disponibles al mes de septiembre para cuando el proceso de negociación presupuestal comienza al interior de la Cámara de Diputados. Este cambio en las fechas de entrega de las Evaluaciones Específicas de Desempeño (de junio a septiembre) puede provocar que para futuras negociaciones presupuestales, los legisladores tengan menores incentivos a revisarlas a medida que en septiembre comienza el periodo de negociación y además, tienen una gran carga de información por revisar.
Por otra parte, un factor que determina el diseño institucional del sistema de evaluación durante el proceso de negociación del presupuesto, tiene que ver con el escaso margen de negociación presupuestal que tienen los legisladores una vez que el
158 de 212

Proyecto de Egresos de la Federación es presentado por la Secretaría de Hacienda. En
este sentido, una de las razones que explican la lógica inercial del gasto público es que la
mayor parte de sus componentes ya están comprometidos antes de su llegada a la
discusión en la Cámara de Diputados en partidas tales como: subsidios, pensiones,
transferencias a entidades federativas, pagos de la deuda y salarios, entre otros. Razón
por la cual la negociación real que los legisladores pueden hacer se limita solamente
entre el 5 y el 8 por ciento del presupuesto total, este margen de recursos provoca una
negociación más compleja debido a que son recursos limitados sujetos a los intereses de
múltiples fuerzas políticas. El siguiente párrafo de la entrevista realizada al diputado de
la Comisión de Presupuesto y Cuenta Pública de la LXII Legislatura refleja el elevado
grado de negociación política que tiene esta porción del menos del 10 por ciento del
presupuesto:
El presupuesto está muy sujeto a los estilos políticos de los grupos gobernantes y a la correlación de fuerzas. Ahora el estilo político impuso una nueva negociación del presupuesto, donde la Cámara pues tuvo un papel muy marginal. Tu veías desfilar en años anteriores aquí a gobernadores, a rectores de universidades, a instituciones de órganos autónomos, porque la Cámara tenía una movilidad más o menos significativa, no en términos porcentuales porque nunca se ha movido una parte muy importante del presupuesto, no pasa ni del 5 por ciento lo que la Cámara mueve con respecto al proyecto que manda el Ejecutivo, pero sí podía mover muchas cosas, había un espacio de negociación. Y en el caso del nuevo gobierno, regresa un estilo de negociación pasado donde los gobernadores, como dieron constancia de ello diferentes medios de comunicación, fueron a Gobernación a negociar su presupuesto con el entonces presidente electo. Este año no desfilaron por la Cámara, donde las universidades y los órganos autónomos también siguieron el mismo procedimiento, y la capacidad de movilizar de la Cámara fue muy baja. Conclusión aquí estuvo instalada la Subsecretaría de Egresos prácticamente haciendo el dictamen. Nosotros no tuvimos un gran margen de maniobra, se aprobó en menos de diez minutos en Comisión de Presupuesto y en el Pleno.
Finalmente, otra característica del diseño institucional que explica el desinterés
de los legisladores para utilizar la información de las evaluaciones es la escasa capacidad
159 de 212

de éstos para asimilar el gran volumen de información que les llega continuamente111, en
especial falta de capacidad en materia de presupuesto para utilizar instrumentalmente
los estudios y evaluaciones sobre programas sociales. Este problema se ve agravado ante
la falta de un cuerpo técnico especializado que analice y procese sistemáticamente toda
la información de las evaluaciones. Aunque la Ley de Presupuesto (LFPRH) señala que
una de las funciones del Centro de Estudios de las Finanzas Públicas de la Cámara de
Diputados es apoyar a los legisladores para procesar y dar seguimiento a la información
de desempeño, ésta no lo realiza. Al respecto, una investigadora del Centro señaló en
entrevista que la carga de trabajo de este cuerpo técnico sobrepasa la capacidad de
análisis de los pocos investigadores que se dedican al tema presupuestal en este lugar. Su
tarea se enfoca, sobre todo, a entregar a solicitud de los legisladores análisis sobre el
impacto presupuestal de las iniciativas de ley que éstos presentan en el periodo
legislativo, y hasta ahora la información sobre desempeño no es un tema prioritario
entre sus funciones. Esta situación provoca que el uso de la información dependa más
del estilo personal de cada legislador que de procedimientos sistemáticos al interior de la
Cámara. Al respecto, un ex integrante del equipo técnico en la Comisión de Desarrollo
Social en la LXI Legislatura señaló lo siguiente:
[Las evaluaciones] llegan dirigidas al Presidente de la Comisión. Nosotros teníamos la costumbre solamente, no se hizo en otras legislaturas, nosotros lo circulábamos entre los asesores de los diputados y a los diputados mismos. Regularmente el cuerpo técnico del diputado es que el hace el análisis, prepara tarjetas, prepara informes. O sea por ejemplo, te llega el informe del Banco de México, ¿qué es esto? te va a decir es diputado. Entonces nosotros teníamos dos vías. Nosotros hacíamos reuniones semanales con el cuerpo de asesores, que eran 30 y ahí discutíamos tanto
111 En particular, en el tema de evaluación los diputados reciben los informes trimestrales que prepara la Secretaría de Hacienda, el informe de consideraciones presupuestales, el Inventario de Programas y Acciones Federales, los informes finales de las Evaluaciones Específicas de Desempeño, las fichas narrativas, la Valoración del Desempeño de los Programas, las Evaluaciones Integrales y las Evaluaciones Estratégicas, todos estos documentos producidos por el CONEVAL; además, los informes finales de todas las evaluaciones obligadas por el PAE de cada año.
160 de 212

los informes, como los proyectos de dictámenes de iniciativas o de puntos de acuerdo, ¿qué hace eso? que el diputado tuviera mayor información a su disposición. Todo informe que llegaba se le mandaba al diputado. Para el presidente de la comisión se hacía un abstract y para los asesores se hacía discusión […] Sólo los coordinadores de grupo y los asesores sí leen esos informes trimestrales. . [Entrevista realizada el 15 de abril de 2013]
Vale la pena mencionar que otros factores como el liderazgo y la presencia de grupos organizados tales como, organizaciones de la sociedad civil, grupos de campesinos o cualquier otro grupo con intereses definidos, no tuvieron influencia en el gasto asignado a los programas de atención a grupos vulnerables. Existen dos posibles explicaciones que ofrecen respuesta a este comportamiento: primero, las decisiones en torno al gasto público responden a negociaciones que involucran a muchos actores con intereses y preferencias políticas y no solamente a un individuo; segundo, como se mencionó en el capítulo 1, aunque existe presión por parte de grupos organizados para la distribución de los recursos, las transferencias que involucra el gasto público se realizan inercialmente con un destino específico desde el gobierno federal, independientemente de los resultados logrados. Como se ha documentado, hasta ahora algunos legisladores comienzan a revisar la información sobre desempeño, sin embargo no es una práctica sistemática. En este sentido, las características institucionales que involucran el gasto público permiten que las decisiones en este rubro se sigan explicando a partir de procesos de negociación política.
En resumen, este capítulo presentó los factores identificados que influyen con más peso en las decisiones orientadas a la mejora de los programas públicos y en las decisiones presupuestales. De la evidencia presentada, se puede concluir que las decisiones de mejora de los programas públicos en general suceden cuando existe liderazgo y compromiso por parte del operador del programa, capacidad técnica y cuando las recomendaciones son factibles para el programa debido a que durante el proceso de evaluación se procuró la buena comunicación con el evaluador.
161 de 212

Para las decisiones presupuestales, las variables que mejor explican los cambios en los montos asignados son el criterio político que domina en la negociación presupuestal y el diseño institucional del sistema de evaluación. Debido a que en el proceso presupuestario se consideran las prioridades del Ejecutivo y los intereses partidistas de los diputados, es más probable que la información de desempeño pase a un segundo plano. Esta situación seguirá existiendo mientras el diseño institucional no cree mayores incentivos para que las evaluaciones se utilicen de forma sistemática y con objetivos instrumentales.
Por lo anterior, el sistema de evaluación que actualmente tenemos ha provocado que los resultados de las evaluaciones se utilicen con fines instrumentales para las decisiones de mejora continua en los programas de tipo social. Sin embargo, en las decisiones de presupuesto su uso aún se limita a ser de tipo simbólico.
162 de 212

Capítulo 4. ¿Qué factores explican el sistema de evaluación en la experiencia mexicana?
Este capítulo responde a la hipótesis que ha guiado la investigación a través de las tres principales preguntas planteadas desde el inicio: ¿Qué tipo de decisiones se adoptan a partir de los resultados de las evaluaciones en el ámbito federal? ¿Qué factores influyen para que las recomendaciones se utilicen efectivamente en acciones concretas? ¿Cómo afecta la falta de incentivos en el sistema de evaluación? Para responder cada pregunta se sintetiza la experiencia documentada a través del caso de estudio y de las entrevistas desarrolladas. En particular, para contestar la segunda pregunta, se presenta el modelo de toma de decisiones ajustado que describe cómo se utilizan en la experiencia mexicana los resultados de las evaluaciones en política social y cuáles son los principales factores que explican los distintos usos que se les dan en el ámbito federal. Recordemos que la hipótesis principal de esta investigación sugiere que, en México, en particular en los programas de tipo social, los resultados de las evaluaciones se utilizan con fines instrumentales para las decisiones de mejora continua de desempeño. Sin embargo, la influencia de esta herramienta en las decisiones relativas al presupuesto se ha limitado al uso simbólico debido a la falta de criterios técnicos durante el proceso de negociación y a la carencia de incentivos en el sistema de evaluación. Con el objeto de proporcionar evidencia que refuerce la hipótesis, iremos contestando cada una de las preguntas mencionadas.
163 de 212

¿Qué tipo de decisiones se adoptan a partir de los resultados de las evaluaciones en el ámbito federal? Nuestro acercamiento a la primera pregunta nos permite señalar que según el marco normativo del sistema de evaluación, la utilización de la información derivada de evaluaciones tiene dos propósitos principales: mejorar los programas públicos y retroalimentar las decisiones del presupuesto, ambos objetivos contribuyen a la cadena de la rendición de cuentas, puesto que un efecto de ellos es contribuir a la transparencia en relación al ejercicio del gasto y a los resultados de los programas.
Las experiencias aquí documentadas permiten identificar que la evaluación cumple fines instrumentales –uso efectivo de hallazgos y recomendaciones- cuando el objetivo es alcanzar mayor eficacia de los programas públicos. Mediante ejercicios sistemáticos de evaluación, los tomadores de decisiones pueden conocer logros de objetivos y metas, los efectos de las intervenciones y facilita la incorporación de lecciones aprendidas para mejorar el desempeño de los programas públicos. Por otra parte, los resultados de las evaluaciones cumplen fines simbólicos cuando se busca retroalimentar el proceso presupuestario. En la negociación presupuestal, los resultados de las evaluaciones todavía se limitan a servir como herramientas simbólicas para ganar la credibilidad y legitimidad de las decisiones presupuestales a partir de la presentación de resultados que coinciden con las agendas políticas previamente identificadas. En este sentido, aún se necesita estrechar el vínculo entre el proceso de evaluación y el proceso presupuestal. Sin embargo, México no es la excepción, implementar el PBR es un reto que no lo ha podido resolver satisfactoriamente ningún país debido a que el presupuesto es un proceso esencialmente político en el que permean las prioridades del gobierno en
164 de 212

turno y los intereses partidistas que buscan incidir en aquellos proyectos que les aseguren mayor exposición política.
Si analizamos al sistema de evaluación en México mediante una imagen de fotografía, nuestro acercamiento a través de esta investigación permite identificar que el diseño normativo e institucional del sistema se ha concentrado más en que la utilización sistemática de la evidencia tenga mayores efectos en la mejora de los programas públicos, nivel meso (programas), que en los otros dos niveles que Ospina, Cunill y Zaltsman reconocen como niveles macro (institucional) y mico (personas). Una vez identificado que existen distintos propósitos que promueven tanto la Secretaría de Hacienda, de la Función Pública, como el CONEVAL en materia de evaluación, se puede señalar que aún existen retos para alcanzar la integración vertical y horizontal de la que hablan Ospina, Cunill y Zaltsman sobre la evaluación del desempeño en el ámbito federal. Los objetivos desarticulados que permean en el diseño institucional y en particular, en el trabajo independiente de cada dependencia coordinadora del sistema, aún plantean serias deficiencias para alcanzar los objetivos de una política pública coherente en materia de evaluación.
Entonces, si uno de los principales objetivos de la evaluación es que los resultados sean considerados en el proceso de análisis y aprobación del Presupuesto de Egresos de la Federación ¿en qué nivel se encuentra México en esta materia? A partir de la evidencia empírica observada en el capítulo anterior, el caso mexicano aún se ubica en el modelo presentacional, de acuerdo a la clasificación que refiere la OCDE y que fue descrito en el primer capítulo de esta tesis. El modelo de PBR adoptado por nuestro país ha servido para nutrir la cadena de rendición de cuentas y para facilitar el diálogo político entre el poder Ejecutivo y el Legislativo. Sin embargo, este diálogo entre ambos poderes
165 de 212

aún no cumple su función de pesos y contrapesos constitucionales porque las decisiones de la Cámara de Diputados en materia de presupuesto siguen reflejando una lógica esencialmente política. La pluralidad que se dio a partir de 1997 en el Congreso no se ha traducido en una mayor calidad del gasto porque hasta ahora los criterios técnicos que puede aportar una evaluación han quedado rezagados ante los intereses partidistas en el Congreso. El papel de la Cámara de Diputados para fomentar el uso instrumental de las evaluaciones en el gasto público aún es muy limitado. En este sentido, el sistema de evaluación en México ha transitado con mayor facilidad en el ámbito de acción del Ejecutivo Federal que en el del Legislativo, debido a que la información de desempeño se usa de forma sistemática en el caso del primero, y de forma muy esporádica en el segundo.
¿Qué factores influyen para que las recomendaciones se utilicen efectivamente en acciones concretas? Aunque las experiencias aquí documentadas dieron cuenta de la enorme heterogeneidad de problemas para operar que enfrentan los programas públicos de tipo social, de manera general nos permiten identificar algunos factores comunes que influyen para que los programas detonen procesos internos de mejora. Sin embargo, esta ruta no influyó de forma directa en el proceso de presupuestación.
En este sentido, y para contestar la segunda pregunta relacionada con los factores que influyen en la toma de decisiones alrededor de las políticas públicas, se presenta un modelo de toma de decisiones que intenta captar de forma esquemática los factores que tienen mayor peso para que los resultados de las evaluaciones se utilicen en las de decisiones de política social particularmente los programas para grupos vulnerables,
166 de 212

tanto en el ciclo de acciones de mejora del programa, como en las relativas al presupuesto.
A fin de ejemplificar este modelo, se retoma la Figura 1 expuesta en la sección introductoria y se ajusta de acuerdo a la evidencia observada en el capítulo tres (Figura 7), de tal forma que el modelo se presenta como una propuesta evolucionada que se adapta a la realidad del contexto mexicano para los programas sociales de atención a grupos vulnerables. Su objetivo es presentar de forma sintética el panorama general de lo que sucede con la implementación del sistema de evaluación de la política social en la experiencia mexicana y advertir que de los usos más comunes que se les da a las evaluaciones son, como ya se ha dicho, el instrumental y el simbólico. Por una parte, el propósito instrumental se deriva de un proceso de decisiones al interior de la dependencia que incorpora recomendaciones de las evaluaciones para la mejora al ciclo del programa y las traduce en aspectos que sean susceptibles de convertirse en acciones orientadas a corregir actividades o procesos del programa y reorientar su propósito. Por otra parte, el propósito simbólico es el resultado del uso real que los diputados, en especial los que integran la Comisión de Presupuesto y Cuenta Pública, hacen de las evaluaciones a fin de encontrar los mejores argumentos que legitimen sus intereses políticos. La relevancia de estudiar el propósito simbólico radica en que es la Cámara de Diputados el único actor que de manera formal aprueba la versión final del gasto público. Por ello, las decisiones que se puedan tomar dentro de este espacio son en torno a aumentar o disminuir los recursos de un programa o crear nuevas intervenciones de política pública. Para el caso de los programas documentados para esta tesis las decisiones se orientaron solamente hacia aumentar o disminuir recursos.
167 de 212

Asimismo, este modelo representa que de manera consistente la utilización efectiva de las evaluaciones en los casos documentados dependió de la generación de liderazgos internos; de la capacidad organizacional para traducir los hallazgos y recomendaciones de las evaluaciones en un conjunto de acciones puntuales y, de la factibilidad de las recomendaciones externas que pudieran implementarse (factores que de forma general pueden ser clasificados de tipo organizacional y relacionados con las características propias de las evaluaciones). Estos factores influyeron sistemáticamente en las estrategias de mejora de las cinco experiencias analizadas. Por otra parte, en el proceso de negociación de sus presupuestos influyeron factores políticos y de diseño institucional; la influencia de ambos elementos provocó que las evaluaciones se limitaran a ser utilizadas de forma simbólica en la negociación final de los recursos presupuestarios.
Aunque es difícil representarlo gráficamente, el modelo también asume que el cambio que presentan los programas de tipo social es el resultado de ejercicios de prueba y error que incrementalmente han tratado de alinear la política pública a criterios más ordenados que buscan mayor coherencia con una nueva racionalidad. Sin embargo, las decisiones que explican estos cambios son una combinación de elementos organizacionales y administrativos, de límites legales, intereses particulares, precedentes cognitivos y experiencias previas que hacen de la política pública una expresión del ajuste pausado en las decisiones públicas, con lo que se estaría más cerca de un modelo incremental de toma de decisiones. (Ver Tabla 15)
168 de 212

Figura 7.Modelo de toma de decisiones ajustado al caso de los programas federales de Atención a Grupos Vulnerables

Fuente: Elaboración propia.

Tabla 15. Usos más comunes de las evaluaciones realizadas a Programas federales de Atención a Grupos Vulnerables

Tipo de decisiones
Mejora de los programas

Principales usuarios

Factores dominantes

 Responsables de los programas

1. Liderazgo 2. Capacidad
organizacional

 Unidades de Evaluación

3. Factibilidad

Clasificación de factores

Efectos observados

Organizacional (demanda)
Características de las
evaluaciones (oferta)

 Corrección de procesos y actividades
 Modificación de apoyos (productos y servicios)
 Reorientación del propósito del programa

Utilización de las evaluaciones
 Políticas basadas en evidencia
 Uso instrumental

 Secretaría de Hacienda
 Legisladores

1. Política

Asignación presupuestaria

 Asesores de la Cámara de Diputados

 Presidente de la República
Fuente: Elaboración propia.

2. Diseño institucional (temporalidad)

Demanda
Oferta y demanda

 Justificaciones previas
 Reorientación del gasto entre programas

 Discrecionalidad de las decisiones
 Uso simbólico

169 de 212

En particular, para cumplir el objetivo de mejora en la operación cotidiana de los casos estudiados, se necesitó la presencia de liderazgos que se comprometieron con resaltar la utilidad de las evaluaciones. La apropiación de los ejercicios de evaluación resultó de la aceptación explícita por parte de los operadores de los programas para asimilar estas iniciativas como procesos que revelaron información útil y estratégica hacia la creación de un mapa de ruta para el cumplimiento de los Aspectos Susceptibles de Mejora, y para garantizar el tránsito hacia la mejora continua en la operación cotidiana de los programas. Sin embargo, para que el operador de un programa identificara como estratégicos los resultados de las evaluaciones, primero tenía que estar convencido, antes que nadie, de que este instrumento le serviría como herramienta de apoyo para respaldar decisiones sobre futuros cambios en la gestión del programa, y no como mecanismo de control y auditoría que busca fiscalizar las actividades administrativas asociadas a la implementación de políticas. Cuando el operador asume que el quid de las evaluaciones es aportar información de calidad para sus decisiones, éste se apropia de forma más fácil de los resultados.
La presencia de liderazgos también comprendió a otros actores además del operador. Uno de éstos fue la presencia de Unidades de Evaluación para acompañar a los programas en las distintas etapas de monitoreo y evaluación con conocimiento técnico durante el proceso. Incluso en niveles de coordinación del sistema, el CONEVAL ejerció liderazgo para impulsar acciones de mejora a través de la operacionalización del Mecanismo de seguimiento y de la capacitación y diálogo constante que mantuvo con los operadores de los programas. Este liderazgo provocó que los cinco programas de tipo social se integraran en una estructura de incentivos orientada por la lógica continua de cambios. En este mismo sentido, el liderazgo de los últimos titulares al frente de
170 de 212

SEDESOL provocó que en materia de evaluación se registraran avances sostenidos en el sector social. Aunque en los últimos dos años se ha intentado incluir a otros sectores en la política de evaluación, como el carretero, política exterior y el de seguridad pública, los avances han sido mucho más modestos. En el corto y mediano plazo, es necesario que estos sectores también generen instrumentos de medición e información relevante para medir resultados que mejoren sus programas.
Otro de los factores que contribuyeron a mejorar los procesos internos de gestión de los casos documentados fue la capacidad operativa real de los programas. En particular, la capacidad técnica, administrativa y la experiencia institucional en materia de evaluación fueron elementos que influyeron para que los operadores se apropiaran de la información de las evaluaciones y las tradujeran en acciones concretas. Un operador de programa que tiene mayor capacidad para analizar, procesar y seleccionar las recomendaciones y hallazgos de las evaluaciones refleja mayor habilidad en el lenguaje técnico de la evaluación y una mejor implementación de recomendaciones en acciones concretas. Una primera lección que se obtuvo de la experiencia documentada es que los programas aún enfrentan la carencia de información de calidad para servir como insumo en el proceso de evaluación, no cuentan con indicadores pertinentes que capten resultados e incluso, la presencia de sistemas de información fragmentados provocó descoordinación interinstitucional entre programas y entre las instancias federales y las estatales. Además, debido a que esta lógica de orientación hacia resultados tiene pocos años en la administración pública federal, no es tan fácil cambiar la mentalidad de los funcionarios públicos acostumbrados a rendir informes de cumplimiento de actividades, hacia una que tenga nociones sobre medición, planeación
171 de 212

estratégica, generación de indicadores, selección de metas y movilización de los resultados a partir de ejercicios evaluativos.
Como segunda lección, los casos documentados permitieron evidenciar que en esta dimensión también influyó la heterogeneidad de capacidades en materia de evaluación en las entidades federativas: cuando un programa es coordinado a nivel central pero operado por las instancias estatales, la diferencia en la capacidad técnica entre el ámbito federal y los estados se vuelve un problema debido a la falta de un marco común de referencia que facilite un mismo lenguaje, una adecuada comprensión de los procesos de evaluación y una mentalidad de los funcionarios públicos orientada a resultados. Esta diferencia, provoca dificultades para la recolección de información de calidad, la construcción de indicadores confiables y para la retroalimentación de información que se produce a partir de los procesos cotidianos de operación, como lo demostraron los programas de Fortalecimiento a la Transversalidad de la Perspectiva de Género y el PAIMEF. Incluso, cuando un programa social se opera desde el ámbito central, como se presentó con los casos estudiados, las Unidades Responsables de los programas se enfrentan a que no todas las áreas internas de la dependencia que intervienen en la operación de éste cuentan con las capacidades y habilidades en materia de evaluación.
A partir de la evidencia recogida, se puede señalar que cuando existe capacidad en materia de evaluación dentro de la dependencia se provoca una cascada de ventajas para el programa, que no solamente se reflejan en la habilidad para traducir recomendaciones en acciones de mejora en la gestión diaria, sino también en mayor comprensión de la lógica causal detrás de las acciones públicas, y de forma subsecuente, se genera aprendizaje organizacional en una visión conjunta sobre el desempeño de los
172 de 212

programas. En este sentido, la construcción de capacidades en materia de evaluación es un proceso que incrementalmente se ha ido afinando con el tiempo: a partir de la experiencia documentada, los programas analizados se han convertido poco a poco en consumidores proactivos de la información derivada de las evaluaciones y cada vez más, los operadores de los programas saben qué pueden esperar de estos ejercicios, y cómo internalizar esta información para mejorar el diseño y la operación de sus programas.
Por otra parte, el tercer factor que influyó de forma consistente en la decisión de mejora de los programas estudiados fue la factibilidad de las recomendaciones, producto de la “construcción” de marcos de entendimiento común que se derivaron de procesos de comunicación constante entre el evaluador y el programa evaluado durante todo el ejercicio. Este espacio de diálogo que se generó dentro del proceso de evaluación, facilitó la discusión de los criterios y razones que influyeron en la presentación de ciertos hallazgos y recomendaciones sobre otras. A partir de este diálogo, los evaluadores profundizaron en el conocimiento sobre la operación del programa en campo más allá de la comprensión que pudiera tener a partir de los análisis de gabinete. Al mismo tiempo, los programas tuvieron la oportunidad de revisar sus planteamientos y encontrar soluciones a las necesidades que originaron los ejercicios de evaluación.
En este sentido, la factibilidad de las recomendaciones no es un atributo que se genera únicamente a partir de evaluadores que cuentan con conocimiento en el tema, ni de una visión estratégica de las acciones necesarias para lograr los avances; en realidad, es un proceso común de construcción que inicia con la receptividad y disposición de ambas partes para afinar, discutir y adaptar las propuestas de mejora, asumir el proceso de evaluación como un instrumento para mejorar metas, costos, focalización y mayor eficiencia. La sensibilidad del evaluador consistió en recabar información sobre la
173 de 212

operación real de los programas, y proponer de forma selectiva recomendaciones factibles que superaran las restricciones internas de la administración pública y que aterrizaran con mayor precisión como parte de esta lógica de cambios para la mejora. Caso contrario, cuando el operador de un programa percibía que sus necesidades no fueron atendidas por el evaluador, el ejercicio evaluativo se asumía como una imposición externa que disminuyó la voluntad del operador para apropiarse de las recomendaciones propuestas.
De manera general, procurar espacios de reflexión para analizar posibles soluciones a los problemas que enfrentan los programas públicos, permite incidir de forma positiva en la toma de decisiones que busca la mejora continua y genera un proceso colectivo de aprendizaje sobre las políticas públicas.
Por otra parte, como se explicó abundantemente en el capítulo anterior, cuando la decisión es de tipo presupuestaria se consideran más elementos políticos que técnicos, que van mucho más allá de las normas. La explicación a este comportamiento se presenta porque el proceso formal que cumple la aprobación final del presupuesto en la Cámara de Diputados, y de forma restringida en la Comisión de Presupuesto y Cuenta Pública, se convierte en el espacio donde múltiples fuerzas políticas se reúnen para incidir en la discusión y elaboración del dictamen presupuestario.
Aunque de manera formal, los actores que deciden la aprobación del Presupuesto de Egresos de la Federación son los diputados, en la negociación también se involucran los intereses del Presidente de la República a través de las prioridades de políticas establecidas en el Plan Nacional de Desarrollo; los intereses de los gobernadores que buscan tener mayor visibilidad política en sus estados, y aquellos intereses que promueven los cabilderos y otros actores para beneficiar a grupos políticos o clientelares.
174 de 212

La mayor participación legislativa que vemos hoy en día en la modificación del presupuesto es un reflejo de la pluralidad que se alcanzó en el Congreso a partir de 1997, sin embargo esta pluralidad no es garantía para que en la negociación se consideren criterios técnicos que le impriman mayor calidad al gasto ni tampoco, que se aplique un uso eficiente de los recursos federales que influyan en mejores programas públicos. Por sí misma esta pluralidad parlamentaria no creó los incentivos para que los diputados pudieran identificar áreas de mejora en el presupuesto y aplicaran más racionalidad en la negociación. Aunque la presente investigación se limitó a un caso de estudio de cinco programas, cuando uno revisa de forma global el decreto de presupuesto, se puede observar cómo los diputados deciden modificar, aunque sea marginalmente, el proyecto enviado por el Ejecutivo para crear y desaparecer programas con motivaciones pocos transparentes. Las entrevistas dieron mayor luz para aclarar que este tipo de programas sirve para generar mayor exposición política y local con el electorado, en lugar de servir como una pieza clave para el desarrollo social de nuestro país.
En este sentido, el modelo ajustado que se presenta en páginas anteriores pretende explicar la dinámica del proceso de toma de decisiones para los programas del sector social aquí documentado, no obstante es posible retomarlo como un punto de referencia para futuras investigaciones en otros sectores de política pública.
¿Cómo afecta la falta de incentivos en el sistema de evaluación? La falta de incentivos en el sistema de evaluación se explica sobre todo a partir del diseño institucional en el que éste se sostiene. Una explicación alrededor de este factor lo podemos observar con mayor énfasis en la dinámica que se genera al interior de la Cámara de Diputados, en particular en el contexto del PBR. El Presupuesto Basado en
175 de 212

Resultados descansa en las facultades de pesos y contrapesos que de manera formal tienen del poder Ejecutivo y el Legislativo, sin embargo el proceso real para aprobar el presupuesto en nuestro país no genera los incentivos adecuados para que el cuerpo legislativo implemente los objetivos que el PBR supone. Parte de este comportamiento se explica porque más de 90 por ciento del presupuesto sigue una lógica inercial, debido a las obligaciones del gobierno federal en materia pensiones y jubilaciones, aportaciones a la seguridad social, participaciones a las entidades federativas y municipios y adeudos de ejercicios fiscales anteriores, por mencionar algunas; y el restante 10 por ciento se convierte en una partida altamente política que responde a agendas de corto plazo, puesto que más actores buscan incidir en la aprobación de un “pedazo de pastel” mucho más pequeño.
Una segunda explicación de las consecuencias del actual diseño institucional es la falta de capacidad de los legisladores para utilizar de forma instrumental la gran diversidad de estudios y evaluaciones que existen en materia de política social. Aunque el Decreto del Presupuesto de Egresos de la Federación, la Ley General de Desarrollo y el Mecanismo para el Seguimiento de Aspectos Susceptibles de Mejora derivados de informes y evaluaciones a los programas presupuestarios de la Administración Pública Federal señalen que la información derivada del seguimiento a los compromisos de mejora y de las evaluaciones se tomará en cuenta para el proceso presupuestario, el problema es que el periodo de tres años que dura la carrera parlamentaria de un diputado no es suficiente para que supere la curva de aprendizaje sobre el análisis técnico que requiere el presupuesto federal. Además, a esto se suma la falta de apoyo de los cuerpos especializados con los que cuenta la Cámara de Diputados, como es el caso del Centro de Estudios de las Finanzas Públicas de la Cámara de Diputados (CEFP) que por
176 de 212

normatividad debería apoyar técnicamente la elaboración y aprobación tanto de la Ley de Ingresos, como del presupuesto, pero que en la práctica no lo lleva a cabo.
Asimismo, la oportunidad temporal con la que se entregan los resultados de las evaluaciones y del seguimiento a los compromisos de mejora presiona los plazos definidos del proceso presupuestario. De toda la información técnica que se produce en materia de política social, sólo los resultados de las Evaluaciones Específicas de Desempeño, de diseño y de los programas nuevos están disponibles para la fecha en que la Secretaría de Hacienda entrega el proyecto de presupuesto a la Cámara de Diputados. Sin embargo, existe una escasa capacidad de éstos para asimilar el gran volumen de información que les llega (no sólo de la política social) y, como se aprecia a partir de las entrevistas, la revisión de esta información se limita a los estilos políticos de cada legislador. Como efecto de esta dinámica política se crean incentivos perversos para que los legisladores resalten la información que más coincida con sus agendas políticas de corto plazo en lugar de incidir sobre el uso eficiente de los recursos destinados a las políticas públicas.
Finalmente, otro de los puntos relacionado con el diseño institucional es la influencia del Mecanismo de Seguimiento de ASM en el proceso presupuestario. El proceso señalado en el Mecanismo de Seguimiento de ASM aún presenta áreas de oportunidad para cumplir con el objetivo de fortalecer la integración del proyecto de Presupuesto de Egresos de la Federación. En particular, la forma en que el Mecanismo documenta los avances graduales de los programas para el cumplimiento de sus ASM no coincide con la lógica anual del ciclo presupuestario. No obstante, aunque la Secretaría de Hacienda ha buscado institucionalizar el uso de la información relativa a los ASM en el Modelo Sintético de Desempeño, aún no hay claridad del grado de influencia que esta
177 de 212

información tiene en la propuesta de presupuesto que se envía a la Cámara de Diputados. Aunado a esta falta de coincidencia temporal entre el proceso del Mecanismo y del presupuesto, están también tanto la falta de un cuerpo colegiado externo a las dependencias que cuente con la facultad de analizar de forma sistemática la calidad de los ASM y su proceso de seguimiento, como la ausencia de consecuencias ante el incumplimiento de las dependencias para darle seguimiento a sus ASM o registrar a tiempo sus avances. El diseño actual de como está pensado el Mecanismo de Seguimiento presenta zonas grises para que las dependencias de la Administración Pública Federal se involucren sistemáticamente en una dinámica de mejora continua y orientación hacia el logro de resultados.
A manera de resumen, mejorar la implementación de los cinco programas estudiados y asignarles su presupuesto no es proceso lineal. Como se mencionó en páginas anteriores, la implementación del PBR en México y en muchos otros países ha tenido sus limitaciones debido a que las decisiones sobre los recursos públicos no se alimentan únicamente de criterios técnicos de desempeño. Promover esta idea sería poco deseable (González, 2010). Sin embargo, no podemos negar que se ha gastado mucho dinero en materia de evaluación y se vuelve preocupante que la información generada por esta herramienta de gestión pública incida de forma muy marginal en el proceso deliberativo de los legisladores. Sería pretensioso sugerir que el documento más político de cualquier gobierno, el presupuesto, siguiera el modelo de formulación directa para asignar los recursos públicos como lo propone la OCDE, sin embargo la dinámica política del Congreso mexicano como hasta ahora ocurre, tiene grandes costos en la racionalidad presupuestal y en el desarrollo social de nuestro país.
178 de 212

Conclusiones El impulso de la política de evaluación en nuestro país se vio influenciada por dos factores: presiones de iniciativas internacionales orientadas a reformar administrativamente el sector público y el inicio de un nuevo gobierno en el ámbito federal. El impulso a la evaluación de programas sociales se convirtió en una ventana de oportunidad política que utilizó la nueva administración para legitimar sus acciones a partir de información técnica que retroalimentara la toma de decisiones en materia de política pública. Este propósito también se hizo coincidir con el impulso que se le dio a otras políticas como la rendición de cuentas, la transparencia y mayor control presupuestario. En el fondo, la implementación de estos cambios buscaba un viraje del enfoque tradicional de la administración pública basado en el monitoreo de insumos y productos, hacia uno orientado a generar resultados e información estratégica para la toma de decisiones que redujera la discrecionalidad de las mismas en el sector público. En este sentido, la política de evaluación se concibió como una herramienta instrumental que retroalimentaría las decisiones relevantes en materia de política pública y de presupuesto, a partir de información técnica sobre el desempeño de los programas públicos. Sin embargo, a unos años de su implementación aún quedan desafíos relevantes para transitar la ruta completa hacia la gestión por resultados.
Para fines de claridad y orden, a continuación se presenta un apartado de los hallazgos identificados a partir de los casos documentados, para posteriormente continuar con la sección de recomendaciones de políticas. Aunque como ya se mencionó en párrafos anteriores, esta investigación se enfocó en los programas dirigidos a la población vulnerables, el eje de análisis que se desarrolló a lo largo de este trabajo son los procesos de toma de decisiones en el sector público, en un entorno de restricciones
179 de 212

normativas, operativas, presupuestales y burocráticas. En este sentido, este trabajo construyó un modelo ideal basado en la teoría que incluyó los factores que deben considerarse al tomar decisiones de política pública, no obstante a partir de la evidencia derivada del análisis de los cinco programas seleccionados para este estudio, el primer modelo se ajustó a partir de los factores que más influyeron al tomador de decisiones. Se puede concluir que este último modelo es una representación evolucionada que describe el proceso de toma de decisiones en el sector público del contexto mexicano y en este sentido, es posible que los hallazgos del mismo se puedan tomar como referencia para explicar las dinámicas que se presentan en otros programas de tipo social e incluso, en otras arenas de política pública. Hallazgos
 La política de evaluación del gobierno federal ha provocado que los resultados de las evaluaciones se utilicen con fines instrumentales para las decisiones de mejora continua en los programas de tipo social pero para las decisiones de presupuesto su uso aún se limita a ser de tipo simbólico.
 En particular, las recomendaciones de las evaluaciones se usan para mejorar paulatinamente la operación de los programas. No obstante, alcanzar el uso instrumental de las evaluaciones debe incluir no sólo las decisiones que corrigen la operación y el desempeño de los programas públicos, también deberá considerar las decisiones de presupuesto, de lo contrario nos quedamos con un objetivo a medio camino que rompe con la cadena de las políticas basadas en evidencia. Hasta ahora, el sistema de evaluación en México solamente ha logrado que el uso instrumental afecte las decisiones de mejora continua de desempeño, sin embargo para las decisiones relacionadas con el presupuesto el uso se ha
180 de 212

limitado a fines simbólicos, sobre todo dentro de la Cámara de Diputados. El gasto que se ha realizado en la política de evaluación en el ámbito federal tiene más impacto en la mejora continua de los programas sociales y el aprendizaje organizacional que en la implementación del Presupuesto Basado en Resultados.  Los factores que explican el propósito de mejorar la política pública son el liderazgo y compromiso del operador del programa; su capacidad organizacional y operativa, sobre todo técnica, y la factibilidad de las recomendaciones hechas por el evaluador. Estos elementos tuvieron gran influencia para producir cambios en la implementación de los programas. Por otra parte, cuando las decisiones se orientan a definir y asignar el presupuesto de cada ejercicio fiscal, el factor que aún sigue dominando esta esfera es de tipo político. En particular, las prioridades del Poder Ejecutivo y los intereses partidistas en la Cámara de Diputados fueron las causas que mejor explicaron la dinámica para distribuir el gasto público. Además, los mecanismos hasta ahora presentes en el diseño institucional del sistema de evaluación para la etapa de negociación presupuestal, provocan que la demanda de información y criterios técnicos se diluyan en la discusión esencialmente política que se lleva a cabo durante la deliberación parlamentaria. En este sentido, el sistema de evaluación en el ámbito federal del contexto mexicano requiere mejorar el diseño de los mecanismos e incentivos para vincular la utilización de las evaluaciones con las decisiones del proceso presupuestal.  Con la información disponible sobre los cambios que se realizaron en la corrección operativa de los programas dirigidos a grupos vulnerables no es posible identificar de manera categórica el impacto neto de los programas en la
181 de 212

política pública del gobierno federal, pero si es posible distinguir efectos positivos que de forma concreta afectaron la corrección de los bienes y servicios, indicadores y procesos de los programas, así como la reorientación de sus propósitos. Sin embargo, no se puede señalar de forma clara que el presupuesto de estas intervenciones haya sido un reflejo del proceso de mejora, la atención de los diputados sobre estas intervenciones respondió a las presiones tanto del Gobierno Federal como de los intereses de los principales grupos parlamentarios. El proceso de toma de decisiones al interior de la Cámara de Diputados aún carece de la utilización sistemática de elementos técnicos que alimenten la negociación del presupuesto. Hasta ahora, el uso que se les da a las evaluaciones en este ámbito político es para justificar decisiones previamente consideradas o reorientar el gasto entre programas.  En materia de evaluación, la política social ha sido por muchos años el sector que más ejercicios de medición y evaluación ha realizado. Por esta misma razón los mecanismos innovadores que se crearon para hacer políticas basadas en evidencia se pueden identificar de forma más clara en este sector. Las experiencias obtenidas dan cuenta de las oportunidades para aprovechar la información derivada de las evaluaciones en las políticas públicas de otros sectores.
Recomendaciones Como en toda política pública, los cambios graduales de la evaluación en el ámbito federal se han guiado por una lógica incremental. Mediante ejercicios de prueba y error la política de evaluación en México ha mejorado paulatinamente en el sector social. En
182 de 212

menos de una década se creó el marco normativo y el andamiaje institucional de la política federal de evaluación que buscó tener consecuencias directas en las políticas públicas, sin embargo hay áreas de mejora que aún faltan por implementar para lograr el objetivo de convertir a las evaluaciones en una verdadera herramienta instrumental. A continuación describiré algunas recomendaciones:
 Incluir a otros sectores de la política pública en la lógica de la orientación a resultados. En el 2012, 68.7 por ciento del gasto programable estaba orientado a resultados. Esto quiere decir que el proceso para identificar, ordenar y sistematizar información que puede ser medible ha tenido efectos en más de la mitad de los programas públicos en nuestro país. Sin embargo, es necesario que en los próximos diez años se amplíe el porcentaje de programas evaluados a otros sectores de políticas. Aunque las lecciones de política social se puedan considerar en otras áreas de políticas, cada una enfrenta necesidades distintas que deben ser identificadas. Hasta ahora los avances en otros ámbitos como la seguridad pública, política exterior e infraestructura por mencionar algunos, son todavía incipientes y se requiere acumular experiencia en estas otras intervenciones.
 Reforzar los mecanismos que promueven el uso instrumental de las evaluaciones. El marco normativo del sistema de evaluación obliga a los actores involucrados directamente en el terreno de la operación de las intervenciones sociales a usar sistemáticamente las evaluaciones para identificar áreas de oportunidad que permitan mejorar su implementación. En este sentido, el trabajo más acabado es el Mecanismo de Seguimiento, el cual ha permitido monitorear los avances que hacen los programas y tener un panorama sobre los cambios que ha tenido la política social en los últimos años. No obstante, este mecanismo aún tiene áreas
183 de 212

de mejora, de lo contrario el proceso de mejora de las políticas públicas corre el riesgo de convertirse en un proceso burocrático sin incentivos positivos o negativos. En particular, se necesita dotar a este Mecanismo de incentivos que involucren consecuencias claras y sistemáticas ante la falta de cumplimiento por parte de las dependencias. El informe anual que publica el CONEVAL puede servir como un espacio para hacer público (naming and shaming) el cumplimiento de los ASM por parte de las dependencias, no solo aquellas que operan programas sociales. En este sentido, es importante capacitar a los funcionarios públicos para que puedan aprovechar los ASM para mejorar resultados. Para reforzar esta tarea, también conviene crear cuerpos colegiados externos a las dependencias que monitoreen la calidad de los compromisos adquiridos por los programas. De lo contrario, seguirán existiendo desigualdades en el grado de compromiso y utilización de las recomendaciones derivadas de las evaluaciones. En este mismo sentido, se debe reforzar el Modelo Sintético de Desempeño. Para alcanzar esta meta primero se debe transparentar el cálculo que se considera entre las variables que lo componen y en segundo lugar, se necesita normar la relación entre la Secretaría de Hacienda, el CONEVAL y la Cámara de Diputados para que el uso de esta información se convierta en una herramienta sistemática al momento de la negociación presupuestal.  Ajustar los calendarios de los procesos que producen información técnica de desempeño con el proceso presupuestal. En otras palabras, se requiere hacer coincidir las fechas del Programa Anual de Evaluación y del Mecanismo de Seguimiento con el proceso presupuestal para reducir la discrecionalidad de la toma de decisiones en el sector público. Ajustar estar fechas comprometería a los
184 de 212

actores involucrados en la negociación del presupuesto a considerar información técnica de desempeño. De lo contrario, se corre el riesgo de que el gasto en evaluaciones siga cumpliendo la mitad de sus objetivos.  Ampliar el universo de actores para que se apropien del “nuevo lenguaje” del sector público. El reto es capacitar colectiva e individualmente a más funcionarios públicos fuera de las áreas de evaluación de las dependencias, y promover en lenguaje ciudadano el uso de esta información. Por ejemplo en el ámbito del gobierno, que los Órganos Internos de Control de las dependencias se sensibilicen en la cultura de rendición de cuentas y cumplimiento de resultados, más que en el cumplimiento de procedimientos o normas. Esta capacitación también involucra la profesionalización del equipo técnico en las Comisiones Ordinarias de la Cámara de Diputados y sobre todo, se requiere fortalecer la capacidad del Centro de Estudios de las Finanzas Públicas en la práctica a fin de ampliar la capacidad del Congreso en el procesamiento del volumen de información que se derivan de las evaluaciones. En este mismo sentido, se requiere fortalecer las capacidades de las entidades federativas tanto en materia normativa como en la práctica del monitoreo y la evaluación a fin de que exista un piso mínimo que permita medir los programas sociales e identificar la productividad de las intervenciones. Asimismo, se requiere de mecanismos que comuniquen en lenguaje ciudadano no solamente información sobre el desempeño de la política pública, también de cómo estos resultados impactan en acciones concretas en la vida común de los beneficiarios de los programas sociales.  Mejorar el diseño en la parte presupuestal mediante incentivos. En particular, a través de la creación de mecanismos institucionales que vinculen de forma real el
185 de 212

proceso de evaluación y el del presupuesto. Sobre todo, que la Cámara de Diputados utilice de forma instrumental los resultados de evaluaciones y los informes de desempeño. De lo contrario, la consulta y revisión de los resultados de los programas sociales seguirá dependiendo de estilos personales que aparecen coyunturalmente en el cuerpo legislativo. Para corregir esta deficiencia se requiere que los mecanismos se institucionalicen de manera formal en las decisiones presupuestales de la Cámara de Diputados. Aunque sabemos que la asignación del presupuesto no es el resultado lineal del resultado de una evaluación, lo que se busca es crear incentivos para que el cuerpo parlamentario incluya criterios técnicos en el proceso deliberativo y se disminuyan los criterios discrecionales cuando se negocia el gasto público. Por ejemplo, una forma de hacerlo es abrir a consulta técnica los sistemas de información que actualmente existen para alimentar el sistema de evaluación (un ejemplo de esto es el Modelo Sintético de Desempeño), a fin de que tanto las tres instancias coordinadoras del sistema (Hacienda, Función Pública y CONEVAL), como las comisiones ordinarias de la Cámara de Diputados tengan acceso a los resultados de los indicadores y las evaluaciones. Otra forma de promover el uso instrumental de las evaluaciones en las decisiones presupuestales es crear un índice que capte diferencias porcentuales en el presupuesto dependiendo del tipo de mejora que realizaron los programas. Por ejemplo, las decisiones relacionadas a corregir actividades; modificar apoyos; reorientar sustancialmente el programa y fusionar o suspender el programa tendrían diferentes ponderaciones según su peso en la coherencia e impacto de la política social. El valor del índice también dependería de la participación de los cuerpos colegiados externos al programa para avalar la
186 de 212

calidad de los cambios adoptados. Este mecanismo puede generar una cascada de incentivos positivos tanto para las dependencias, como para los actores que toman decisiones estratégicas fuera de éstas. Se trata de generar elementos que permitan transitar al Congreso a una cultura de la transparencia y de resultados.  Articular el sistema de evaluación con otras políticas y entre las instancias que lo coordinan. Por una parte, para lograr que la información de las evaluaciones alcance un radar más amplio que permita incrementar la racionalidad instrumental en la toma de decisiones del sector público, es indispensable que se integre con otras políticas del gobierno federal que buscan la rendición de cuentas. Si el sistema de evaluación no se vincula con otras políticas como la de contabilidad gubernamental y control presupuestario, calidad del gasto público y la transparencia, se corre el riesgo de que la información técnica de desempeño sólo alcance un nivel meso (programas públicos) que no aporte la evidencia completa que requiere la gobernanza democrática y la rendición de cuentas. Por otra parte, este riesgo también se corre entre las instancias que coordinan la política de evaluación federal debido a la multiplicidad de señales que cada una envía. En este sentido, las Secretaría de Hacienda, de la Función Pública y el CONEVAL deberán delimitar los ámbitos de competencia que tendrá cada uno para evaluar, coordinar los resultados de los distintos propósitos que cada uno asumió, y definir los alcances de la política de evaluación en el orden federal tanto horizontal como verticalmente hasta su impacto final. La fragmentación que mantienen hasta ahora provoca que exista diferencias de información entre los distintos sectores de las políticas públicas. Se trata de un desafío que de no atenderse afectará la utilización de las evaluaciones
187 de 212

y en niveles más amplios y terminará por ser un obstáculo para que el sistema de evaluación sirva para mejorar efectivamente el desempeño del gobierno.
Sin duda, la agenda de evaluación en el ámbito nacional e internacional ocupará un espacio muy importante en el quehacer del gobierno y en las reformas de la administración pública en los próximos años. Sin embargo, aún estamos a medio camino, los esfuerzos y recursos gastados en los últimos años en la política de evaluación deberá permitirnos identificar los beneficios reales que estas estrategias han tenido en las condiciones de vida de la ciudadanía, hasta ahora muy borrosos. La utilización de las evaluaciones es una pieza clave en la política federal de evaluación, sin embargo es un proceso aún incompleto para generar una orientación a resultados. Aunque hoy contamos con dependencias que coordinan la política de evaluación, un andamiaje institucional y marco normativo que han promovido prácticas para traducir los resultados de las evaluaciones en una mejora sustantiva de los programas públicos, aún es necesario un elemento fundamental para esta apuesta: la voluntad de cambio de los actores políticos dispuestos a aprovechar potencialmente la información derivada de las evaluaciones como una práctica cotidiana en la discusión presupuestaria. La apuesta por generar consensos en torno a la confianza en las instituciones y en la legitimidad sobre la capacidad para gobernar de nuestros políticos se refleja de forma clara en la calidad del gasto público. Para esto se requiere que en la negociación presupuestal se recojan las necesidades de la población mediante un uso inteligente de criterios de productividad de los recursos públicos.
188 de 212

189 de 212

Anexo 1.

Avance porcentual de las acciones para la atención de los ASM del Programa de Atención a Jornaleros Agrícolas,

periodo 2008-2012

Aspectos Susceptibles de Mejora comprometidos

Clasificación de ASM

Fecha de término

Porcentaje de avance

Realizar un documento de Planeación 1 Estratégica, que incluya metas de mediano y
largo plazo.

Institucional

30 de Agosto 2008

100

Expresar claramente el diseño del programa en

2

las Reglas de Operación y la Matriz de Indicadores dando mayor claridad y

Institucional

30 de Septiembre 2008

100

congruencia a sus diversos elementos

Especificar indicadores de resultados en 3 relación a la población objetivo en la matriz de
indicadores

Institucional

30 de Septiembre 2008

100

Definir claramente la población potencial y

4

objetivo de acuerdo con el problema que el programa pretende resolver y a las restricciones

Institucional

31 de Octubre 2008

100

institucional es

Revisar la estructura y actividades de

5 operación del programa buscando mejorar la eficiencia operativa

Específico

31 de Diciembre 2008

100

Revisar los tipos de apoyo que otorga el

6

programa considerando la posibilidad de concentrar esfuerzos en aquellos que tienen

Institucional

31 de Diciembre 2008

100

mayor impacto en la población.

7

Definir metas viables para los indicadores, en función de la población que se desea atender

Institucional

31 de Marzo 2009

100

Contar con una agenda de evaluación de

resultados de los programas sociales, 8 privilegiando las evaluaciones de impacto y de
seguimiento a beneficiarios, previo análisis de

Institucional

17 de Septiembre 2009

100

factibilidad

Actualizar y difundir los diagnósticos de los

problemas que atienden los programas sociales,

documentando la medición de la población

9

potencial y objetico para su incorporación en las estrategias de cobertura, cambios en el

Institucional

1 de Junio 2010

100

diseño y definición de estrategias óptimas de

atención.

Realizar una evaluación de satisfacción de la

10 población atendida

Institucional

30 de Junio 2010

100

11 Cuantificar la población potencial y objetivo

Institucional

31 de Diciembre 2010

100

Mejorar la información de los beneficiarios

12

tanto en los padrones como en las bases de datos del programa, para conocer con claridad

Institucional

31 de Diciembre 2010

100

qué tipo de apoyos fue beneficiado cada uno.

Establecer metas retadoras y factibles de 13 alcanzar para todos los indicadores de la Matriz
de Indicadores para Resultados 2011 y 2012

Específico

31 de Marzo de 2012

80

Continuar con el proceso de mejora de las

Matrices de Indicadores para Resultados (MIR),

31 de Diciembre

14 documentando la solidez técnica de los

Institucional

2012

100

indicadores, su relevancia, el establecimiento

de líneas de base y metas.

Avance porcentual de las acciones para la atención de los ASM del Programa de 70 y más, periodo 2008-2012

190 de 212

Aspectos Susceptibles de Mejora

comprometidos

Deberá analizarse la conveniencia de fusionar

en un solo programa los tres instrumentos de

1 política de SEDESOL que actualmente

entregan un apoyo en efectivo a los adultos

mayores.

Mejorar el diagnóstico del programa a fin de

2 que establezca con claridad el problema que

el programa debiera contribuir a resolver.

Establecer claramente el diseño del programa

en las Reglas de Operación y la Matriz de

3

indicadores, vinculando el diseño con el problema que el programa contribuye a

resolver a través de objetivos claros y

alineados

Contar con una agenda de evaluación de

resultados de los programas sociales,

privilegiando las evaluaciones de impacto y 4 de seguimiento a beneficiarios, previo

análisis de factibilidad.

Clasificación de ASM
Institucional Institucional
Institucional
Institucional

Fecha de término

Porcentaje de avance

30 de Abril 2008

100

31 de Julio 2008

100

30 de Septiembre

2008

100

17 de Septiembre

100

2009

Actualizar y difundir los diagnósticos de los

problemas que atienden los programas

sociales, documentando la medición de la 5 población potencial y objetivo para su

Institucional

1 de Junio 2010

100

incorporación en las estrategias de cobertura,

cambios en el diseño y definición de

estrategias óptimas de atención

Mejorar las condiciones de atención en las

31 de Diciembre

6 sedes de pago

Específico

2010

100

Fortalecer la capacitación y el seguimiento a 7 los Gestores Voluntarios.

Específico

31 de Diciembre

2010

100

Establecer metas retadoras y factibles de

8

alcanzar para todos los indicadores de la Matriz de Indicadores para Resultados 2011 y

Específico

31 de Marzo 2012

80

2012

Continuar con el proceso de mejora de las

Matrices de Indicadores para Resultados

31 de Diciembre

9 (MIR), documentando la solidez técnica de los

Institucional

2012

100

indicadores, su relevancia, el establecimiento

de líneas de base y metas.

Mejorar las condiciones de entrega de apoyos

31 de Diciembre

10 económicos

Específico

2012

80

Fortalecer la supervisión de las condiciones de

31 de Diciembre

11 atención en las sedes de pago.

Específico

2012

80

Reforzar el conocimiento de los mecanismos

31 de Diciembre

12 de presentación de quejas y denuncias.

Específico

2012

80

191 de 212

Avance porcentual de las acciones para la atención de los ASM del Programa PAIMEF, periodo 2008-2012

Aspecto Susceptible de Mejora comprometido Clasificación de

Fecha de

ASM

término

Se incorporará un proceso de mesas de

1 dictaminación a los proyectos presentados por

Institucional Diciembre 2008

las instancias estatales de las mujeres

Se incorporará en Reglas de Operación del

PAIMEF, en el formato de informe final, un

2

apartado para la identificación de instituciones, organizaciones de la sociedad civil o áreas

Institucional

Diciembre 2008

administrativas con las que se promovió la

coordinación en la realización del proyecto

3 Elaboración del Diagnóstico

Institucional 1 de Junio 2010

Asegurar la calidad y un mayor impacto de las

31 de Agosto

4 acciones que se realizan en los estados con

Específico

2010

recursos del PAIMEF

Establecer criterios mínimos para la selección

31 de Octubre

5 de las organizaciones que reciben recursos del

Específico

2010

PAIMEF

Trabajar en conjunto con las áreas de

31 de Octubre

6

comunicación al interior del INDESOL para contar con una estrategia institucional propia

Específico

2010

de difusión nacional

Incluir en la planeación de las IMEF la definición

31 de Octubre

7 de objetivos a largo plazo

Específico

2010

Porcentaje de avance 100
100
100 100 100
100
100

Ofrecer un marco de trabajo estable dentro del

2 de Diciembre

8 cual ocurran las mejorías anuales a las Reglas

Específico

2010

100

de Operación

Revisar y gestionar la aprobación y publicación

10 de Diciembre

9 del Manual de Procedimientos del PAIMEF

Específico

2010

100

Elaboración del documento de identificación de

31 de Diciembre

10 posibles interaccione s PAIMEF con otros

Institucional

2010

100

programas del gobierno Federal.

11 Mejorar el mecanismo de las mesas de revisión

Específico

31 de Diciembre 2010

100

Evaluar la pertinencia de modificar la fórmula

de asignación de los recursos, así como definir y 12 establecer criterios claros para la reasignación
de recursos y para la ampliación presupuestal a

Específico

31 de Diciembre 2010

50

los proyectos apoyados

Agenda de evaluación de resultados de los

13

programas sociales privilegiando las evaluaciones de impacto y de seguimiento a

Institucional

31 de Diciembre 2010

100

beneficiario s previo análisis de factibilidad

Conciliar los dos objetivos del PAIMEF: resolver

14

el problema de las capacidades institucionales de las IMEF y resolver el problema de la

Específico

31 de Diciembre 2010

100

violencia contra las mujeres

15

Contar con información desagregada a nivel municipal

Específico

31 de Diciembre 2010

100

Contar con un documento de planeación 16 estratégica

Institucional 8 de Enero 2011

70

Contar con estimaciones lo más actualizadas

2 de Febrero

17 posibles de la población potencial y la población Institucional

2011

100

objetivo del programa.

Incentivar la continuidad presupuestal para

31 de Marzo

18 brindar servicios y realizar actividades que son

Específico

2011

100

necesarias todo el año

19 Implementar acciones para el fomento

Específico

31 de Octubre

100

192 de 212

estratégico y

2011

Desarrollo organizacional de las IMEF con la

finalidad de fortalecer sus capacidades para el

logro de sus objetivos en materia de atención y

prevención de la violencia contra las mujeres.

Elaborar un documento marco que guíe las

acciones relativas al monitoreo y seguimiento

20

físico de los proyectos que implementan las Instancias de Mujeres en las Entidades

Específico

31 de Enero 2012

40

Federativas (IMEF) con recursos del

PAIMEF

Contribuir a garantizar la continuidad de los

proyectos de las IMEF durante los cambios de

21

administración a través de la implementación de un mecanismo para la entrega recepción de

Específico

31 de Enero 2012

40

los compromisos institucionales adquiridos en

el marco del PAIMEF

193 de 212

Avance porcentual de las acciones para la atención de los ASM del Programa Coinversión Social, periodo 2008-2012

Aspecto Susceptible de Mejora comprometido

La población objetivo de la Matriz de

1 Indicadores debe corresponder a la enunciada

en las Reglas de Operación.

Alineación de Fin y Propósito de la Matriz de

2 Indicadores para Resultados con las Reglas de

Operación vigentes.

Difundir al interior del Indesol y las

3 Delegaciones de la SEDESOL los resultados de

las evaluaciones externas del PCS.

4

Elaborar un Plan estratégico de corto, mediano y largo plazo

5

Elaboración de un diagnóstico actualizado del Programa.

6

Difundir los resultados relativos a la percepción de la población objetivo

Se apoyará la evaluación de los proyectos

apoyados por el PCS a través de la participación

7

transversal de otras Organizaciones de la Sociedad Civil o Instituciones Académicas en el

proceso de seguimiento de los mismos en cada

convocatoria

Actualizar y difundir los diagnósticos de los

problemas que atienden los programas sociales,

documentando la medición de la población

8 potencial y objetivo para su incorporación en

las estrategias de cobertura, cambios en el

diseño y definición de estrategias óptimas de

atención.

Definir la agenda anual de estudios y

evaluaciones 2011, con base en el PAE, las

9 iniciativas de los programas sociales y las

prioridades de la Secretaría y presentar la

agenda de evaluación al CONEVAL

1.- Realizar una evaluación operativa, técnica y

de funcionalidad del Formato de Presentación

de Proyectos, incluyendo de ser posible un

10 análisis comparativo con otros Fondos, a fin de

elaborar acciones de mejora. 2. Aplicar los

criterios de mejora acordados para simplificar

de manera significativa el formato.

Realizar una consulta a las Delegaciones de

11 SEDESOL sobre el funcionamiento de las Reglas

de Operación (ROP) 2010 y las ROP 2011.

Revisar y actualizar a fin de garantizar que el

12

PCS cuente con un mecanismo que garantice un trabajo permanente de planeación que incluya

los procedimientos, responsables y plazos.

Elaborar un mecanismo de apoyo para el

proceso de validación en las Delegaciones:

1. Definir los puntos de verificación, para

facilitar y eficientar el proceso de

13

validación en Delegaciones 2. Brindar asesoría y capacitación en las Delegaciones

para la correcta aplicación de los puntos de

verificación de los requisitos de validación,

3. Turnar al Área Jurídica de Indesol

solamente los casos críticos.

Clasificación de ASM Específico Específico Específico
Institucional Institucional Específico Específico
Institucional
Institucional
Específico
Específico Específico
Específico

Fecha de término 31 de Diciembre
2008 31 de Diciembre
2008 27 de Febrero 2009
30 de Junio 2009 30 de Junio 2009 30 de Marzo 2010
1 de Abril 2010
30 de Julio 2010
31 de Diciembre 2010
Diciembre 2010
Diciembre 2010 Diciembre 2010
1 de Enero 2011

Porcentaje de avance 100 100 100 100 100 100 100
100
100
100
100 100
100

194 de 212

Realizar un mecanismo de consulta que permita

realizar una evaluación operativa, técnica y de

funcionalidad del Formato de dictaminación de

14 Proyectos, a fin de elaborar acciones de mejora. Específico

Febrero 2011

100

2. Aplicar los criterios de mejora derivados del

mecanismo de consulta, para simplificar el

formato.

Publicar en la página web del Indesol las Reglas

15

Operación del Programa, así como los resultados de la recepción, validación,

Específico

1 de Abril 2011

100

dictaminación y evaluación de proyectos.

16

Diseño y Piloteo de Indicadores de Capital Social y de Fortalecimiento

Específico

1 de Abril 2011

100

1. Promover la convocatoria de

Acompañamiento y Monitoreo (AM) y la de

Profesionalización y Fortalecimiento (PF) 2. 17 Reuniones regionales con Actores Sociales. 3.

Específico

1 de Mayo 2011

100

Grupos de Acompañamiento entre pares (Un

Agente Responsable de la Ejecución de

Proyectos que visita a otro similar)

1. Establecer una coordinación con la Comisión

Nacional para eI Desarrollo de los Pueblos

18

Indígenas (CDI) para definir una mecánica que permita difundir algunas convocatoria de

Específico

1 de Mayo 2011

100

Indesol orientadas a temáticas de interés para

pueblos indígenas

1. Evaluación Cualitativa, mediante mesas de

evaluación con evaluadores externos. 2.

Retroalimentación a los AREP (Semáforos

19

cualitativos publicados en la WEB). 3. Reuniones regionales con OSC. 4.

Específico

Mayo 2011

100

Acompañamiento de Pares en el seguimiento

en campo. 5. Promover la sistematización de

experiencias de los AREP

Elaborar un mecanismo que establezca

20 estándares de atención y calidad dentro del

Específico

Junio 2011

100

proceso de dictaminación.

Definir una convocatoria apoyada a nivel

21

central como proyecto piloto, para probar la descentralización del proceso de dictaminación

Específico

1 de julio 2011

100

operado por las Delegaciones

22

Creación del nuevo Sistema de Gestión de Proyectos del Programa de Coinversión Social.

Específico

Septiembre 2011

10

23 Crear Comités de Contraloría Social del PCS.

Específico

Septiembre 2011

80

1. Revisar el mecanismo de los procesos

simultáneos. 2. Elaborar un mecanismo, como

24

plan piloto, para dictaminación es a distancia. 3. Realizar una revisión de todas las fases que

Específico

Noviembre de 2011

100

conforman el proceso del PCS, a fin de evaluar

actividades y tiempos.

Definir los conceptos de fortalecimiento

25

institucional y capital social y vincularlos al proceso operativo

Específico

31 de Diciembre 2011

100

del Programa

Promover centros de acompañamiento y

monitoreo de actores sociales, para contribuir a

los siguientes puntos: 1. Identificar a nivel

regional OSC que requieran acompañamiento 26 para su fortalecimiento institucional. 2.

Específico

Diciembre 2011

100

Impulsar la difusión de las convocatorias. 3.

Promover la vinculación y articulación regional

entre las organizaciones. 4. Capacitar a las

Organizaciones en materia de elaboración de

195 de 212

proyectos y otras necesidades de

fortalecimiento basado en diagnósticos locales.

5. Identificar Instituciones de Educación

Superior que puedan colaborar en esa tarea. 6.

Evaluar los talleres de capacitación a OSC,

impartidos a nivel local.

Sistematizar la información de los procesos de

27 seguimiento y evaluación de los proyectos para

Específico

31 de Mayo 2012

80

generar aprendizajes para el PCS y las OSC

Recuperar y sistematizar las experiencias y

28 proyectos

Específico

31 de Mayo 2012

30

exitosos

Revisar de los formatos de presentación de

proyectos, a fin de contar con mecanismos que

29 permitan a los Actores Sociales identificar su

Específico

30 de Agosto 2012

0

objetivo, población, bienes y servicios e

incidencia.

Reforzar el mecanismo para contar con una

relación de

Personas atendidas, debe ser reforzado a fin de que los AREP’s112 y el propio PCS cuenten con

30 una base de datos que

Específico

31 de Julio 2012

0

permita conocer la situación de los beneficiarios

de

los proyectos de los AREP’s sin que se ponga en

riesgo la confidencialidad requerida

31

Diseñar una estrategia de cobertura del Programa.

Institucional

30 de Junio 2012

95

1. Elaboración de una cédula con las variables

que inciden en el fortalecimiento y en el capital 32 social de los AREP’s.
2. Medición de los resultados, con la finalidad

Específico

Agosto 2012

60 20

de contar con un diagnóstico de los AREP’s

Contar con un informe detallado del

funcionamiento del sistema informático, el cual

33 incluirá un diagnóstico de la situación actual la

Específico

Diciembre 2012

100

identificación de las áreas de oportunidad, para

la administración del sistema informático

Explorar mecanismos adicionales, que le 34 permitan
promover la vinculación entre AREP’s

Específico

31 de Diciembre 2012

20

Definir capital social y actores sociales 35 fortalecidos y elaborar una propuesta de
operacionalización de estas definiciones.

Específico

31 de Diciembre 2012

40

112 Agentes Responsables de la Ejecución de los Proyectos. 196 de 212

Avance porcentual de las acciones para la atención de los ASM del Programa

Fortalecimiento a la Transversalidad de la Perspectiva de Género, periodo 20082012113

Aspecto Susceptible de Mejora comprometido

Clasificación de

Fecha de Porcentaje de

ASM

término

avance

Priorizar, entre los diversos aspectos que

1

contribuyen a la existencia y reproducción de la desigualdad entre mujeres y hombres, el problema

S/I

Diciembre 2010

100

central en el que se propone incidir.

Que el Programa cuente con un plan a corto y

2 mediano plazo que permita tener un diagnóstico

S/I

integral de la problemática.

Diciembre 2010

100

Cambiar la redacción del Propósito como a

3

continuación se sugiere: Políticas Públicas en las Entidades Federativas con perspectiva de género

S/I

Diciembre 2010

100

incorporada.

Se recomienda revisar la Matriz de Indicadores, y

4 reestructurar los niveles correspondientes a

S/I

Componentes y Actividades.

Diciembre 2010

100

Se recomienda revisar la Matriz de Indicadores, y de

5 ser necesario redefinir el objetivo correspondiente al nivel de Propósito.

S/I

Diciembre 2010

100

Una vez reformulados el Propósito y los

6 componentes, será necesario adecuar los

S/I

indicadores.

Diciembre 2010

100

Precisar en las fichas técnicas los medios de

7 verificación y la forma de acceder a las fuentes de información necesarias para reproducir el indicador.

S/I

Diciembre 2010

100

Se recomienda internalizar los riesgos de los

supuestos que implican para el éxito del Programa,

8 estableciendo procedimientos de apoyo,

S/I

acompañamiento e información del Programa a las

Diciembre 2010

100

IMEF.

9

Registrar y mantener actualizada la información sobre los proyectos apoyados a las IMEF, así como los resultados de los mismos.

Intergubernamen tal*

S/I

S/I

Se recomienda establecer una estrecha coordinación

con el PAIMEF, con el propósito de establecer

10

sinergias para la atención de la problemática de la violencia contra las mujeres en las EF buscando

Interinstitucional*

S/I

S/I

potenciar el cumplimiento de objetivos y lograr,

resultando complementarios.

Nota: S/I (Sin información) Documento de opinión elaborado en el marco del Mecanismo para el seguimiento a los

aspectos susceptibles de mejora derivados de informes y evaluaciones a los programas presupuestarios de la APF

(ASM), 2011.

113Como ya se mencionó, este programa comenzó a operar en el año 2010 y a partir de 2011 implementó el Mecanismo para el Seguimiento de Aspectos Susceptibles de Mejora. Derivado de la Evaluación de Diseño 2010, el programa se comprometió con ocho Aspectos Susceptibles de Mejora, modificaciones que incorporó en las Reglas de Operación y Matriz de Indicadores 2011. Cabe señalar que el programa señala en el Documento de opinión elaborado en el marco del Mecanismo para el seguimiento a los aspectos susceptibles de mejora derivados de informes y evaluaciones a los programas presupuestarios de la APF (ASM), 2011 que sólo falta por solventar dos ASM relativos a: registrar y mantener actualizada la información sobre los proyectos apoyados a las IMEF, así como los resultados de los mismos; y establecer una estrecha coordinación con el PAIMEF; sin embargo, el Informe de la Secretaría de Hacienda sobre la Situación Económica, las Finanzas Públicas y la Deuda Pública (segundo semestre de 2012) señala que el programa aún “carece de un diagnóstico que defina claramente sus características y que además le permita definir con mayor precisión sus poblaciones objetivo, potencial y atendida”, aunque el programa ya lo dio por solventado.

197 de 212

Anexo 2. Actores entrevistados para la elaboración de esta investigación
a) Mtro. Ernesto Cordero Arroyo.
Secretario de Hacienda y Crédito Público (2009-2012).
b) Mtra. Ana María León Miravalles.
Extitular del Instituto Nacional de Desarrollo Social.
c) Lic. Benjamín Hill Mayoral.
Extitular de la Unidad de Evaluación del Desempeño, SHCP (2010-2012).
d) Mtro. Agustín Caso Raphael.
Director General Adjunto de la Unidad de Evaluación del Desempeño, SCHP (2010-a la fecha).
e) Mtra. Thania de la Garza Navarrete.
Directora General de Adjunta de Evaluación del Consejo Nacional de Evaluación para la Política de Desarrollo Social (2006-a la fecha).
f) Mtro. Gerardo Franco Parrillat Marroquín
Ex titular de la Unidad de Planeación y Relaciones Internacionales de la Secretaría de Desarrollo Social
g) Dra. Claudia Mir Cervantes
Evaluadora externa, Cocoa services
h) Lic. Rogelio Omar Grados Zamudio
Director General Adjunto de Enlace para Evaluaciones Externas del Programa Oportunidades
i) Lic. Cecilia Reyes Montes
Subdirectora de Estudios del Presupuesto y Gasto Público, Centro de Estudios de las Finanzas Públicas
j) Mtra. Mónica Orozco Corona
Exdirectora de Evaluación del Instituto Nacional de las Mujeres
k) Mtra. Carmen Echeverría
Ex Coordinadora nacional del Programa de Apoyo a las instancias de mujeres en las entidades federativas para implementar y ejecutar programas de prevención de la violencia contra las mujeres
l) Lic. Carlos Augusto Morales López
Diputado de la Comisión de Presupuesto y Cuenta Pública de la LXII Legislatura
m) Ex integrante del equipo técnico en la Comisión de Desarrollo Social de la LXI Legislatura
n) Ex integrante del equipo técnico de la Comisión de Grupos Vulnerables en la LXI Legislatura
198 de 212

Anexo 3. Modelo de cuestionario aplicado en las entrevistas.
1. Desde su ámbito de competencias, ¿cómo definiría el concepto buen desempeño de un programa?
2. ¿Qué usos se le da a la información derivada de las evaluaciones?
3. ¿Las evaluaciones han incidido para que el programa cambie, en qué sentido han sido esos cambios?
4. ¿Qué tipo de decisiones se tomaron a partir de los resultados de las evaluaciones respecto a acciones de mejora o asignación de presupuesto?
5. ¿Qué porcentaje de las recomendaciones se convierten en Aspectos Susceptibles de Mejora y cuál es la naturaleza de los programas que sí se adoptan?
6. ¿Qué otros factores explican cambios en los programas?
7. ¿Existen factores de tipo organizativo que influyeron para tomar en consideración las recomendaciones derivadas de las evaluaciones?
8. ¿Existen factores de diseño institucional que influyeron para tomar en consideración las recomendaciones derivadas de las evaluaciones?
9. ¿Existen características de las evaluaciones que influyeron para tomar en consideración las recomendaciones derivadas de las evaluaciones?
10. ¿Existen factores políticos que influyeron para tomar en consideración las recomendaciones derivadas de las evaluaciones? ¿Cómo cuáles?
11. ¿Los resultados de las evaluaciones llegaban a todos los actores involucrados en la toma de decisiones?
12. ¿Cómo es el proceso de toma de decisiones al interior de la dependencia?
13. ¿A partir de la implementación de las recomendaciones se obtuvieron ahorros en el programa?
14. ¿A partir de la implementación de las recomendaciones se obtuvo incremento de la cobertura?
15. ¿Existen sanciones a las dependencias por incumplimiento de los ASM? ¿por qué? ¿Qué otros incentivos se plantean?
16. ¿Los costos que han representado los programas de atención a grupos vulnerables se justifican con los resultados obtenidos hasta este momento de acuerdo a las evaluaciones?
199 de 212

17. ¿Influyen los resultados de las evaluaciones en la asignación de presupuesto de cada programa? ¿cómo?
18. Cuando un programa arroja buen desempeño ¿Qué decisiones se toman respecto a la asignación presupuestal? ¿y si es insatisfactorio?
200 de 212

Acrónimos
ASM: Aspectos Susceptibles de Mejora CEFP: Centro de Estudios de las Finanzas Públicas CONEVAL: Consejo Nacional de Evaluación de la Política Social ECR: Evaluación de Consistencia y Resultados EE: Evaluación Especial EED: Evaluación Específica de Desempeño ED: Evaluación de Diseño EI: Evaluación de Impacto ENIGH: Encuesta Nacional de Ingresos y Gastos de los Hogares EP: Evaluación de Procesos EPB: Evaluación de Percepción de Beneficiarios IMEF: Instancias de Mujeres en las entidades federales INDESOL: Instituto Nacional de Desarrollo Social INMUJERES: Instituto Nacional de las Mujeres LFPRH: Ley Federal de Presupuesto y Responsabilidad Hacendaria LGDS: Ley General de Desarrollo Social MEED: Módulo de Información para la Evaluación Específica de Desempeño MIR: Matriz de Indicadores para Resultados MSD: Modelo Sintético de Información del Desempeño NGP: Nueva Gestión Pública OCDE: Organización para la Cooperación y Desarrollo Económico PAE: Programa Anual de Evaluación
201 de 212

PAIMEF: Programa de Apoyo a las instancias de mujeres en las entidades federativas para implementar y ejecutar programas de prevención de la violencia contra las mujeres PAJA: Programa de Atención a Jornaleros Agrícolas PEA: Población Económicamente Activa PEF: Presupuesto de Egresos de la Federación PPEF: Proyecto de Presupuesto de Egresos de la Federación PND: Programa Nacional de Desarrollo PBR: Presupuesto basado en Resultados PCS: Programa de Coinversión Social ROP: Reglas de Operación SED: Sistema de Evaluación del Desempeño SEDESOL: Secretaría de Desarrollo Social SFP: Secretaría de la Función Pública SHCP: Secretaría de Hacienda y Crédito Público SIED: Sistema de Información de las Evaluaciones Específicas de Desempeño SSAS: Sistema de Seguimiento a los Aspectos Susceptibles
202 de 212

Contenido de tablas, figuras y gráficos.
Tablas Tabla 1. Composición de los programas federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades. Tabla 2. Objetivos planteados en las reformas recientes de los países miembros de la OCDE. Tabla 3. Evaluaciones realizadas a los Programas federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades en el periodo 2008-2012. Tabla 4. Presupuesto del programa Jornaleros Agrícolas 2008-2012. Tabla 5. Porcentaje de adultos mayores que viven en pobreza, 2010. Tabla 6. Presupuesto del Programa 70 y más, 2008-2012. Tabla 7. Presupuesto del programa PAIMEF, 2008-2012.
Tabla 8. Presupuesto del programa Coinversión Social, 2008-2012.
Tabla 9. Presupuesto del programa de Fortalecimiento a la Transversalidad de la Perspectiva de Género, 2008-2012. Tabla 10. Número de ASM por programa 2008-2012. Tabla 11. Tipo de cambios que realizaron los programas de Atención a Grupos Vulnerables 2008-2012. Tabla 12. Decisiones implementadas por las dependencias ejecutoras y Cámara de Diputados a partir de los resultados de las evaluaciones. Tabla 13. Información que coincide con la etapa de planeación del presupuesto. Tabla 14. Comparación de los calendarios para el ciclo presupuestal, del Mecanismo de Seguimiento y del Programa Anual de Evaluación en el caso mexicano. Tabla 15. Usos más comunes de las evaluaciones realizadas a Programas federales de Atención a Grupos Vulnerables
Figuras Figura 1. Modelo de toma de decisiones para el sistema de evaluación en México
203 de 212

Figura 2. Posibles usos por el Congreso de la información sobre el desempeño en el ciclo presupuestal. Figura 3. Ciclo de acciones de mejora. Figura 4. Ciclo de seguimiento a los Aspectos Susceptibles de Mejora. Figura 5. El ciclo de la evaluación en México. Figura 6. Ciclo de evaluación y cumplimiento de ASM Figura 7. Modelo de toma de decisiones ajustado al caso de los programas federales de Atención a Grupos Vulnerables Gráficos Gráfico 1. Avance porcentual de los ASM específicos e institucionales de los programas de Atención a Grupos Vulnerables. Gráfico 2. ASM concluidos por programa 2008-2012.
204 de 212

Referencias Bibliográficas
Aguilar, L. F. 1996. La hechura de las políticas, Miguel Ángel Porrúa, México.
Aguilar, L. F. (2004) “Las políticas públicas recientes: una mirada” en Raúl Béjar Navarro (coord.), Las políticas públicas en la alternancia mexicana, México, UNAM.
Aguilar, L. F. (2006) Gobernanza y gestión pública, México, FCE.
Arellano, D. (coord.) (2004), Más allá de la reinvención del gobierno: fundamentos de la Nueva Gestión Pública y Presupuestos por Resultados en América Latina, México, Cámara de Diputados LIX Legislatura, CIDE y Miguel Ángel Porrúa.
____________, (1996) Política pública, racionalidad imperfecta e irracionalidad. Hacia una perspectiva diferente, Gestión y política pública, vol. 5, pp. 319-347.
___________, et. al. 2012. Estudio de la capacidad organizacional e institucional de la CNPSS para incidir en materia de regulación, supervisión y evaluación del desempeño en el sistema de protección social en salud., Reporte de proyecto. CIDE México. Disponible en seguropopular.cide.edu/documents/130486/.../201202_regulación.pdf
___________. 2010, “El enfoque organizacional en la política y la gestión públicas. Entendiendo las organizaciones gubernamentales”, en Merino, M, et. al., Problemas, decisiones y soluciones, México, FCE y CIDE, 2010, pp. 61-92.
________, et. al. 2012. Sistemas de Evaluación del Desempeño para organizaciones públicas. CIDE, México.
Armienta, G. 2002. “La relación entre los poderes Legislativo y Ejecutivo en el constitucionalismo mexicano” en Celia Mora-Donatto (Coord.), Relaciones entre gobierno y Congreso. Memoria del VII Congreso Iberoamericano de Derecho Constitucional, Instituto de Investigaciones Jurídicas, Serie Doctrina Jurídica, núm. 101.
Bailey, J. 2008, Maximizing the Use of Evaluation Findings, Asian Development Bank, p. 3.
Baglione, L. (2012), Writing a research paper in political science. A practical guide to inquiry, structure, and methods, Washington D.C., CQ press.
Behn, R. 1986. El análisis de políticas y la política, en Luis F. Aguilar, El estudio de las políticas públicas, 1996, Miguel Ángel Porrúa, México.
______. 2003. Why Measure Performance? Different Purposes Require Different Measures. Public Administration Review. Vol., 63, No, 5. pp. 586-606.
Bracho, T. 2010. “Políticas basadas en evidencia. La política pública como acción informada y objeto de investigación”, en Merino, M, et. al., Problemas, decisiones y soluciones, México, FCE y CIDE, 2010, pp. 291-321.
205 de 212

Bozeman, B. (2003), Public management decision making: technical vs. political decisions, National public management research conference, Georgetown University, Washington, D.C., October 9-11.
Cardozo, M. (1993), La evaluación de las políticas públicas: problemas, metodologías, aportes y limitaciones. Revista de administración pública, núm. 84, pp. 167-197.
Cejudo, G. et. al., 2011. De las recomendaciones a las acciones, México, CIDE-CLEAR, México.
Centro de Estudios de Finanzas Públicas, 2012, Glosario de términos más usuales de finanzas públicas, Cámara de Diputados. México.
Chelimsky, Eleanor, Program evaluation and appropriate governmental change, Annals of the American academic of political and social science, vol. 466, 1983, pp. 103-118.
CONEVAL, (2011) Informe de evaluación de la política de desarrollo social en México 2011, México.
CONEVAL, (2011) Evaluación Integral del Desempeño de los Programas Federales de Atención a Grupos Prioritarios y Fortalecimiento de Capacidades 2010-2011, México.
Cortés, F. (2008), “Causalidad y evaluación del impacto de la política” en Fernando Cortés, et. al. Método científico y política social. A propósito de las evaluaciones de programas sociales, México, El Colegio de México, pp-97-127.
Cooter R. et. al. (1998), Derecho y economía, México, FCE.
Curristine, T. (2005), Government Perfomance: lessons and challenges, OCDE journal of budgeting, vol 5, pp. 127-151.
Dahler-Larsen, P. (2000), Surviving the Routinization of Evaluation: The Administrative Use of Evaluations in Danish Municipalities, Administration & Society, Vol. 32, pp. 70-92.
Diario Oficial de la Federación, Lineamientos Generales para la Evaluación de los Programas Federales de la Administración Pública Federal, Publicado el 30 de marzo de 2007.
__________________________, Ley General de Desarrollo Social. Publicada el 20 de enero de 2004.
Etzioni, A. (1967), Mixed-scanning: a third approach to decision making, Public administration review, vol. 27, pp. 385-392.
Feldman, M. et.al., 1981. Information in Organizations as Signal and Symbol. Administrative Science Quarterly, Vol. 26, pp. 171-186.
206 de 212

FIDA y PREVAL (2006), Conceptos clave de seguimiento y evaluación de programas y proyectos. Breve guía, Perú, disponible en http://preval.org/es/content/conceptos-clavede-seguimiento-y-evaluaci%C3%B3n-de-programas-y-proyectos-breve-gu%C3%AD
García, et. al, (2010). La gestión para resultados en el desarrollo. Avances y desafíos en América Latina y el Caribe, BID, Segunda edición, 2010. Consultado el 15 de octubre de 2012 en http://preval.org/es/la-gesti%C3%B3n-para-resultados-en-el-desarrollo-avancesy-desaf%C3%ADos-en-am%C3%A9rica-latina-y-el-caribe
González, J. (2010), “La evaluación de la actividad gubernamental: premisas básicas y algunas anotaciones sobre la experiencia mexicana” en José Luis Méndez (coord.), Los grandes problemas de México, Tomo XIII Políticas Públicas, México, El Colegio de México, pp. 143-145.
__________ (2011), “La evaluación del desempeño en cifras”, Política Digital, disponible en http://www.politicadigital.com.mx/?P=leernoticia&Article=20786&c=4
__________ (2013), “El uso efectivo de los resultados de la evaluación: un eslabón de la política de rendición de cuentas”, Buen Gobierno, núm. 14, enero-junio 2013, pp. 94-105.
González, A. (coord.), (2008), ¿Gobernar por resultados? Implicaciones de la política de evaluación del desempeño del gobierno mexicano, versión preliminar.
Graizbord, B. (2011), Sobre la necesidad de considerar el futuro para tomar decisiones presentes, Estudios demográficos y urbanos, vol. 26, pp. 735-748.
Grifel, S. 1994. Organizational Culture: its importance in performance measurement, Public Management, Vol. 76, No. 9.
Hood, C. y Michael Jackson, (1997). La argumentación administrativa, México, FCE.
Julnes, P. et. al., 2001, Promoting the Utilization of Performance Measures in Public Organizations: An Empirical Study of Factors Affecting Adoption and Implementation, Public Administration Review, Vol. 61, pp. 693-708.
Krause, Philipp, (2010), “M&E Systems and the Budget”, Premnotes, Banco Mundial, num. 3, p. 8.
Kusek, J. et. al. 2005. Diez pasos hacia un sistema de seguimiento y evaluación basado en resultados. Banco Mundial, Colombia.
Langley, A. et. al. 1995. Opening up Decision Making: The View from the Black Stool. Organization Science, Vol. 6, pp. 260-279.
207 de 212

Levitt, B. et. al. 1988. Organizational Learning. Annual Review of Sociology, Vol. 14, pp. 319-340.
Ley Federal de Presupuesto y Responsabilidad Presupuestaria, México, D.F., 2006.
Lindblom, C. (1959), The science of “muddling through”, Public administration review, vol. 19, pp. 79-88.
_____________, (1979), Still muddling, not yet through, Public administration review, vol. 39, pp. 517-526.
Lipton, D. 1992. How to Maximize Utilization of Evaluation Research by Policymakers, Annals of the American Academy of Political and Social Science, Vol. 521, Drug Abuse: Linking Policy and Research, pp. 175-188.
March, J. and Johan Olsen, (2009) The logic of appropriateness, Centre for European Studies, University of Oslo, pp. 1-28.
Majone, G. 1997. Evidencia, argumentación y persuasión en la formulación de políticas, FCE, México.
__________, 2001, Nonmajoritarian Institutions and the Limits of Democratic Governance: A PoliticalTransaction-Cost Approach, Journal of Institutional and Theoretical Economics, vol. 157, pp. 57-78.
_________, 1975. “La factibilidad de las políticas sociales” en Luis F. Aguilar, La hechura de las políticas, 1996. Miguel Ángel Porrúa, México.
May, P. 1981. “Claves para diseñar opciones de políticas” en Luis F. Aguilar, Problemas públicos y agenda de gobierno. 1996. Miguel Ángel Porrúa, México.
Mejía, J. (2006), Evaluación por resultados: eje estratégico de la profesionalización, XI Congreso Internacional del CLAD sobre la Reforma del Estado y de la Administración Pública, Guatemala.
Merino, M., Sergio López Ayllón y Guillermo Cejudo (Coords.), (2010), La estructura de la Rendición de Cuentas en México, UNAM-IIJ, CIDE.
Méndez, José Luis, 2010. “Implementing Developed Countries’ Administrative Reforms in Developing Countries: The case of Mexico”, en Jon Pierre y Patricia Ingraham (eds), Comparative Administrative Change and Reform. Quebec, McGill-Queen’s University Press, pp. 159-181.
_____________, 1996. “Federalismo, regiones y política industrial en Nuevo León, México y Westfalia del Rhin del Norte, Alemania”, en Carlos Alba (comp.), México y Alemania: dos países en transición. México, D.F. El Colegio de México, pp.51-79.
208 de 212

_____________, 1993. La política pública como variable dependiente: hacia un análisis más integral de las políticas públicas. Foro Internacional, Vol. 33, pp. 111-44.

Meltsner, A. 1972. “La factibilidad política y el análisis de políticas” en Luis F. Aguilar, La hechura de las políticas, 1996. Miguel Ángel Porrúa, México.

Montiel, J. 2011. “La evaluación como instrumento de cambio” en Guillermo Cejudo, G. et. al. De las recomendaciones a las acciones, México, CIDE-CLEAR, México.

Moynihan, D. et.al., 2005. What Do We Talk About When We Talk About Performance?

Dialogue Theory and Performance Budgeting. Working Paper Series. La Follette School

Working

Paper

No.

021.

pp.

1-33.

Disponible

en

http://www.lafollette.wisc.edu/publications/workingpapers

___________et. al., 2009. How Do Public Organizations Learn? Bridging Cultural and Structural Perspectives. Public Administration Review, vol. 69 pp. 1097-1105

__________ et.al., 2010, The Big Question for Performance Management: Why Do Managers Use Performance Information?, Journal of Public Administration Research and Theory, pp. 849-866.

_________et. al.,2011. Does Involvement in Performance Management Routines Encourage Performance Information Use? Evaluating GPRA and PART. Working Paper Series La Follette School Working Paper No. 017. Disponible en http://www.lafollette.wisc.edu/publications/workingpapers

North, D. 1993. Instituciones, cambio institucional y desempeño económico, traduc. Agustín Bárcena, México, FCE.

OCDE 1995, Governance in Transition: Public Management Reforms in OECD Countries, París.

________, 2001. Evaluation Feedback for Effective Learning and Accountability, ediciones de la OCDE, París.

________, 2005, Evaluating public participation in policy making, París.

________, 2007, Performance Budgeting in OECD countries, Las Ediciones de la OCDE, París.
_____, 2009, Estudio de la OCDE sobre el proceso presupuestario en México, ediciones de la OCDE, París.

Ospina, S. 2001. Evaluación de la gestión pública: conceptos y aplicaciones en el caso latinoamericano, Revista del CLAD Reforma y Democracia. No.19. Caracas.

209 de 212

Ospina, Cunill y Zaltsman, (2004) Performace evaluation, public management improvement and democratic accountability, Public Management Review, 6, pp. 229-251.

Papadakis, V., S. Lioukas and D. Chambers, (1998), Strategic decision-making processes: the role of management and context, Strategic management journal, vol. 19, pp. 115147.

Pardo, M. (2009), La modernización administrativa en México 1940-2006, México, El Colegio de México, 2009.

Peters G. y J. Pierre (1998), Institutions and Time: problems of conceptualization and explanation, Journal of Public Administration Research and Theory, vol. 8 , pp.565-583.

Puente, K. 2011. Democratización, Congreso y gasto público en México: la lógica del pacto político presupuestal entre 1994 y 2010. Tesis, México, El Colegio de México.

Ramírez, E. y Ramírez J. (2004), “Génesis y desarrollo del concepto de nueva gestión pública. Bases organizacionales para el replanteamiento de la acción administrativa y su impacto en la reforma del gobierno” en Arellano Gual, David (coord.), Más allá de la reinvención del gobierno: fundamentos de la Nueva Gestión Pública y Presupuestos por Resultados en América Latina, México, Cámara de Diputados LIX Legislatura, CIDE y Miguel Ángel Porrúa.

Reddick Christopher G. (2002), Testing Rival Decision-Making Theories on Budget Outputs: Theories and Comparative Evidence. Public Budgeting and Finance, Vol. 22, pp. 1-25. Disponible en http://ssrn.com/abstract=330761.

Ríos Hess, (2007) Diagnóstico de los sistemas de monitoreo y evaluación en Chile, http://www.clad.org/siare_isis/innotend/evaluacion/chile.pdf pág. 47.

Roemer, A. y E. Moctezuma Barragán, (1999), Por un gobierno con resultados. El servicio civil de carrera: un sistema integral de profesionalización, evaluación y desempeño de los servidores públicos en México, México, FCE.
Rossi, P. et. al., (2004) Evaluation: a systematic approach, 7th edition, United States of America, Sage Publications.

Rubio, G. (2011), “Sistema de seguimiento y evaluación del gobierno mexicano”, Premnotes, Banco Mundial, núm. 14, p. 11.

Simon, H. (1995), Rationality in political behavior, Political Psychology, vol. 16, pp. 45-61.

SHCP, Sistema de evaluación del desempeño, http://www.normateca.gob.mx/Archivos/51_D_1996_.pdf

México,

2008.

SHCP y BM, (2010) Mejorando la calidad del gasto público a través del uso de información de desempeño en México, Washington.

210 de 212

SIEMPRO y UNESCO, (1999), Gestión integral de programas sociales orientada a resultados. Manual metodológico para la planificación y evaluación de programas sociales, Brasil, FCE.
Sterck, M. et.al. (2006), Trends in Performance Budgeting in seven Oecd countries, Public Performance and Management Review, vol. 30, pp. 47-72.
Subirats, J. (1992), Análisis de políticas públicas y eficacia de la administración, Madrid, Instituto Nacional de Administración Pública.
Stone, D. 2002. Policy Paradox: the art of political decision making, Norton Company, New York.
Townley, B. 2002, The Role of Competing Rationalities in Institutional Change, The Academy of Management Journal, Vol. 45, pp. 163-179.
Urbanos Garrido R. (2012), Evaluación de políticas públicas. Madrid, Escuela Nacional de Sanidad; Tema 10.7
Weiss, C. (1998), Have we learned anything about the use of evaluation?, American Journal of Evaluation, vol. 19, pp. 21-33.
_________, 1998. Evaluation: methods for studying programs and policies. Prentice Hall, New Jersey.
_________, (1982), Policy research in the context of diffuse decision making, The Journal of higher education, vol. 53, pp. 619-639.
_________, (1980), Truth test and utility tests: decision-maker’s frames of reference for social science research, American sociological review, vol. 45, pp. 302-313.
________, (1979), The many meanings of research utilization, Public administration review, vol. 39, pp. 426-431.
Wiesner, E. 2000. Función de evaluación de planes, programas, estrategias y proyectos, Santiago de Chile, CEPAL.
White, M. et. al. 2005. Measuring Organizational Capacity among Agencies Serving the Poor: Implications for Achieving Organizational Effectiveness, Justice Policy Journal, 2(2): 1-39. Disponible en http://johnjayresearch.org/rec/2005/10/01/orgcap2005/
Zabaleta, D. 2008. “Orientación a resultados y proceso presupuestario: algunas anotaciones sobre su implementación en México” en González, Alejandro (coord.), ¿Gobernar por resultados? Implicaciones de la política de evaluación del desempeño del gobierno mexicano, versión preliminar.
211 de 212

Zall, J. y Ray R. (2004), Diez pasos hacia un sistema de seguimiento y evaluación basado en resultados, Colombia, Banco Mundial.
212 de 212

